import gradio as gr
import torch
from transformers import Qwen3VLForConditionalGeneration, AutoProcessor, BitsAndBytesConfig, TextIteratorStreamer
from qwen_vl_utils import process_vision_info
from PIL import Image
import random
import os
import warnings
from typing import List, Tuple, Optional, Generator
import gc
import json
import csv
import shutil
from datetime import datetime
import time
import tempfile
from threading import Thread
import io
import sys
import logging

# Optional: psutil for memory monitoring
try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False
    print("Note: psutil not installed. RAM monitoring will be limited.")

# Suppress meta device warning (not useful)
warnings.filterwarnings('ignore', message='.*meta device.*')

# Global flag for stopping generation
stop_generation_flag = False

# ==========================================
# Console Log Capture for UI display
# ==========================================
class LogCapture:
    """Captures stdout and logs for real-time console output in UI"""
    def __init__(self):
        self.log_buffer = io.StringIO()
        self.original_stdout = sys.stdout
        self.is_capturing = False

    def start_capture(self):
        """Start capturing stdout"""
        if not self.is_capturing:
            sys.stdout = self
            self.is_capturing = True

    def stop_capture(self):
        """Stop capturing stdout"""
        if self.is_capturing:
            sys.stdout = self.original_stdout
            self.is_capturing = False

    def write(self, message):
        """Write to both original stdout and buffer"""
        self.original_stdout.write(message)
        self.log_buffer.write(message)

    def flush(self):
        """Flush stdout"""
        self.original_stdout.flush()

    def get_logs(self):
        """Get captured logs"""
        return self.log_buffer.getvalue()

    def clear_logs(self):
        """Clear log buffer"""
        self.log_buffer = io.StringIO()

# Global log capture instance
log_capture = LogCapture()

# Base directory for portable app
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
TEMP_DIR = os.path.join(SCRIPT_DIR, "temp")
OUTPUT_DIR = os.path.join(SCRIPT_DIR, "output")
DATASETS_DIR = os.path.join(SCRIPT_DIR, "datasets")
PROMPTS_DIR = os.path.join(SCRIPT_DIR, "prompts")

# Create directories if they don't exist
os.makedirs(TEMP_DIR, exist_ok=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(DATASETS_DIR, exist_ok=True)
os.makedirs(PROMPTS_DIR, exist_ok=True)

# Huggingface cache directory - check env variables first, then platform-specific defaults
def get_hf_cache_dir():
    """Get HuggingFace cache directory, respecting environment variables and platform defaults"""
    # Check HuggingFace environment variables first
    if os.environ.get("HUGGINGFACE_HUB_CACHE"):
        return os.environ["HUGGINGFACE_HUB_CACHE"]
    if os.environ.get("HF_HOME"):
        return os.path.join(os.environ["HF_HOME"], "hub")
    if os.environ.get("HF_HUB_CACHE"):
        return os.environ["HF_HUB_CACHE"]

    # Platform-specific defaults
    if os.name == 'nt':  # Windows
        # Windows: typically in USERPROFILE\.cache\huggingface\hub
        local_app_data = os.environ.get("LOCALAPPDATA")
        if local_app_data:
            cache_in_localappdata = os.path.join(local_app_data, "huggingface", "hub")
            if os.path.exists(cache_in_localappdata):
                return cache_in_localappdata
        # Fall back to home directory
        return os.path.join(os.path.expanduser("~"), ".cache", "huggingface", "hub")
    else:
        # Linux/Mac
        xdg_cache = os.environ.get("XDG_CACHE_HOME", os.path.join(os.path.expanduser("~"), ".cache"))
        return os.path.join(xdg_cache, "huggingface", "hub")

HF_CACHE_DIR = get_hf_cache_dir()

def get_model_cache_size(model_id: str) -> Optional[str]:
    """Check if model is downloaded and return its size on disk"""
    try:
        # Convert model_id to cache folder name format
        # huihui-ai/Huihui-Qwen3-VL-2B-Instruct-abliterated -> models--huihui-ai--Huihui-Qwen3-VL-2B-Instruct-abliterated
        cache_name = "models--" + model_id.replace("/", "--")
        cache_path = os.path.join(HF_CACHE_DIR, cache_name)

        if os.path.exists(cache_path):
            # Calculate total size
            total_size = 0
            for dirpath, dirnames, filenames in os.walk(cache_path):
                for f in filenames:
                    fp = os.path.join(dirpath, f)
                    if os.path.exists(fp):
                        total_size += os.path.getsize(fp)

            # Convert to human-readable format
            if total_size >= 1024 ** 3:
                return f"{total_size / (1024 ** 3):.1f}GB"
            elif total_size >= 1024 ** 2:
                return f"{total_size / (1024 ** 2):.0f}MB"
            else:
                return f"{total_size / 1024:.0f}KB"
        return None
    except:
        return None

# Available models (without MOE models which have different architecture)
AVAILABLE_MODELS = [
    # Abliterated models (Ð±ÐµÐ· Ñ†ÐµÐ½Ð·ÑƒÑ€Ñ‹) - Ñ€ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐµÐ¼Ñ‹Ðµ
    ("2B Instruct Abliterated", "huihui-ai/Huihui-Qwen3-VL-2B-Instruct-abliterated"),
    ("2B Thinking Abliterated", "huihui-ai/Huihui-Qwen3-VL-2B-Thinking-abliterated"),
    ("4B Instruct Abliterated", "huihui-ai/Huihui-Qwen3-VL-4B-Instruct-abliterated"),
    ("4B Thinking Abliterated", "huihui-ai/Huihui-Qwen3-VL-4B-Thinking-abliterated"),
    ("8B Instruct Abliterated", "huihui-ai/Huihui-Qwen3-VL-8B-Instruct-abliterated"),
    ("8B Thinking Abliterated", "huihui-ai/Huihui-Qwen3-VL-8B-Thinking-abliterated"),
    ("32B Instruct Abliterated", "huihui-ai/Huihui-Qwen3-VL-32B-Instruct-abliterated"),
    ("32B Thinking Abliterated", "huihui-ai/Huihui-Qwen3-VL-32B-Thinking-abliterated"),
    # Original Qwen models
    ("Qwen 2B Instruct", "Qwen/Qwen3-VL-2B-Instruct"),
    ("Qwen 4B Instruct", "Qwen/Qwen3-VL-4B-Instruct"),
    ("Qwen 8B Instruct", "Qwen/Qwen3-VL-8B-Instruct"),
]

def get_model_choices():
    """Get model choices with download status indicator"""
    choices = []
    for name, model_id in AVAILABLE_MODELS:
        cached_size = get_model_cache_size(model_id)
        if cached_size:
            # Model is downloaded - show size
            display_name = f"âœ… {name} [{cached_size}]"
        else:
            # Model not downloaded - will be downloaded on first use
            display_name = f"â¬‡ï¸ {name} [Ð½Ðµ ÑÐºÐ°Ñ‡Ð°Ð½Ð°]"
        choices.append((display_name, model_id))
    return choices

# Extra options for description enhancement (IMAGE)
EXTRA_OPTIONS = {
    "en": {
        "Include lighting info": "Include information about lighting.",
        "Include camera angle": "Include information about camera angle.",
        "Include watermark info": "Include information about whether there is a watermark or not.",
        "Include JPEG artifacts info": "Include information about whether there are JPEG artifacts or not.",
        "Include camera/photo details": "If it is a photo, include information about what camera was likely used and details such as aperture, shutter speed, ISO, etc.",
        "Keep it SFW/PG": "Do NOT include anything sexual; keep it PG.",
        "Don't mention resolution": "Do NOT mention the image's resolution.",
        "Include aesthetic quality": "Include information about the subjective aesthetic quality of the image from low to very high.",
        "Include composition style": "Include information on the image's composition style, such as leading lines, rule of thirds, or symmetry.",
        "Don't mention text in image": "Do NOT mention any text that is in the image.",
        "Include depth of field": "Specify the depth of field and whether the background is in focus or blurred.",
        "Describe only key elements": "ONLY describe the most important elements of the image."
    },
    "ru": {
        "Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾Ð± Ð¾ÑÐ²ÐµÑ‰ÐµÐ½Ð¸Ð¸": "Ð”Ð¾Ð±Ð°Ð²ÑŒ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾Ð± Ð¾ÑÐ²ÐµÑ‰ÐµÐ½Ð¸Ð¸.",
        "Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ñ€Ð°ÐºÑƒÑ€Ñ ÐºÐ°Ð¼ÐµÑ€Ñ‹": "Ð”Ð¾Ð±Ð°Ð²ÑŒ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ñ€Ð°ÐºÑƒÑ€ÑÐµ ÐºÐ°Ð¼ÐµÑ€Ñ‹.",
        "Ð£Ð¿Ð¾Ð¼ÑÐ½ÑƒÑ‚ÑŒ Ð²Ð¾Ð´ÑÐ½Ð¾Ð¹ Ð·Ð½Ð°Ðº": "Ð£ÐºÐ°Ð¶Ð¸, ÐµÑÑ‚ÑŒ Ð»Ð¸ Ð²Ð¾Ð´ÑÐ½Ð¾Ð¹ Ð·Ð½Ð°Ðº Ð½Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¸.",
        "Ð£Ð¿Ð¾Ð¼ÑÐ½ÑƒÑ‚ÑŒ JPEG Ð°Ñ€Ñ‚ÐµÑ„Ð°ÐºÑ‚Ñ‹": "Ð£ÐºÐ°Ð¶Ð¸, ÐµÑÑ‚ÑŒ Ð»Ð¸ JPEG Ð°Ñ€Ñ‚ÐµÑ„Ð°ÐºÑ‚Ñ‹ Ð½Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¸.",
        "Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð´ÐµÑ‚Ð°Ð»Ð¸ ÐºÐ°Ð¼ÐµÑ€Ñ‹/Ñ„Ð¾Ñ‚Ð¾": "Ð•ÑÐ»Ð¸ ÑÑ‚Ð¾ Ñ„Ð¾Ñ‚Ð¾Ð³Ñ€Ð°Ñ„Ð¸Ñ, ÑƒÐºÐ°Ð¶Ð¸ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ ÐºÐ°Ð¼ÐµÑ€Ðµ, Ð°Ð¿ÐµÑ€Ñ‚ÑƒÑ€Ðµ, Ð²Ñ‹Ð´ÐµÑ€Ð¶ÐºÐµ, ISO Ð¸ Ñ‚.Ð´.",
        "Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ SFW/PG Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³": "ÐÐ• Ð²ÐºÐ»ÑŽÑ‡Ð°Ð¹ ÑÐµÐºÑÑƒÐ°Ð»ÑŒÐ½Ñ‹Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚, ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐ¹ Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³ PG.",
        "ÐÐµ ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ñ‚ÑŒ Ñ€Ð°Ð·Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ": "ÐÐ• ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ð¹ Ñ€Ð°Ð·Ñ€ÐµÑˆÐµÐ½Ð¸Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ.",
        "Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ ÑÑÑ‚ÐµÑ‚Ð¸Ñ‡ÐµÑÐºÑƒÑŽ Ð¾Ñ†ÐµÐ½ÐºÑƒ": "Ð”Ð¾Ð±Ð°Ð²ÑŒ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ ÑÑƒÐ±ÑŠÐµÐºÑ‚Ð¸Ð²Ð½Ð¾Ð¼ ÑÑÑ‚ÐµÑ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð¼ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ðµ Ð¾Ñ‚ Ð½Ð¸Ð·ÐºÐ¾Ð³Ð¾ Ð´Ð¾ Ð¾Ñ‡ÐµÐ½ÑŒ Ð²Ñ‹ÑÐ¾ÐºÐ¾Ð³Ð¾.",
        "Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ ÑÑ‚Ð¸Ð»ÑŒ ÐºÐ¾Ð¼Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸": "Ð”Ð¾Ð±Ð°Ð²ÑŒ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ ÑÑ‚Ð¸Ð»Ðµ ÐºÐ¾Ð¼Ð¿Ð¾Ð·Ð¸Ñ†Ð¸Ð¸ (Ð²ÐµÐ´ÑƒÑ‰Ð¸Ðµ Ð»Ð¸Ð½Ð¸Ð¸, Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð¾ Ñ‚Ñ€ÐµÑ‚ÐµÐ¹, ÑÐ¸Ð¼Ð¼ÐµÑ‚Ñ€Ð¸Ñ).",
        "ÐÐµ ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ñ‚ÑŒ Ñ‚ÐµÐºÑÑ‚ Ð½Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¸": "ÐÐ• ÑƒÐ¿Ð¾Ð¼Ð¸Ð½Ð°Ð¹ Ñ‚ÐµÐºÑÑ‚, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ ÐµÑÑ‚ÑŒ Ð½Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¸.",
        "Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð³Ð»ÑƒÐ±Ð¸Ð½Ñƒ Ñ€ÐµÐ·ÐºÐ¾ÑÑ‚Ð¸": "Ð£ÐºÐ°Ð¶Ð¸ Ð³Ð»ÑƒÐ±Ð¸Ð½Ñƒ Ñ€ÐµÐ·ÐºÐ¾ÑÑ‚Ð¸ Ð¸ Ñ€Ð°Ð·Ð¼Ñ‹Ñ‚Ð¾ÑÑ‚ÑŒ Ñ„Ð¾Ð½Ð°.",
        "ÐžÐ¿Ð¸ÑÑ‹Ð²Ð°Ñ‚ÑŒ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ñ‹": "ÐžÐ¿Ð¸ÑÑ‹Ð²Ð°Ð¹ Ð¢ÐžÐ›Ð¬ÐšÐž ÑÐ°Ð¼Ñ‹Ðµ Ð²Ð°Ð¶Ð½Ñ‹Ðµ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ñ‹ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ."
    },
    "zh": {
        "åŒ…å«å…‰ç…§ä¿¡æ¯": "åŒ…å«å…‰ç…§ä¿¡æ¯ã€‚",
        "åŒ…å«ç›¸æœºè§’åº¦": "åŒ…å«ç›¸æœºè§’åº¦ä¿¡æ¯ã€‚",
        "æåŠæ°´å°": "è¯´æ˜Žå›¾ç‰‡æ˜¯å¦æœ‰æ°´å°ã€‚",
        "æåŠJPEGä¼ªå½±": "è¯´æ˜Žå›¾ç‰‡æ˜¯å¦æœ‰JPEGä¼ªå½±ã€‚",
        "åŒ…å«ç›¸æœº/ç…§ç‰‡è¯¦æƒ…": "å¦‚æžœæ˜¯ç…§ç‰‡ï¼ŒåŒ…å«å¯èƒ½ä½¿ç”¨çš„ç›¸æœºä¿¡æ¯ï¼Œå¦‚å…‰åœˆã€å¿«é—¨é€Ÿåº¦ã€ISOç­‰ã€‚",
        "ä¿æŒSFW/PGçº§åˆ«": "ä¸è¦åŒ…å«ä»»ä½•æ€§ç›¸å…³å†…å®¹ï¼Œä¿æŒPGçº§åˆ«ã€‚",
        "ä¸è¦æåŠåˆ†è¾¨çŽ‡": "ä¸è¦æåŠå›¾ç‰‡çš„åˆ†è¾¨çŽ‡ã€‚",
        "åŒ…å«ç¾Žå­¦è´¨é‡è¯„ä»·": "åŒ…å«ä»Žä½Žåˆ°éžå¸¸é«˜çš„ä¸»è§‚ç¾Žå­¦è´¨é‡è¯„ä»·ã€‚",
        "åŒ…å«æž„å›¾é£Žæ ¼": "åŒ…å«æž„å›¾é£Žæ ¼ä¿¡æ¯ï¼Œå¦‚å¼•å¯¼çº¿ã€ä¸‰åˆ†æ³•åˆ™æˆ–å¯¹ç§°æ€§ã€‚",
        "ä¸è¦æåŠå›¾ç‰‡ä¸­çš„æ–‡å­—": "ä¸è¦æåŠå›¾ç‰‡ä¸­çš„ä»»ä½•æ–‡å­—ã€‚",
        "åŒ…å«æ™¯æ·±ä¿¡æ¯": "è¯´æ˜Žæ™¯æ·±ä»¥åŠèƒŒæ™¯æ˜¯å¦æ¨¡ç³Šã€‚",
        "åªæè¿°å…³é”®å…ƒç´ ": "åªæè¿°å›¾ç‰‡ä¸­æœ€é‡è¦çš„å…ƒç´ ã€‚"
    }
}

# Extra options for VIDEO description enhancement
EXTRA_OPTIONS_VIDEO = {
    "en": {
        "Describe camera movement": "Describe camera movements (panning, zooming, static, etc.).",
        "Include audio description": "If the video has audio, describe it (music, speech, sound effects).",
        "Describe plot/story": "Describe the plot or story progression in the video.",
        "Include lighting info": "Include information about lighting changes throughout the video.",
        "Include editing style": "Describe the editing style (cuts, transitions, effects).",
        "Keep it SFW/PG": "Do NOT include anything sexual; keep it PG.",
        "Describe only key moments": "ONLY describe the most important moments in the video.",
        "Include aesthetic quality": "Include information about the subjective aesthetic quality from low to very high."
    },
    "ru": {
        "ÐžÐ¿Ð¸ÑÐ°Ñ‚ÑŒ Ð´Ð²Ð¸Ð¶ÐµÐ½Ð¸Ðµ ÐºÐ°Ð¼ÐµÑ€Ñ‹": "ÐžÐ¿Ð¸ÑˆÐ¸ Ð´Ð²Ð¸Ð¶ÐµÐ½Ð¸Ñ ÐºÐ°Ð¼ÐµÑ€Ñ‹ (Ð¿Ð°Ð½Ð¾Ñ€Ð°Ð¼Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ, Ð·ÑƒÐ¼, ÑÑ‚Ð°Ñ‚Ð¸Ñ‡Ð½Ð°Ñ Ð¸ Ñ‚.Ð´.).",
        "Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð·Ð²ÑƒÐºÐ°": "Ð•ÑÐ»Ð¸ Ð² Ð²Ð¸Ð´ÐµÐ¾ ÐµÑÑ‚ÑŒ Ð·Ð²ÑƒÐº, Ð¾Ð¿Ð¸ÑˆÐ¸ ÐµÐ³Ð¾ (Ð¼ÑƒÐ·Ñ‹ÐºÐ°, Ñ€ÐµÑ‡ÑŒ, Ð·Ð²ÑƒÐºÐ¾Ð²Ñ‹Ðµ ÑÑ„Ñ„ÐµÐºÑ‚Ñ‹).",
        "ÐžÐ¿Ð¸ÑÐ°Ñ‚ÑŒ ÑÑŽÐ¶ÐµÑ‚/Ð¸ÑÑ‚Ð¾Ñ€Ð¸ÑŽ": "ÐžÐ¿Ð¸ÑˆÐ¸ ÑÑŽÐ¶ÐµÑ‚ Ð¸Ð»Ð¸ Ñ€Ð°Ð·Ð²Ð¸Ñ‚Ð¸Ðµ Ð¸ÑÑ‚Ð¾Ñ€Ð¸Ð¸ Ð² Ð²Ð¸Ð´ÐµÐ¾.",
        "Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾Ð± Ð¾ÑÐ²ÐµÑ‰ÐµÐ½Ð¸Ð¸": "Ð”Ð¾Ð±Ð°Ð²ÑŒ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾Ð± Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸ÑÑ… Ð¾ÑÐ²ÐµÑ‰ÐµÐ½Ð¸Ñ Ð² Ñ‚ÐµÑ‡ÐµÐ½Ð¸Ðµ Ð²Ð¸Ð´ÐµÐ¾.",
        "Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ ÑÑ‚Ð¸Ð»ÑŒ Ð¼Ð¾Ð½Ñ‚Ð°Ð¶Ð°": "ÐžÐ¿Ð¸ÑˆÐ¸ ÑÑ‚Ð¸Ð»ÑŒ Ð¼Ð¾Ð½Ñ‚Ð°Ð¶Ð° (Ð¿ÐµÑ€ÐµÑ…Ð¾Ð´Ñ‹, ÑÑ„Ñ„ÐµÐºÑ‚Ñ‹).",
        "Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ SFW/PG Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³": "ÐÐ• Ð²ÐºÐ»ÑŽÑ‡Ð°Ð¹ ÑÐµÐºÑÑƒÐ°Ð»ÑŒÐ½Ñ‹Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐ½Ñ‚, ÑÐ¾Ñ…Ñ€Ð°Ð½ÑÐ¹ Ñ€ÐµÐ¹Ñ‚Ð¸Ð½Ð³ PG.",
        "ÐžÐ¿Ð¸ÑÑ‹Ð²Ð°Ñ‚ÑŒ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ð¼Ð¾Ð¼ÐµÐ½Ñ‚Ñ‹": "ÐžÐ¿Ð¸ÑÑ‹Ð²Ð°Ð¹ Ð¢ÐžÐ›Ð¬ÐšÐž ÑÐ°Ð¼Ñ‹Ðµ Ð²Ð°Ð¶Ð½Ñ‹Ðµ Ð¼Ð¾Ð¼ÐµÐ½Ñ‚Ñ‹ Ð²Ð¸Ð´ÐµÐ¾.",
        "Ð”Ð¾Ð±Ð°Ð²Ð¸Ñ‚ÑŒ ÑÑÑ‚ÐµÑ‚Ð¸Ñ‡ÐµÑÐºÑƒÑŽ Ð¾Ñ†ÐµÐ½ÐºÑƒ": "Ð”Ð¾Ð±Ð°Ð²ÑŒ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ ÑÑƒÐ±ÑŠÐµÐºÑ‚Ð¸Ð²Ð½Ð¾Ð¼ ÑÑÑ‚ÐµÑ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð¼ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ðµ Ð¾Ñ‚ Ð½Ð¸Ð·ÐºÐ¾Ð³Ð¾ Ð´Ð¾ Ð¾Ñ‡ÐµÐ½ÑŒ Ð²Ñ‹ÑÐ¾ÐºÐ¾Ð³Ð¾."
    },
    "zh": {
        "æè¿°é•œå¤´è¿åŠ¨": "æè¿°é•œå¤´è¿åŠ¨ï¼ˆå¹³ç§»ã€ç¼©æ”¾ã€é™æ­¢ç­‰ï¼‰ã€‚",
        "åŒ…å«éŸ³é¢‘æè¿°": "å¦‚æžœè§†é¢‘æœ‰éŸ³é¢‘ï¼Œæè¿°å®ƒï¼ˆéŸ³ä¹ã€è¯­éŸ³ã€éŸ³æ•ˆï¼‰ã€‚",
        "æè¿°æƒ…èŠ‚/æ•…äº‹": "æè¿°è§†é¢‘ä¸­çš„æƒ…èŠ‚æˆ–æ•…äº‹å‘å±•ã€‚",
        "åŒ…å«å…‰ç…§ä¿¡æ¯": "åŒ…å«è§†é¢‘ä¸­å…‰ç…§å˜åŒ–çš„ä¿¡æ¯ã€‚",
        "åŒ…å«å‰ªè¾‘é£Žæ ¼": "æè¿°å‰ªè¾‘é£Žæ ¼ï¼ˆåˆ‡æ¢ã€è¿‡æ¸¡ã€æ•ˆæžœï¼‰ã€‚",
        "ä¿æŒSFW/PGçº§åˆ«": "ä¸è¦åŒ…å«ä»»ä½•æ€§ç›¸å…³å†…å®¹ï¼Œä¿æŒPGçº§åˆ«ã€‚",
        "åªæè¿°å…³é”®æ—¶åˆ»": "åªæè¿°è§†é¢‘ä¸­æœ€é‡è¦çš„æ—¶åˆ»ã€‚",
        "åŒ…å«ç¾Žå­¦è´¨é‡è¯„ä»·": "åŒ…å«ä»Žä½Žåˆ°éžå¸¸é«˜çš„ä¸»è§‚ç¾Žå­¦è´¨é‡è¯„ä»·ã€‚"
    }
}

def get_memory_info() -> str:
    """Get current memory usage information"""
    info_parts = []

    # GPU memory
    if torch.cuda.is_available():
        try:
            allocated = torch.cuda.memory_allocated() / (1024 ** 3)
            reserved = torch.cuda.memory_reserved() / (1024 ** 3)
            total = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)
            info_parts.append(f"GPU: {allocated:.1f}/{total:.1f} GB (reserved: {reserved:.1f} GB)")
        except:
            pass

    # RAM
    if PSUTIL_AVAILABLE:
        try:
            process = psutil.Process(os.getpid())
            ram_usage = process.memory_info().rss / (1024 ** 3)
            info_parts.append(f"RAM: {ram_usage:.1f} GB")
        except:
            pass

    return " | ".join(info_parts) if info_parts else "Memory info unavailable"

def load_prompt_presets() -> dict:
    """Load prompt presets from the prompts directory"""
    presets = {"None": ""}

    if not os.path.exists(PROMPTS_DIR):
        return presets

    for filename in os.listdir(PROMPTS_DIR):
        if filename.endswith('.txt'):
            preset_name = os.path.splitext(filename)[0]
            try:
                with open(os.path.join(PROMPTS_DIR, filename), 'r', encoding='utf-8') as f:
                    presets[preset_name] = f.read().strip()
            except:
                pass

    return presets

def save_prompt_preset(name: str, prompt: str) -> str:
    """Save a prompt preset to the prompts directory"""
    if not name or not name.strip():
        if current_language == "ru":
            return "âŒ Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð¸Ð¼Ñ Ð¿Ñ€ÐµÑÐµÑ‚Ð°"
        return "âŒ Please provide a preset name"

    if not prompt or not prompt.strip():
        if current_language == "ru":
            return "âŒ Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ Ð´Ð»Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ"
        return "âŒ Please provide a prompt to save"

    # Sanitize filename
    safe_name = "".join(c for c in name if c.isalnum() or c in "_ -").strip()
    if not safe_name:
        if current_language == "ru":
            return "âŒ ÐÐµÐ´Ð¾Ð¿ÑƒÑÑ‚Ð¸Ð¼Ð¾Ðµ Ð¸Ð¼Ñ Ð¿Ñ€ÐµÑÐµÑ‚Ð°"
        return "âŒ Invalid preset name"

    try:
        os.makedirs(PROMPTS_DIR, exist_ok=True)
        filepath = os.path.join(PROMPTS_DIR, f"{safe_name}.txt")
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(prompt.strip())
        if current_language == "ru":
            return f"âœ… ÐŸÑ€ÐµÑÐµÑ‚ '{safe_name}' ÑÐ¾Ñ…Ñ€Ð°Ð½Ñ‘Ð½!"
        return f"âœ… Preset '{safe_name}' saved successfully!"
    except Exception as e:
        if current_language == "ru":
            return f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ: {str(e)}"
        return f"âŒ Error saving preset: {str(e)}"

def save_text_to_file(text: str, filename: str = "result.txt") -> str:
    """Save text to a temporary file and return the path"""
    temp_file = os.path.join(TEMP_DIR, filename)
    with open(temp_file, 'w', encoding='utf-8') as f:
        f.write(text)
    return temp_file

def stop_generation():
    """Set the stop flag to True"""
    global stop_generation_flag
    stop_generation_flag = True
    return "ðŸ›‘ Stopping generation..."

def reset_stop_flag():
    """Reset the stop flag"""
    global stop_generation_flag
    stop_generation_flag = False

# Custom CSS for beautiful UI
CUSTOM_CSS = """
/* Main container styling */
.gradio-container {
    background: linear-gradient(135deg, #f8fafc 0%, #e2e8f0 100%) !important;
}

/* Card style blocks */
.card-style {
    background: rgba(255, 255, 255, 0.9) !important;
    border: 1px solid rgba(203, 213, 225, 0.5) !important;
    box-shadow: 0 8px 32px rgba(100, 116, 139, 0.1) !important;
    border-radius: 16px !important;
    padding: 1.5rem !important;
    margin-bottom: 1rem !important;
}

/* Main header with gradient */
.main-header {
    background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
    padding: 2rem;
    border-radius: 20px;
    margin-bottom: 1.5rem;
    text-align: center;
    box-shadow: 0 10px 40px rgba(102, 126, 234, 0.3);
}

.main-header h1 {
    color: white !important;
    font-size: 2.5rem !important;
    font-weight: 700 !important;
    margin: 0 !important;
    text-shadow: 0 2px 4px rgba(0,0,0,0.3);
}

.main-header p {
    color: rgba(255,255,255,0.9) !important;
    font-size: 1.1rem !important;
    margin: 0.5rem 0 0 0 !important;
}

.main-header a {
    color: white !important;
    text-decoration: underline;
}

/* Generate button styling */
.generate-btn {
    min-height: 36px !important;
    font-size: 0.95rem !important;
    font-weight: 500 !important;
    padding: 8px 16px !important;
}

/* Status box */
.status-box {
    background: linear-gradient(135deg, #f0f9ff 0%, #e0f2fe 100%) !important;
    border: 1px solid #7dd3fc !important;
    border-radius: 12px !important;
    padding: 1rem !important;
}

/* Progress info */
.progress-info {
    background: #f0fdf4 !important;
    border: 1px solid #86efac !important;
    border-radius: 8px !important;
    padding: 0.75rem !important;
}

/* Dark mode support */
.dark .gradio-container {
    background: linear-gradient(135deg, #0f172a 0%, #1e293b 100%) !important;
}

.dark .card-style {
    background: rgba(30, 41, 59, 0.9) !important;
    border: 1px solid rgba(51, 65, 85, 0.5) !important;
    box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3) !important;
}

.dark .status-box {
    background: linear-gradient(135deg, #1e3a5f 0%, #1e293b 100%) !important;
    border: 1px solid #3b82f6 !important;
}

.dark .progress-info {
    background: #14532d !important;
    border: 1px solid #22c55e !important;
}

/* Accordion styling */
.settings-accordion {
    border-radius: 12px !important;
    overflow: hidden !important;
}

/* Result variants */
.variant-box {
    border: 2px solid #e2e8f0;
    border-radius: 12px;
    padding: 1rem;
    margin-bottom: 0.5rem;
    transition: all 0.2s ease;
}

.variant-box:hover {
    border-color: #667eea;
    box-shadow: 0 4px 12px rgba(102, 126, 234, 0.15);
}

/* Export buttons */
.export-btn {
    margin: 0.25rem !important;
}
"""

# Description types with prompts
DESCRIPTION_TYPES = {
    "en": {
        "Descriptive (Formal)": "Write a detailed and formal description of this image.",
        "Descriptive (Informal)": "Write a casual, friendly description of this image.",
        "Product Description": "Write a compelling product description for e-commerce based on this image.",
        "SEO Description": "Write an SEO-optimized description for this image, maximum 160 characters.",
        "Stable Diffusion Prompt": "Write a detailed Stable Diffusion prompt to recreate this image.",
        "MidJourney Prompt": "Write a MidJourney prompt to recreate this image.",
        "Booru Tags": "Write a list of Booru-style tags for this image, separated by commas.",
        "Art Critic Analysis": "Analyze this image like an art critic, discussing composition, style, color, lighting, and artistic elements.",
        "Social Media Caption": "Write an engaging social media caption for this image.",
        "Custom": ""
    },
    "ru": {
        "ÐžÐ¿Ð¸ÑÐ°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ (Ñ„Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹)": "ÐÐ°Ð¿Ð¸ÑˆÐ¸ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð¸ Ñ„Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ ÑÑ‚Ð¾Ð³Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ.",
        "ÐžÐ¿Ð¸ÑÐ°Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ð¹ (Ð½ÐµÑ„Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹)": "ÐÐ°Ð¿Ð¸ÑˆÐ¸ Ð½ÐµÐ¿Ñ€Ð¸Ð½ÑƒÐ¶Ð´Ñ‘Ð½Ð½Ð¾Ðµ, Ð´Ñ€ÑƒÐ¶ÐµÐ»ÑŽÐ±Ð½Ð¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ ÑÑ‚Ð¾Ð³Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ.",
        "ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ñ‚Ð¾Ð²Ð°Ñ€Ð°": "ÐÐ°Ð¿Ð¸ÑˆÐ¸ Ð¿Ñ€Ð¸Ð²Ð»ÐµÐºÐ°Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ñ‚Ð¾Ð²Ð°Ñ€Ð° Ð´Ð»Ñ Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚-Ð¼Ð°Ð³Ð°Ð·Ð¸Ð½Ð° Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ ÑÑ‚Ð¾Ð³Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ.",
        "SEO Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ": "ÐÐ°Ð¿Ð¸ÑˆÐ¸ SEO-Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð´Ð»Ñ ÑÑ‚Ð¾Ð³Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ, Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼ 160 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð².",
        "ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚ Stable Diffusion": "ÐÐ°Ð¿Ð¸ÑˆÐ¸ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ Ð´Ð»Ñ Stable Diffusion, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð²Ð¾ÑÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ ÑÑ‚Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ.",
        "ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚ MidJourney": "ÐÐ°Ð¿Ð¸ÑˆÐ¸ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ Ð´Ð»Ñ MidJourney, Ñ‡Ñ‚Ð¾Ð±Ñ‹ Ð²Ð¾ÑÑÐ¾Ð·Ð´Ð°Ñ‚ÑŒ ÑÑ‚Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ.",
        "Ð¢ÐµÐ³Ð¸ Booru": "ÐÐ°Ð¿Ð¸ÑˆÐ¸ ÑÐ¿Ð¸ÑÐ¾Ðº Ñ‚ÐµÐ³Ð¾Ð² Ð² ÑÑ‚Ð¸Ð»Ðµ Booru Ð´Ð»Ñ ÑÑ‚Ð¾Ð³Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ, Ñ€Ð°Ð·Ð´ÐµÐ»Ñ‘Ð½Ð½Ñ‹Ñ… Ð·Ð°Ð¿ÑÑ‚Ñ‹Ð¼Ð¸.",
        "ÐÐ½Ð°Ð»Ð¸Ð· Ð¸ÑÐºÑƒÑÑÑ‚Ð²Ð¾Ð²ÐµÐ´Ð°": "ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹ ÑÑ‚Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ ÐºÐ°Ðº Ð¸ÑÐºÑƒÑÑÑ‚Ð²Ð¾Ð²ÐµÐ´, Ð¾Ð±ÑÑƒÐ¶Ð´Ð°Ñ ÐºÐ¾Ð¼Ð¿Ð¾Ð·Ð¸Ñ†Ð¸ÑŽ, ÑÑ‚Ð¸Ð»ÑŒ, Ñ†Ð²ÐµÑ‚, Ð¾ÑÐ²ÐµÑ‰ÐµÐ½Ð¸Ðµ Ð¸ Ñ…ÑƒÐ´Ð¾Ð¶ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ðµ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ñ‹ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ.",
        "ÐŸÐ¾ÑÑ‚ Ð´Ð»Ñ ÑÐ¾Ñ†ÑÐµÑ‚ÐµÐ¹": "ÐÐ°Ð¿Ð¸ÑˆÐ¸ Ð¿Ñ€Ð¸Ð²Ð»ÐµÐºÐ°Ñ‚ÐµÐ»ÑŒÐ½ÑƒÑŽ Ð¿Ð¾Ð´Ð¿Ð¸ÑÑŒ Ð´Ð»Ñ ÑÐ¾Ñ†Ð¸Ð°Ð»ÑŒÐ½Ñ‹Ñ… ÑÐµÑ‚ÐµÐ¹ Ðº ÑÑ‚Ð¾Ð¼Ñƒ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸ÑŽ Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ.",
        "Ð¡Ð²Ð¾Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚": ""
    },
    "zh": {
        "æè¿°æ€§ï¼ˆæ­£å¼ï¼‰": "å†™ä¸€ä¸ªè¯¦ç»†æ­£å¼çš„å›¾åƒæè¿°ã€‚",
        "æè¿°æ€§ï¼ˆéžæ­£å¼ï¼‰": "å†™ä¸€ä¸ªè½»æ¾å‹å¥½çš„å›¾åƒæè¿°ã€‚",
        "äº§å“æè¿°": "æ ¹æ®è¿™å¼ å›¾ç‰‡ä¸ºç”µå•†å¹³å°å†™ä¸€ä¸ªå¸å¼•äººçš„äº§å“æè¿°ã€‚",
        "SEOæè¿°": "ä¸ºè¿™å¼ å›¾ç‰‡å†™ä¸€ä¸ªSEOä¼˜åŒ–çš„æè¿°ï¼Œæœ€å¤š160ä¸ªå­—ç¬¦ã€‚",
        "Stable Diffusionæç¤ºè¯": "å†™ä¸€ä¸ªè¯¦ç»†çš„Stable Diffusionæç¤ºè¯æ¥é‡çŽ°è¿™å¼ å›¾ç‰‡ã€‚",
        "MidJourneyæç¤ºè¯": "å†™ä¸€ä¸ªMidJourneyæç¤ºè¯æ¥é‡çŽ°è¿™å¼ å›¾ç‰‡ã€‚",
        "Booruæ ‡ç­¾": "ä¸ºè¿™å¼ å›¾ç‰‡å†™ä¸€ä¸ªBoorué£Žæ ¼çš„æ ‡ç­¾åˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš”ã€‚",
        "è‰ºæœ¯è¯„è®ºåˆ†æž": "åƒè‰ºæœ¯è¯„è®ºå®¶ä¸€æ ·åˆ†æžè¿™å¼ å›¾ç‰‡ï¼Œè®¨è®ºæž„å›¾ã€é£Žæ ¼ã€è‰²å½©ã€å…‰çº¿å’Œè‰ºæœ¯å…ƒç´ ã€‚",
        "ç¤¾äº¤åª’ä½“æ–‡æ¡ˆ": "ä¸ºè¿™å¼ å›¾ç‰‡å†™ä¸€ä¸ªå¸å¼•äººçš„ç¤¾äº¤åª’ä½“æ–‡æ¡ˆã€‚",
        "è‡ªå®šä¹‰": ""
    }
}

# Description lengths
DESCRIPTION_LENGTHS = {
    "en": {
        "Any": "",
        "Very Short (1-2 sentences)": "Keep it very short, 1-2 sentences maximum.",
        "Short (3-4 sentences)": "Keep it short, 3-4 sentences.",
        "Medium (1 paragraph)": "Write a medium-length description, about one paragraph.",
        "Long (2-3 paragraphs)": "Write a detailed description, 2-3 paragraphs.",
        "Very Long (comprehensive)": "Write a comprehensive and very detailed description."
    },
    "ru": {
        "Ð›ÑŽÐ±Ð°Ñ": "",
        "ÐžÑ‡ÐµÐ½ÑŒ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ°Ñ (1-2 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ)": "Ð¡Ð´ÐµÐ»Ð°Ð¹ Ð¾Ñ‡ÐµÐ½ÑŒ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¾, Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼ 1-2 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ.",
        "ÐšÐ¾Ñ€Ð¾Ñ‚ÐºÐ°Ñ (3-4 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ)": "Ð¡Ð´ÐµÐ»Ð°Ð¹ ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐ¾, 3-4 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ñ.",
        "Ð¡Ñ€ÐµÐ´Ð½ÑÑ (1 Ð°Ð±Ð·Ð°Ñ†)": "ÐÐ°Ð¿Ð¸ÑˆÐ¸ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ ÑÑ€ÐµÐ´Ð½ÐµÐ¹ Ð´Ð»Ð¸Ð½Ñ‹, Ð¾ÐºÐ¾Ð»Ð¾ Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð°Ð±Ð·Ð°Ñ†Ð°.",
        "Ð”Ð»Ð¸Ð½Ð½Ð°Ñ (2-3 Ð°Ð±Ð·Ð°Ñ†Ð°)": "ÐÐ°Ð¿Ð¸ÑˆÐ¸ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ, 2-3 Ð°Ð±Ð·Ð°Ñ†Ð°.",
        "ÐžÑ‡ÐµÐ½ÑŒ Ð´Ð»Ð¸Ð½Ð½Ð°Ñ (Ð¿Ð¾Ð´Ñ€Ð¾Ð±Ð½Ð°Ñ)": "ÐÐ°Ð¿Ð¸ÑˆÐ¸ Ð¸ÑÑ‡ÐµÑ€Ð¿Ñ‹Ð²Ð°ÑŽÑ‰ÐµÐµ Ð¸ Ð¾Ñ‡ÐµÐ½ÑŒ Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ."
    },
    "zh": {
        "ä»»æ„": "",
        "éžå¸¸çŸ­ï¼ˆ1-2å¥ï¼‰": "ä¿æŒéžå¸¸ç®€çŸ­ï¼Œæœ€å¤š1-2å¥ã€‚",
        "çŸ­ï¼ˆ3-4å¥ï¼‰": "ä¿æŒç®€çŸ­ï¼Œ3-4å¥ã€‚",
        "ä¸­ç­‰ï¼ˆ1æ®µï¼‰": "å†™ä¸€ä¸ªä¸­ç­‰é•¿åº¦çš„æè¿°ï¼Œå¤§çº¦ä¸€æ®µã€‚",
        "é•¿ï¼ˆ2-3æ®µï¼‰": "å†™ä¸€ä¸ªè¯¦ç»†çš„æè¿°ï¼Œ2-3æ®µã€‚",
        "éžå¸¸é•¿ï¼ˆå…¨é¢ï¼‰": "å†™ä¸€ä¸ªå…¨é¢ä¸”éžå¸¸è¯¦ç»†çš„æè¿°ã€‚"
    }
}

# Multi-language support
TRANSLATIONS = {
    "en": {
        "title": "Qwen VL Image Description Generator",
        "header": "ðŸ–¼ï¸ Image Description Generator based on Qwen Vision Language Models",
        "subtitle": "Upload an image and enter a prompt to generate a description using Qwen VL models.",
        "language": "Language",
        "language_info": "Select language",
        "model_selection": "Model Selection",
        "model_info": "Select a model for generating descriptions",
        "advanced_params": "âš™ï¸ Advanced Parameters",
        "max_tokens": "Max New Tokens",
        "max_tokens_info": "Maximum number of tokens to generate",
        "temperature": "Temperature",
        "temperature_info": "Controls randomness of generation",
        "top_p": "Top-p (nucleus sampling)",
        "top_p_info": "Probability threshold for token sampling",
        "top_k": "Top-k",
        "top_k_info": "Number of most probable tokens to consider",
        "seed": "Seed",
        "seed_info": "Seed for reproducibility (-1 for random)",
        "random_seed_btn": "ðŸŽ² Random Seed",
        "single_processing": "ðŸ“„ Single Processing",
        "batch_processing": "ðŸ“š Batch Processing",
        "upload_image": "Upload Image",
        "image_url": "Or enter Image URL",
        "image_url_placeholder": "https://example.com/image.jpg",
        "prompt": "Prompt",
        "prompt_placeholder": "For example: Create a product description for online store",
        "generate_btn": "ðŸš€ Generate Description",
        "result": "Result",
        "upload_images": "Upload Images",
        "prompts_multiline": "Prompts (one per line)",
        "prompts_placeholder": "Create a product description for online store\nCreate SEO Description for product\n...",
        "prompts_info": "Specify one prompt for all images or one prompt per image",
        "process_batch_btn": "ðŸš€ Process Batch",
        "results": "Results",
        "examples_title": "ðŸ’¡ Example Prompts:",
        "example_1": "Create a product description for online store",
        "example_2": "Create an SEO description for a product with a maximum of 160 characters.",
        "example_3": "Create an attractive product description for marketplace",
        "example_4": "Describe image in detail for product catalog",
        "error_no_image": "Please upload an image or provide an image URL",
        "error_no_prompt": "Please enter a prompt",
        "error_no_images": "Please upload images",
        "error_no_prompts": "Please enter prompts (one per line)",
        "error_prompt_mismatch": "Number of prompts ({}) does not match number of images ({}). Specify either one prompt for all images or one prompt per image.",
        "error_generation": "Error generating description: {}",
        "error_url_load": "Error loading image from URL: {}",
        "loading_model": "Loading model: {}",
        "model_loaded": "Model {} successfully loaded on {}",
        "image_label": "=== Image {}: {} ===",
        "prompt_label": "Prompt: {}",
        "result_label": "Result: {}",
        "model_size_warning": "âš ï¸ Note: Large models (8B+) may use CPU offloading if GPU memory is insufficient, which can slow down generation.",
        "quantization": "Quantization",
        "quantization_info": "Memory optimization (4-bit = ~75% less VRAM)",
        "quant_4bit": "4-bit (Recommended)",
        "quant_8bit": "8-bit (Better quality)",
        "quant_none": "None (Full precision)",
        "description_type": "Description Type",
        "description_type_info": "Select the type/style of description",
        "description_length": "Description Length",
        "description_length_info": "Select desired length",
        "num_variants": "Number of Variants",
        "num_variants_info": "Generate multiple description variants",
        "custom_prompt_override": "Custom Prompt (overrides type selection)",
        "custom_prompt_placeholder": "Enter your custom prompt here...",
        "status": "Status",
        "processing_time": "Processing time",
        "generating": "â³ Generating...",
        "stop_btn": "ðŸ›‘ Stop",
        "save_results": "ðŸ’¾ Save Results",
        "output_folder": "Output Folder Name",
        "output_folder_placeholder": "my_dataset",
        "export_format": "Export Format",
        "export_txt": "TXT (one file per image)",
        "export_json": "JSON (all results)",
        "export_csv": "CSV (table format)",
        "variant": "Variant",
        "copy_btn": "ðŸ“‹ Copy",
        "download_btn": "â¬‡ï¸ Download",
        "generation_complete": "âœ… Generation complete!",
        "seconds": "seconds",
        "processing_image": "Processing image",
        "of": "of",
        "extra_options": "Extra Options",
        "extra_options_info": "Additional modifiers for description",
        "character_name": "Character/Person Name",
        "character_name_placeholder": "e.g., John, Alice, or leave empty",
        "character_name_info": "If provided, will use this name instead of generic terms",
        "prompt_preset": "Prompt Preset",
        "prompt_preset_info": "Load a preset from prompts/ folder",
        "refresh_presets": "Refresh",
        "memory_usage": "Memory Usage",
        "download_result": "Download Result",
        "generation_stopped": "Generation stopped by user",
        "stopping": "Stopping..."
    },
    "ru": {
        "title": "Ð“ÐµÐ½ÐµÑ€Ð°Ñ‚Ð¾Ñ€ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ð¹ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ Qwen VL",
        "header": "ðŸ–¼ï¸ Ð“ÐµÐ½ÐµÑ€Ð°Ñ‚Ð¾Ñ€ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ð¹ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Qwen Vision Language Models",
        "subtitle": "Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð¸ Ð²Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð¿Ñ€Ð¾Ð¼Ñ‚ Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Qwen VL.",
        "language": "Ð¯Ð·Ñ‹Ðº",
        "language_info": "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ ÑÐ·Ñ‹Ðº",
        "model_selection": "Ð’Ñ‹Ð±Ð¾Ñ€ Ð¼Ð¾Ð´ÐµÐ»Ð¸",
        "model_info": "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ð¹",
        "advanced_params": "âš™ï¸ Ð Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð½Ñ‹Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹",
        "max_tokens": "ÐœÐ°ÐºÑ. ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð½Ð¾Ð²Ñ‹Ñ… Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²",
        "max_tokens_info": "ÐœÐ°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð¾Ðµ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð´Ð»Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸",
        "temperature": "Ð¢ÐµÐ¼Ð¿ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð°",
        "temperature_info": "ÐšÐ¾Ð½Ñ‚Ñ€Ð¾Ð»Ð¸Ñ€ÑƒÐµÑ‚ ÑÐ»ÑƒÑ‡Ð°Ð¹Ð½Ð¾ÑÑ‚ÑŒ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸",
        "top_p": "Top-p (nucleus sampling)",
        "top_p_info": "Ð’ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ÑÑ‚Ð½Ñ‹Ð¹ Ð¿Ð¾Ñ€Ð¾Ð³ Ð´Ð»Ñ Ð²Ñ‹Ð±Ð¾Ñ€ÐºÐ¸ Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð²",
        "top_k": "Top-k",
        "top_k_info": "ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð½Ð°Ð¸Ð±Ð¾Ð»ÐµÐµ Ð²ÐµÑ€Ð¾ÑÑ‚Ð½Ñ‹Ñ… Ñ‚Ð¾ÐºÐµÐ½Ð¾Ð² Ð´Ð»Ñ Ñ€Ð°ÑÑÐ¼Ð¾Ñ‚Ñ€ÐµÐ½Ð¸Ñ",
        "seed": "Seed",
        "seed_info": "Seed Ð´Ð»Ñ Ð²Ð¾ÑÐ¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ð¼Ð¾ÑÑ‚Ð¸ (-1 Ð´Ð»Ñ ÑÐ»ÑƒÑ‡Ð°Ð¹Ð½Ð¾Ð³Ð¾)",
        "random_seed_btn": "ðŸŽ² Ð¡Ð»ÑƒÑ‡Ð°Ð¹Ð½Ñ‹Ð¹ seed",
        "single_processing": "ðŸ“„ ÐžÐ´Ð¸Ð½Ð¾Ñ‡Ð½Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ°",
        "batch_processing": "ðŸ“š ÐŸÐ°ÐºÐµÑ‚Ð½Ð°Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ°",
        "upload_image": "Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ",
        "image_url": "Ð˜Ð»Ð¸ Ð²Ð²ÐµÐ´Ð¸Ñ‚Ðµ URL Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ",
        "image_url_placeholder": "https://example.com/image.jpg",
        "prompt": "ÐŸÑ€Ð¾Ð¼Ñ‚",
        "prompt_placeholder": "ÐÐ°Ð¿Ñ€Ð¸Ð¼ÐµÑ€: Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ñ‚Ð¾Ð²Ð°Ñ€Ð° Ð´Ð»Ñ Ð¾Ð½Ð»Ð°Ð¹Ð½ Ð¼Ð°Ð³Ð°Ð·Ð¸Ð½Ð°",
        "generate_btn": "ðŸš€ Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ",
        "result": "Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚",
        "upload_images": "Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ",
        "prompts_multiline": "ÐŸÑ€Ð¾Ð¼Ñ‚Ñ‹ (Ð¿Ð¾ Ð¾Ð´Ð½Ð¾Ð¼Ñƒ Ð½Ð° ÑÑ‚Ñ€Ð¾ÐºÑƒ)",
        "prompts_placeholder": "Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ñ‚Ð¾Ð²Ð°Ñ€Ð° Ð´Ð»Ñ Ð¾Ð½Ð»Ð°Ð¹Ð½ Ð¼Ð°Ð³Ð°Ð·Ð¸Ð½Ð°\nÐ¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ SEO-Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð´Ð»Ñ Ñ‚Ð¾Ð²Ð°Ñ€Ð°\n...",
        "prompts_info": "Ð£ÐºÐ°Ð¶Ð¸Ñ‚Ðµ Ð¾Ð´Ð¸Ð½ Ð¿Ñ€Ð¾Ð¼Ñ‚ Ð´Ð»Ñ Ð²ÑÐµÑ… Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ Ð¸Ð»Ð¸ Ð¿Ð¾ Ð¾Ð´Ð½Ð¾Ð¼Ñƒ Ð¿Ñ€Ð¾Ð¼Ñ‚Ñƒ Ð½Ð° ÐºÐ°Ð¶Ð´Ð¾Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ",
        "process_batch_btn": "ðŸš€ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ð¿Ð°ÐºÐµÑ‚",
        "results": "Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹",
        "examples_title": "ðŸ’¡ ÐŸÑ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð¿Ñ€Ð¾Ð¼Ñ‚Ð¾Ð²:",
        "example_1": "Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ñ‚Ð¾Ð²Ð°Ñ€Ð° ''  Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ",
        "example_2": "Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ SEO-Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð´Ð»Ñ Ñ‚Ð¾Ð²Ð°Ñ€Ð° Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼ 160 ÑÐ¸Ð¼Ð²Ð¾Ð»Ð¾Ð² Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ",
        "example_3": "Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð¿Ñ€Ð¸Ð²Ð»ÐµÐºÐ°Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ðµ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð° Ð´Ð»Ñ Ð¼Ð°Ñ€ÐºÐµÑ‚Ð¿Ð»ÐµÐ¹ÑÐ° Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ",
        "example_4": "Ð”ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¾ Ð¾Ð¿Ð¸ÑÐ°Ñ‚ÑŒ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð´Ð»Ñ ÐºÐ°Ñ‚Ð°Ð»Ð¾Ð³Ð° Ñ‚Ð¾Ð²Ð°Ñ€Ð¾Ð² Ð½Ð° Ñ€ÑƒÑÑÐºÐ¾Ð¼ ÑÐ·Ñ‹ÐºÐµ",
        "error_no_image": "ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð¸Ð»Ð¸ ÑƒÐºÐ°Ð¶Ð¸Ñ‚Ðµ URL Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ",
        "error_no_prompt": "ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð²Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð¿Ñ€Ð¾Ð¼Ñ‚",
        "error_no_images": "ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ",
        "error_no_prompts": "ÐŸÐ¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°, Ð²Ð²ÐµÐ´Ð¸Ñ‚Ðµ Ð¿Ñ€Ð¾Ð¼Ñ‚Ñ‹ (Ð¿Ð¾ Ð¾Ð´Ð½Ð¾Ð¼Ñƒ Ð½Ð° ÑÑ‚Ñ€Ð¾ÐºÑƒ)",
        "error_prompt_mismatch": "ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¿Ñ€Ð¾Ð¼Ñ‚Ð¾Ð² ({}) Ð½Ðµ ÑÐ¾Ð²Ð¿Ð°Ð´Ð°ÐµÑ‚ Ñ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾Ð¼ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹ ({}). Ð£ÐºÐ°Ð¶Ð¸Ñ‚Ðµ Ð»Ð¸Ð±Ð¾ Ð¾Ð´Ð¸Ð½ Ð¿Ñ€Ð¾Ð¼Ñ‚ Ð´Ð»Ñ Ð²ÑÐµÑ… Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹, Ð»Ð¸Ð±Ð¾ Ð¿Ð¾ Ð¾Ð´Ð½Ð¾Ð¼Ñƒ Ð¿Ñ€Ð¾Ð¼Ñ‚Ñƒ Ð½Ð° ÐºÐ°Ð¶Ð´Ð¾Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ.",
        "error_generation": "ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ: {}",
        "error_url_load": "ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð¿Ð¾ URL: {}",
        "loading_model": "Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸: {}",
        "model_loaded": "ÐœÐ¾Ð´ÐµÐ»ÑŒ {} ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð° Ð½Ð° {}",
        "image_label": "=== Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ {}: {} ===",
        "prompt_label": "ÐŸÑ€Ð¾Ð¼Ñ‚: {}",
        "result_label": "Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚: {}",
        "model_size_warning": "âš ï¸ ÐŸÑ€Ð¸Ð¼ÐµÑ‡Ð°Ð½Ð¸Ðµ: Ð‘Ð¾Ð»ÑŒÑˆÐ¸Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ (8B+) Ð¼Ð¾Ð³ÑƒÑ‚ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ð²Ñ‹Ð³Ñ€ÑƒÐ·ÐºÑƒ Ð½Ð° CPU Ð¿Ñ€Ð¸ Ð½ÐµÐ´Ð¾ÑÑ‚Ð°Ñ‚ÐºÐµ Ð¿Ð°Ð¼ÑÑ‚Ð¸ GPU, Ñ‡Ñ‚Ð¾ Ð¼Ð¾Ð¶ÐµÑ‚ Ð·Ð°Ð¼ÐµÐ´Ð»Ð¸Ñ‚ÑŒ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸ÑŽ.",
        "quantization": "ÐšÐ²Ð°Ð½Ñ‚Ð¸Ð·Ð°Ñ†Ð¸Ñ",
        "quantization_info": "ÐžÐ¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¿Ð°Ð¼ÑÑ‚Ð¸ (4-bit = ~75% Ð¼ÐµÐ½ÑŒÑˆÐµ Ð²Ð¸Ð´ÐµÐ¾Ð¿Ð°Ð¼ÑÑ‚Ð¸)",
        "quant_4bit": "4-bit (Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐµÑ‚ÑÑ)",
        "quant_8bit": "8-bit (Ð›ÑƒÑ‡ÑˆÐµ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾)",
        "quant_none": "ÐÐµÑ‚ (ÐŸÐ¾Ð»Ð½Ð°Ñ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ)",
        "description_type": "Ð¢Ð¸Ð¿ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ",
        "description_type_info": "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ñ‚Ð¸Ð¿/ÑÑ‚Ð¸Ð»ÑŒ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ",
        "description_length": "Ð”Ð»Ð¸Ð½Ð° Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ",
        "description_length_info": "Ð’Ñ‹Ð±ÐµÑ€Ð¸Ñ‚Ðµ Ð¶ÐµÐ»Ð°ÐµÐ¼ÑƒÑŽ Ð´Ð»Ð¸Ð½Ñƒ",
        "num_variants": "ÐšÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ð¾Ð²",
        "num_variants_info": "Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ð¾Ð² Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ",
        "custom_prompt_override": "Ð¡Ð²Ð¾Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ (Ð¿ÐµÑ€ÐµÐ¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÑ‚ Ð²Ñ‹Ð±Ð¾Ñ€ Ñ‚Ð¸Ð¿Ð°)",
        "custom_prompt_placeholder": "Ð’Ð²ÐµÐ´Ð¸Ñ‚Ðµ ÑÐ²Ð¾Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ Ð·Ð´ÐµÑÑŒ...",
        "status": "Ð¡Ñ‚Ð°Ñ‚ÑƒÑ",
        "processing_time": "Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸",
        "generating": "â³ Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ...",
        "stop_btn": "ðŸ›‘ ÐžÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ",
        "save_results": "ðŸ’¾ Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹",
        "output_folder": "ÐÐ°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð¿Ð°Ð¿ÐºÐ¸",
        "output_folder_placeholder": "Ð¼Ð¾Ð¹_Ð´Ð°Ñ‚Ð°ÑÐµÑ‚",
        "export_format": "Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð°",
        "export_txt": "TXT (Ð¾Ð´Ð¸Ð½ Ñ„Ð°Ð¹Ð» Ð½Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ)",
        "export_json": "JSON (Ð²ÑÐµ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹)",
        "export_csv": "CSV (Ñ‚Ð°Ð±Ð»Ð¸Ñ‡Ð½Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚)",
        "variant": "Ð’Ð°Ñ€Ð¸Ð°Ð½Ñ‚",
        "copy_btn": "ðŸ“‹ ÐšÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ",
        "download_btn": "â¬‡ï¸ Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ",
        "generation_complete": "âœ… Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð°!",
        "seconds": "ÑÐµÐºÑƒÐ½Ð´",
        "processing_image": "ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ",
        "of": "Ð¸Ð·",
        "extra_options": "Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¾Ð¿Ñ†Ð¸Ð¸",
        "extra_options_info": "Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¼Ð¾Ð´Ð¸Ñ„Ð¸ÐºÐ°Ñ‚Ð¾Ñ€Ñ‹ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ",
        "character_name": "Ð˜Ð¼Ñ Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð¶Ð°/Ñ‡ÐµÐ»Ð¾Ð²ÐµÐºÐ°",
        "character_name_placeholder": "Ð½Ð°Ð¿Ñ€., Ð˜Ð²Ð°Ð½, ÐÐ»Ð¸ÑÐ°, Ð¸Ð»Ð¸ Ð¾ÑÑ‚Ð°Ð²ÑŒÑ‚Ðµ Ð¿ÑƒÑÑ‚Ñ‹Ð¼",
        "character_name_info": "Ð•ÑÐ»Ð¸ ÑƒÐºÐ°Ð·Ð°Ð½Ð¾, Ð±ÑƒÐ´ÐµÑ‚ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒÑÑ Ð²Ð¼ÐµÑÑ‚Ð¾ Ð¾Ð±Ñ‰Ð¸Ñ… Ñ‚ÐµÑ€Ð¼Ð¸Ð½Ð¾Ð²",
        "prompt_preset": "ÐŸÑ€ÐµÑÐµÑ‚ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð°",
        "prompt_preset_info": "Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð¿Ñ€ÐµÑÐµÑ‚ Ð¸Ð· Ð¿Ð°Ð¿ÐºÐ¸ prompts/",
        "refresh_presets": "ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ",
        "memory_usage": "Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð¿Ð°Ð¼ÑÑ‚Ð¸",
        "download_result": "Ð¡ÐºÐ°Ñ‡Ð°Ñ‚ÑŒ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚",
        "generation_stopped": "Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¼",
        "stopping": "ÐžÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ°..."
    },
    "zh": {
        "title": "Qwen VL å›¾åƒæè¿°ç”Ÿæˆå™¨",
        "header": "ðŸ–¼ï¸ åŸºäºŽ Qwen Vision Language Models çš„å›¾åƒæè¿°ç”Ÿæˆå™¨",
        "subtitle": "ä¸Šä¼ å›¾åƒå¹¶è¾“å…¥æç¤ºè¯ï¼Œä½¿ç”¨ Qwen VL æ¨¡åž‹ç”Ÿæˆæè¿°ã€‚",
        "language": "è¯­è¨€",
        "language_info": "é€‰æ‹©è¯­è¨€",
        "model_selection": "æ¨¡åž‹é€‰æ‹©",
        "model_info": "é€‰æ‹©ç”¨äºŽç”Ÿæˆæè¿°çš„æ¨¡åž‹",
        "advanced_params": "âš™ï¸ é«˜çº§å‚æ•°",
        "max_tokens": "æœ€å¤§æ–°ä»¤ç‰Œæ•°",
        "max_tokens_info": "ç”Ÿæˆçš„æœ€å¤§ä»¤ç‰Œæ•°",
        "temperature": "æ¸©åº¦",
        "temperature_info": "æŽ§åˆ¶ç”Ÿæˆçš„éšæœºæ€§",
        "top_p": "Top-pï¼ˆæ ¸é‡‡æ ·ï¼‰",
        "top_p_info": "ä»¤ç‰Œé‡‡æ ·çš„æ¦‚çŽ‡é˜ˆå€¼",
        "top_k": "Top-k",
        "top_k_info": "è€ƒè™‘çš„æœ€å¯èƒ½ä»¤ç‰Œæ•°",
        "seed": "éšæœºç§å­",
        "seed_info": "ç”¨äºŽå¯é‡çŽ°æ€§çš„ç§å­ï¼ˆ-1 è¡¨ç¤ºéšæœºï¼‰",
        "random_seed_btn": "ðŸŽ² éšæœºç§å­",
        "single_processing": "ðŸ“„ å•å¼ å¤„ç†",
        "batch_processing": "ðŸ“š æ‰¹é‡å¤„ç†",
        "upload_image": "ä¸Šä¼ å›¾åƒ",
        "image_url": "æˆ–è¾“å…¥å›¾åƒURL",
        "image_url_placeholder": "https://example.com/image.jpg",
        "prompt": "æç¤ºè¯",
        "prompt_placeholder": "ä¾‹å¦‚ï¼šä¸ºåœ¨çº¿å•†åº—åˆ›å»ºäº§å“æè¿°",
        "generate_btn": "ðŸš€ ç”Ÿæˆæè¿°",
        "result": "ç»“æžœ",
        "upload_images": "ä¸Šä¼ å›¾åƒ",
        "prompts_multiline": "æç¤ºè¯ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
        "prompts_placeholder": "ä¸ºåœ¨çº¿å•†åº—åˆ›å»ºäº§å“æè¿°\nä¸ºäº§å“åˆ›å»ºSEOæè¿°\n...",
        "prompts_info": "ä¸ºæ‰€æœ‰å›¾åƒæŒ‡å®šä¸€ä¸ªæç¤ºè¯ï¼Œæˆ–ä¸ºæ¯ä¸ªå›¾åƒæŒ‡å®šä¸€ä¸ªæç¤ºè¯",
        "process_batch_btn": "ðŸš€ å¤„ç†æ‰¹æ¬¡",
        "results": "ç»“æžœ",
        "examples_title": "ðŸ’¡ ç¤ºä¾‹æç¤ºè¯ï¼š",
        "example_1": "ä¸ºåœ¨çº¿å•†åº—åˆ›å»ºäº§å“æè¿°",
        "example_2": "ä¸ºäº§å“åˆ›å»ºSEOæè¿°æœ€å¤š 160 ä¸ªå­—ç¬¦",
        "example_3": "ä¸ºå¸‚åœºåˆ›å»ºæœ‰å¸å¼•åŠ›çš„äº§å“æè¿°",
        "example_4": "è¯¦ç»†æè¿°äº§å“ç›®å½•çš„å›¾åƒ",
        "error_no_image": "è¯·ä¸Šä¼ å›¾åƒæˆ–æä¾›å›¾åƒURL",
        "error_no_prompt": "è¯·è¾“å…¥æç¤ºè¯",
        "error_no_images": "è¯·ä¸Šä¼ å›¾åƒ",
        "error_no_prompts": "è¯·è¾“å…¥æç¤ºè¯ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
        "error_prompt_mismatch": "æç¤ºè¯æ•°é‡ï¼ˆ{}ï¼‰ä¸Žå›¾åƒæ•°é‡ï¼ˆ{}ï¼‰ä¸åŒ¹é…ã€‚è¯·ä¸ºæ‰€æœ‰å›¾åƒæŒ‡å®šä¸€ä¸ªæç¤ºè¯ï¼Œæˆ–ä¸ºæ¯ä¸ªå›¾åƒæŒ‡å®šä¸€ä¸ªæç¤ºè¯ã€‚",
        "error_generation": "ç”Ÿæˆæè¿°æ—¶å‡ºé”™ï¼š{}",
        "error_url_load": "ä»ŽURLåŠ è½½å›¾åƒæ—¶å‡ºé”™ï¼š{}",
        "loading_model": "æ­£åœ¨åŠ è½½æ¨¡åž‹ï¼š{}",
        "model_loaded": "æ¨¡åž‹ {} å·²æˆåŠŸåŠ è½½åˆ° {}",
        "image_label": "=== å›¾åƒ {}: {} ===",
        "prompt_label": "æç¤ºè¯ï¼š{}",
        "result_label": "ç»“æžœï¼š{}",
        "model_size_warning": "âš ï¸ æ³¨æ„ï¼šå¦‚æžœ GPU å†…å­˜ä¸è¶³ï¼Œå¤§åž‹æ¨¡åž‹ï¼ˆ8B+ï¼‰å¯èƒ½ä¼šä½¿ç”¨ CPU å¸è½½ï¼Œè¿™å¯èƒ½ä¼šå‡æ…¢ç”Ÿæˆé€Ÿåº¦ã€‚",
        "quantization": "é‡åŒ–",
        "quantization_info": "å†…å­˜ä¼˜åŒ–ï¼ˆ4ä½ = å‡å°‘çº¦75%æ˜¾å­˜ï¼‰",
        "quant_4bit": "4ä½ï¼ˆæŽ¨èï¼‰",
        "quant_8bit": "8ä½ï¼ˆæ›´é«˜è´¨é‡ï¼‰",
        "quant_none": "æ— ï¼ˆå…¨ç²¾åº¦ï¼‰",
        "description_type": "æè¿°ç±»åž‹",
        "description_type_info": "é€‰æ‹©æè¿°ç±»åž‹/é£Žæ ¼",
        "description_length": "æè¿°é•¿åº¦",
        "description_length_info": "é€‰æ‹©æ‰€éœ€é•¿åº¦",
        "num_variants": "å˜ä½“æ•°é‡",
        "num_variants_info": "ç”Ÿæˆå¤šä¸ªæè¿°å˜ä½“",
        "custom_prompt_override": "è‡ªå®šä¹‰æç¤ºè¯ï¼ˆè¦†ç›–ç±»åž‹é€‰æ‹©ï¼‰",
        "custom_prompt_placeholder": "åœ¨æ­¤è¾“å…¥æ‚¨çš„è‡ªå®šä¹‰æç¤ºè¯...",
        "status": "çŠ¶æ€",
        "processing_time": "å¤„ç†æ—¶é—´",
        "generating": "â³ ç”Ÿæˆä¸­...",
        "stop_btn": "ðŸ›‘ åœæ­¢",
        "save_results": "ðŸ’¾ ä¿å­˜ç»“æžœ",
        "output_folder": "è¾“å‡ºæ–‡ä»¶å¤¹åç§°",
        "output_folder_placeholder": "æˆ‘çš„æ•°æ®é›†",
        "export_format": "å¯¼å‡ºæ ¼å¼",
        "export_txt": "TXTï¼ˆæ¯å¼ å›¾ç‰‡ä¸€ä¸ªæ–‡ä»¶ï¼‰",
        "export_json": "JSONï¼ˆæ‰€æœ‰ç»“æžœï¼‰",
        "export_csv": "CSVï¼ˆè¡¨æ ¼æ ¼å¼ï¼‰",
        "variant": "å˜ä½“",
        "copy_btn": "ðŸ“‹ å¤åˆ¶",
        "download_btn": "â¬‡ï¸ ä¸‹è½½",
        "generation_complete": "âœ… ç”Ÿæˆå®Œæˆï¼",
        "seconds": "ç§’",
        "processing_image": "å¤„ç†å›¾åƒ",
        "of": "/",
        "extra_options": "é¢å¤–é€‰é¡¹",
        "extra_options_info": "æè¿°çš„é¢å¤–ä¿®é¥°ç¬¦",
        "character_name": "è§’è‰²/äººç‰©åç§°",
        "character_name_placeholder": "ä¾‹å¦‚ï¼šå°æ˜Žã€å°çº¢ï¼Œæˆ–ç•™ç©º",
        "character_name_info": "å¦‚æžœæä¾›ï¼Œå°†ä½¿ç”¨æ­¤åç§°ä»£æ›¿é€šç”¨æœ¯è¯­",
        "prompt_preset": "æç¤ºè¯é¢„è®¾",
        "prompt_preset_info": "ä»Žprompts/æ–‡ä»¶å¤¹åŠ è½½é¢„è®¾",
        "refresh_presets": "åˆ·æ–°",
        "memory_usage": "å†…å­˜ä½¿ç”¨",
        "download_result": "ä¸‹è½½ç»“æžœ",
        "generation_stopped": "ç”¨æˆ·åœæ­¢äº†ç”Ÿæˆ",
        "stopping": "åœæ­¢ä¸­..."
    }
}

# Default language
current_language = "ru"

def get_text(key: str) -> str:
    """Get translated text for the current language"""
    return TRANSLATIONS[current_language].get(key, key)

def get_description_types() -> list:
    """Get description types for current language"""
    return list(DESCRIPTION_TYPES.get(current_language, DESCRIPTION_TYPES["en"]).keys())

def get_description_lengths() -> list:
    """Get description lengths for current language"""
    return list(DESCRIPTION_LENGTHS.get(current_language, DESCRIPTION_LENGTHS["en"]).keys())

def get_extra_options(is_video: bool = False) -> list:
    """Get extra options for current language and media type"""
    options_dict = EXTRA_OPTIONS_VIDEO if is_video else EXTRA_OPTIONS
    return list(options_dict.get(current_language, options_dict["en"]).keys())

def get_extra_option_prompt(option: str, is_video: bool = False) -> str:
    """Get the prompt text for an extra option"""
    options_dict = EXTRA_OPTIONS_VIDEO if is_video else EXTRA_OPTIONS
    lang_options = options_dict.get(current_language, options_dict["en"])
    return lang_options.get(option, "")

def build_prompt(
    description_type: str,
    description_length: str,
    custom_prompt: str,
    base_prompt: str = "",
    extra_options: list = None,
    character_name: str = "",
    is_video: bool = False
) -> str:
    """Build the final prompt based on type, length, custom input, extra options and character name.
    Automatically replaces 'image' with 'video' when is_video=True for context-aware prompts."""
    # If custom prompt is provided, use it (but still add character name if present)
    if custom_prompt and custom_prompt.strip():
        final_prompt = custom_prompt.strip()
    else:
        # Get type prompt
        types_dict = DESCRIPTION_TYPES.get(current_language, DESCRIPTION_TYPES["en"])
        type_prompt = types_dict.get(description_type, "")

        # If type is Custom, use base prompt
        if not type_prompt:
            if is_video:
                type_prompt = base_prompt if base_prompt else "Describe this video."
            else:
                type_prompt = base_prompt if base_prompt else "Describe this image."

        # Get length modifier
        lengths_dict = DESCRIPTION_LENGTHS.get(current_language, DESCRIPTION_LENGTHS["en"])
        length_modifier = lengths_dict.get(description_length, "")

        # Combine type and length
        if length_modifier:
            final_prompt = f"{type_prompt} {length_modifier}"
        else:
            final_prompt = type_prompt

    # Context-aware: Replace "image" with "video" when processing video
    if is_video:
        # English replacements
        final_prompt = final_prompt.replace(" image.", " video.")
        final_prompt = final_prompt.replace(" image ", " video ")
        final_prompt = final_prompt.replace("this image", "this video")
        final_prompt = final_prompt.replace("the image", "the video")
        final_prompt = final_prompt.replace("an image", "a video")
        # Russian replacements
        final_prompt = final_prompt.replace("Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ", "Ð²Ð¸Ð´ÐµÐ¾")
        final_prompt = final_prompt.replace("Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¸", "Ð²Ð¸Ð´ÐµÐ¾")
        final_prompt = final_prompt.replace("Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ", "Ð²Ð¸Ð´ÐµÐ¾")
        # Chinese replacements
        final_prompt = final_prompt.replace("å›¾ç‰‡", "è§†é¢‘")
        final_prompt = final_prompt.replace("å›¾åƒ", "è§†é¢‘")

    # Add character name instruction if provided
    if character_name and character_name.strip():
        name = character_name.strip()
        media_term_ru = "Ð²Ð¸Ð´ÐµÐ¾" if is_video else "Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¸"
        media_term_zh = "è§†é¢‘" if is_video else "å›¾ç‰‡"
        media_term_en = "video" if is_video else "image"

        if current_language == "ru":
            final_prompt += f" Ð•ÑÐ»Ð¸ Ð½Ð° {media_term_ru} ÐµÑÑ‚ÑŒ Ñ‡ÐµÐ»Ð¾Ð²ÐµÐº Ð¸Ð»Ð¸ Ð¿ÐµÑ€ÑÐ¾Ð½Ð°Ð¶, Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð¸Ð¼Ñ '{name}' Ð²Ð¼ÐµÑÑ‚Ð¾ Ð¾Ð±Ñ‰Ð¸Ñ… Ñ‚ÐµÑ€Ð¼Ð¸Ð½Ð¾Ð²."
        elif current_language == "zh":
            final_prompt += f" å¦‚æžœ{media_term_zh}ä¸­æœ‰äººæˆ–è§’è‰²ï¼Œè¯·ä½¿ç”¨åå­—'{name}'è€Œä¸æ˜¯é€šç”¨æœ¯è¯­ã€‚"
        else:
            final_prompt += f" If there is a person or character in the {media_term_en}, use the name '{name}' instead of generic terms."

    # Add extra options
    if extra_options:
        for option in extra_options:
            option_prompt = get_extra_option_prompt(option, is_video=is_video)
            if option_prompt:
                final_prompt += f" {option_prompt}"

    return final_prompt

def create_output_folder(folder_name: str = None) -> str:
    """Create and return path to output folder"""
    if folder_name and folder_name.strip():
        # Sanitize folder name
        safe_name = "".join(c for c in folder_name if c.isalnum() or c in "_ -").strip()
        if not safe_name:
            safe_name = f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    else:
        safe_name = f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

    folder_path = os.path.join(DATASETS_DIR, safe_name)
    os.makedirs(folder_path, exist_ok=True)
    return folder_path

def save_results_txt(results: List[dict], output_folder: str) -> List[str]:
    """Save results as individual TXT files"""
    saved_files = []
    for result in results:
        filename = os.path.splitext(os.path.basename(result.get("image_path", "image")))[0]
        txt_path = os.path.join(output_folder, f"{filename}.txt")
        with open(txt_path, "w", encoding="utf-8") as f:
            if isinstance(result.get("descriptions"), list):
                for i, desc in enumerate(result["descriptions"], 1):
                    f.write(f"=== Variant {i} ===\n{desc}\n\n")
            else:
                f.write(result.get("description", ""))
        saved_files.append(txt_path)

        # Copy image if exists
        if result.get("image_path") and os.path.exists(result["image_path"]):
            img_dest = os.path.join(output_folder, os.path.basename(result["image_path"]))
            if not os.path.exists(img_dest):
                shutil.copy2(result["image_path"], img_dest)

    return saved_files

def save_results_json(results: List[dict], output_folder: str) -> str:
    """Save all results as a single JSON file"""
    json_path = os.path.join(output_folder, "results.json")
    export_data = []
    for result in results:
        export_data.append({
            "image": os.path.basename(result.get("image_path", "")),
            "prompt": result.get("prompt", ""),
            "descriptions": result.get("descriptions", [result.get("description", "")]),
            "timestamp": datetime.now().isoformat()
        })

    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(export_data, f, ensure_ascii=False, indent=2)

    return json_path

def save_results_csv(results: List[dict], output_folder: str) -> str:
    """Save all results as a CSV file"""
    csv_path = os.path.join(output_folder, "results.csv")

    with open(csv_path, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(["Image", "Prompt", "Description", "Variant"])

        for result in results:
            image_name = os.path.basename(result.get("image_path", ""))
            prompt = result.get("prompt", "")
            descriptions = result.get("descriptions", [result.get("description", "")])

            for i, desc in enumerate(descriptions, 1):
                writer.writerow([image_name, prompt, desc, i])

    return csv_path

class ImageDescriptionGenerator:
    def __init__(self):
        self.model = None
        self.processor = None
        self.current_model_name = None
        self.current_quantization = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"

    def load_model(self, model_name: str, quantization: str = "4-bit"):
        """Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ñ ÐºÐ²Ð°Ð½Ñ‚Ð¸Ð·Ð°Ñ†Ð¸ÐµÐ¹ BitsAndBytes"""
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð½ÑƒÐ¶Ð½Ð° Ð»Ð¸ Ð¿ÐµÑ€ÐµÐ·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ°
        if (self.current_model_name == model_name and
            self.current_quantization == quantization and
            self.model is not None):
            print(f"âœ… ÐœÐ¾Ð´ÐµÐ»ÑŒ {model_name} ÑƒÐ¶Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð°")
            return

        print(f"\n{'='*50}")
        print(f"ðŸ§  Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸: {model_name}")
        print(f"âš™ï¸ ÐšÐ²Ð°Ð½Ñ‚Ð¸Ð·Ð°Ñ†Ð¸Ñ: {quantization}")
        print(f"ðŸ’» Ð£ÑÑ‚Ñ€Ð¾Ð¹ÑÑ‚Ð²Ð¾: {self.device}")
        print(f"{'='*50}")

        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÑÐºÐ°Ñ‡Ð°Ð½Ð° Ð»Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
        cached_size = get_model_cache_size(model_name)
        if cached_size:
            print(f"âœ… ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð½Ð°Ð¹Ð´ÐµÐ½Ð° Ð² ÐºÑÑˆÐµ [{cached_size}]")
        else:
            print(f"â¬‡ï¸ ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð° Ð² ÐºÑÑˆÐµ - Ð±ÑƒÐ´ÐµÑ‚ ÑÐºÐ°Ñ‡Ð°Ð½Ð° Ñ HuggingFace...")
            print(f"â³ Ð­Ñ‚Ð¾ Ð¼Ð¾Ð¶ÐµÑ‚ Ð·Ð°Ð½ÑÑ‚ÑŒ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð¼Ð¸Ð½ÑƒÑ‚ Ð¿Ñ€Ð¸ Ð¿ÐµÑ€Ð²Ð¾Ð¼ Ð·Ð°Ð¿ÑƒÑÐºÐµ")

        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ ÑÑ‚Ð°Ñ€ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð½Ð° ÑÐ»ÑƒÑ‡Ð°Ð¹ Ð¾ÑˆÐ¸Ð±ÐºÐ¸
        old_model = self.model
        old_processor = self.processor
        old_model_name = self.current_model_name
        old_quantization = self.current_quantization

        try:
            # ÐžÑÐ²Ð¾Ð±Ð¾Ð¶Ð´Ð°ÐµÐ¼ Ð¿Ð°Ð¼ÑÑ‚ÑŒ Ð¾Ñ‚ Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰ÐµÐ¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸
            if self.model is not None:
                print(f"ðŸ—‘ï¸ Ð’Ñ‹Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¿Ñ€ÐµÐ´Ñ‹Ð´ÑƒÑ‰ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ: {old_model_name}")
                self.model = None
                self.processor = None
                del old_model
                del old_processor
                gc.collect()
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    torch.cuda.synchronize()
                print(f"âœ… ÐŸÐ°Ð¼ÑÑ‚ÑŒ Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½Ð°")

            # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° ÐºÐ²Ð°Ð½Ñ‚Ð¸Ð·Ð°Ñ†Ð¸Ð¸ BitsAndBytes
            bnb_config = None
            dtype = torch.bfloat16 if torch.cuda.is_available() else torch.float32

            if quantization == "4-bit" and torch.cuda.is_available():
                bnb_config = BitsAndBytesConfig(
                    load_in_4bit=True,
                    bnb_4bit_compute_dtype=torch.bfloat16,
                    bnb_4bit_quant_type="nf4",
                    bnb_4bit_use_double_quant=True,
                )
                print("âš¡ 4-bit ÐºÐ²Ð°Ð½Ñ‚Ð¸Ð·Ð°Ñ†Ð¸Ñ (NF4) â€” ÑÐºÐ¾Ð½Ð¾Ð¼Ð¸Ñ ~75% VRAM")
            elif quantization == "8-bit" and torch.cuda.is_available():
                bnb_config = BitsAndBytesConfig(
                    load_in_8bit=True,
                )
                print("âš¡ 8-bit ÐºÐ²Ð°Ð½Ñ‚Ð¸Ð·Ð°Ñ†Ð¸Ñ â€” ÑÐºÐ¾Ð½Ð¾Ð¼Ð¸Ñ ~50% VRAM")
            else:
                print("ðŸ“Š ÐŸÐ¾Ð»Ð½Ð°Ñ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ (bfloat16/float32)")

            # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð½Ð¾Ð²ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ñ Ð¿Ð¾Ð´Ð°Ð²Ð»ÐµÐ½Ð¸ÐµÐ¼ Ð¿Ñ€ÐµÐ´ÑƒÐ¿Ñ€ÐµÐ¶Ð´ÐµÐ½Ð¸Ð¹
            print(f"ðŸ”„ Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸...")
            load_start_time = time.time()

            with warnings.catch_warnings():
                warnings.filterwarnings('ignore')
                load_kwargs = {
                    "device_map": "auto",
                    "trust_remote_code": True,
                }

                if bnb_config is not None:
                    load_kwargs["quantization_config"] = bnb_config
                else:
                    load_kwargs["torch_dtype"] = dtype

                # SDPA (Scaled Dot Product Attention) - Ð²ÑÑ‚Ñ€Ð¾ÐµÐ½ Ð² PyTorch 2.0+
                # Ð‘Ñ‹ÑÑ‚Ñ€Ñ‹Ð¹ Ð¸ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ Ð½Ð° Windows Ð±ÐµÐ· Ð´Ð¾Ð¿. Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚ÐµÐ¹
                if torch.cuda.is_available():
                    load_kwargs["attn_implementation"] = "sdpa"
                    print("ðŸš€ SDPA attention (PyTorch native)")

                self.model = Qwen3VLForConditionalGeneration.from_pretrained(
                    model_name,
                    **load_kwargs
                )
                print(f"ðŸ”„ Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ¾Ñ€Ð°...")
                self.processor = AutoProcessor.from_pretrained(model_name, trust_remote_code=True)

            load_time = time.time() - load_start_time
            self.current_model_name = model_name
            self.current_quantization = quantization

            # ÐŸÐ¾ÐºÐ°Ð·Ñ‹Ð²Ð°ÐµÐ¼ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ð¿Ð°Ð¼ÑÑ‚Ð¸
            memory_info = get_memory_info()
            print(f"\n{'='*50}")
            print(f"âœ… ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð° Ð·Ð° {load_time:.1f} ÑÐµÐº")
            print(f"ðŸ“Š {memory_info}")
            print(f"{'='*50}\n")

        except Exception as e:
            # ÐŸÑ€Ð¸ Ð¾ÑˆÐ¸Ð±ÐºÐµ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ - Ð¾Ñ‡Ð¸Ñ‰Ð°ÐµÐ¼ ÑÐ¾ÑÑ‚Ð¾ÑÐ½Ð¸Ðµ
            print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸: {str(e)}")
            self.model = None
            self.processor = None
            self.current_model_name = None
            self.current_quantization = None
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            raise Exception(f"ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸ {model_name}: {str(e)}")
    
    def _prepare_inputs(
        self,
        media_path: str,
        prompt: str,
        model_name: str,
        quantization: str,
        seed: int,
        is_video: bool = False
    ):
        """Prepare inputs for generation"""
        # Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÐ¼ Ð¼Ð¾Ð´ÐµÐ»ÑŒ ÐµÑÐ»Ð¸ Ð½ÐµÐ¾Ð±Ñ…Ð¾Ð´Ð¸Ð¼Ð¾
        self.load_model(model_name, quantization)

        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ‡Ñ‚Ð¾ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð°
        if self.model is None or self.processor is None:
            raise Exception("ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð½Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð°. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð²Ñ‹Ð±Ñ€Ð°Ñ‚ÑŒ Ð´Ñ€ÑƒÐ³ÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¸Ð»Ð¸ Ð¿ÐµÑ€ÐµÐ·Ð°Ð¿ÑƒÑÑ‚Ð¸Ñ‚ÑŒ Ð¿Ñ€Ð¸Ð»Ð¾Ð¶ÐµÐ½Ð¸Ðµ.")

        # Ð£ÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ seed ÐµÑÐ»Ð¸ ÑƒÐºÐ°Ð·Ð°Ð½
        if seed != -1:
            torch.manual_seed(seed)
            if torch.cuda.is_available():
                torch.cuda.manual_seed(seed)

        # ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð´Ð»Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸
        # Use "video" type for videos, "image" for images
        if is_video:
            content_item = {
                "type": "video",
                "video": media_path,
            }
        else:
            content_item = {
                "type": "image",
                "image": media_path,
            }

        messages = [
            {
                "role": "user",
                "content": [
                    content_item,
                    {"type": "text", "text": prompt},
                ],
            }
        ]

        # ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÐ¼ Ñ‚ÐµÐºÑÑ‚ Ð´Ð»Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸
        text = self.processor.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True
        )

        # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ/Ð²Ð¸Ð´ÐµÐ¾ Ð¸ Ñ‚ÐµÐºÑÑ‚
        image_inputs, video_inputs = process_vision_info(messages)
        inputs = self.processor(
            text=[text],
            images=image_inputs,
            videos=video_inputs,
            padding=True,
            return_tensors="pt",
        )
        inputs = inputs.to(self.device)
        return inputs

    def generate_description(
        self,
        image_path: str,
        prompt: str,
        model_name: str,
        quantization: str = "4-bit",
        max_new_tokens: int = 1024,
        temperature: float = 0.6,
        top_p: float = 0.9,
        top_k: int = 50,
        seed: int = -1,
        is_video: bool = False
    ) -> str:
        """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ Ð´Ð»Ñ Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ/Ð²Ð¸Ð´ÐµÐ¾ (Ð±ÐµÐ· streaming)"""
        try:
            inputs = self._prepare_inputs(
                image_path, prompt, model_name, quantization, seed, is_video
            )

            # Non-streaming generation (inference_mode Ð±Ñ‹ÑÑ‚Ñ€ÐµÐµ Ñ‡ÐµÐ¼ no_grad)
            with torch.inference_mode():
                generated_ids = self.model.generate(
                    **inputs,
                    max_new_tokens=max_new_tokens,
                    temperature=temperature,
                    top_p=top_p,
                    top_k=top_k,
                    do_sample=True if temperature > 0 else False,
                    use_cache=True,  # KV ÐºÑÑˆÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ðµ Ð´Ð»Ñ ÑƒÑÐºÐ¾Ñ€ÐµÐ½Ð¸Ñ
                )

            # Ð”ÐµÐºÐ¾Ð´Ð¸Ñ€ÑƒÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
            generated_ids_trimmed = [
                out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
            ]
            output_text = self.processor.batch_decode(
                generated_ids_trimmed,
                skip_special_tokens=True,
                clean_up_tokenization_spaces=False
            )

            return output_text[0]

        except Exception as e:
            error_msg = get_text("error_generation").format(str(e))
            return error_msg

    def generate_description_stream(
        self,
        image_path: str,
        prompt: str,
        model_name: str,
        quantization: str = "4-bit",
        max_new_tokens: int = 1024,
        temperature: float = 0.6,
        top_p: float = 0.9,
        top_k: int = 50,
        seed: int = -1,
        is_video: bool = False
    ) -> Generator[str, None, None]:
        """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ Ð´Ð»Ñ Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ/Ð²Ð¸Ð´ÐµÐ¾ ÑÐ¾ streaming"""
        try:
            inputs = self._prepare_inputs(
                image_path, prompt, model_name, quantization, seed, is_video
            )

            streamer = TextIteratorStreamer(
                self.processor.tokenizer,
                skip_special_tokens=True,
                skip_prompt=True
            )

            generation_kwargs = {
                **inputs,
                "max_new_tokens": max_new_tokens,
                "temperature": temperature,
                "top_p": top_p,
                "top_k": top_k,
                "do_sample": True if temperature > 0 else False,
                "use_cache": True,
                "streamer": streamer,
            }

            # Run generation in a separate thread
            thread = Thread(target=self.model.generate, kwargs=generation_kwargs)
            thread.start()

            # Yield tokens as they come
            generated_text = ""
            for new_text in streamer:
                generated_text += new_text
                yield generated_text

            thread.join()

        except Exception as e:
            error_msg = get_text("error_generation").format(str(e))
            yield error_msg

# Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð³Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÑÐºÐ·ÐµÐ¼Ð¿Ð»ÑÑ€ Ð³ÐµÐ½ÐµÑ€Ð°Ñ‚Ð¾Ñ€Ð°
generator = ImageDescriptionGenerator()

def process_single_image(
    image,
    video,
    description_type: str,
    description_length: str,
    custom_prompt: str,
    extra_options: list,
    character_name: str,
    num_variants: int,
    model_name: str,
    quantization: str,
    max_new_tokens: int,
    temperature: float,
    top_p: float,
    top_k: int,
    seed: int,
    use_streaming: bool = True,
    progress=gr.Progress(track_tqdm=True)
) -> Generator:
    """ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ/Ð²Ð¸Ð´ÐµÐ¾ Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸ÐµÐ¹ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¸Ñ… Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ð¾Ð² Ð¸ streaming output"""
    global stop_generation_flag
    reset_stop_flag()
    start_time = time.time()

    # Start capturing console output
    log_capture.clear_logs()
    log_capture.start_capture()
    print(f"[{datetime.now().strftime('%H:%M:%S')}] ÐÐ°Ñ‡Ð°Ð»Ð¾ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸...")

    # Check if we have either uploaded image or video
    if image is None and video is None:
        yield get_text("error_no_image"), "", [], None, log_capture.get_logs()
        return

    # Determine if processing video
    is_video = video is not None

    # Build prompt from type, length, custom, extra options and character name
    final_prompt = build_prompt(
        description_type, description_length, custom_prompt,
        extra_options=extra_options or [],
        character_name=character_name or "",
        is_video=is_video
    )
    if not final_prompt.strip():
        yield get_text("error_no_prompt"), "", [], None, log_capture.get_logs()
        return

    temp_path = None
    num_variants = int(num_variants) if num_variants and str(num_variants).strip() else 1

    try:
        # Priority: video > image
        if video is not None:
            # Video uploaded - use it directly
            media_path = video
            is_video = True
        elif hasattr(image, 'shape'):
            # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ðµ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ ÐµÑÐ»Ð¸ ÑÑ‚Ð¾ numpy array
            temp_path = os.path.join(TEMP_DIR, "temp_image.jpg")
            Image.fromarray(image).save(temp_path)
            media_path = temp_path
            is_video = False
        else:
            media_path = image
            is_video = False

        results = []
        variant_times = []  # Track time for each variant

        for i in range(num_variants):
            # Check stop flag
            if stop_generation_flag:
                elapsed_time = time.time() - start_time
                print(f"[{datetime.now().strftime('%H:%M:%S')}] Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð¾ÑÑ‚Ð°Ð½Ð¾Ð²Ð»ÐµÐ½Ð° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÐµÐ¼")
                yield f"ðŸ›‘ {get_text('generation_stopped')} ({get_text('processing_time')}: {elapsed_time:.1f} {get_text('seconds')})", final_prompt, results, None, log_capture.get_logs()
                return

            variant_start = time.time()
            variant_seed = seed if seed == -1 else seed + i
            memory_info = get_memory_info()
            status_msg = f"{get_text('generating')} ({get_text('variant')} {i+1}/{num_variants}) | {memory_info}"
            print(f"[{datetime.now().strftime('%H:%M:%S')}] Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚Ð° {i+1}/{num_variants}, seed={variant_seed}")

            if use_streaming:
                # Stream the generation for real-time output
                current_result = ""
                for partial_result in generator.generate_description_stream(
                    image_path=media_path,
                    prompt=final_prompt,
                    model_name=model_name,
                    quantization=quantization,
                    max_new_tokens=max_new_tokens,
                    temperature=temperature,
                    top_p=top_p,
                    top_k=top_k,
                    seed=variant_seed,
                    is_video=is_video
                ):
                    if stop_generation_flag:
                        break
                    current_result = partial_result
                    # Update results with streaming text
                    temp_results = results + [current_result]
                    yield status_msg, final_prompt, temp_results, None, log_capture.get_logs()

                result = current_result
            else:
                # Non-streaming generation
                yield status_msg, final_prompt, results, None, log_capture.get_logs()
                result = generator.generate_description(
                    image_path=media_path,
                    prompt=final_prompt,
                    model_name=model_name,
                    quantization=quantization,
                    max_new_tokens=max_new_tokens,
                    temperature=temperature,
                    top_p=top_p,
                    top_k=top_k,
                    seed=variant_seed,
                    is_video=is_video
                )

            variant_time = time.time() - variant_start
            variant_times.append(variant_time)
            results.append(result)
            print(f"[{datetime.now().strftime('%H:%M:%S')}] Ð’Ð°Ñ€Ð¸Ð°Ð½Ñ‚ {i+1} Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½ Ð·Ð° {variant_time:.1f}s")

        # Calculate processing time
        elapsed_time = time.time() - start_time
        memory_info = get_memory_info()

        # Build detailed status with per-variant timing
        timing_details = " | ".join([f"V{i+1}: {t:.1f}s" for i, t in enumerate(variant_times)])
        final_status = f"{get_text('generation_complete')} | Total: {elapsed_time:.1f}s ({timing_details}) | {memory_info}"

        # Prepare download file
        download_path = None
        if results:
            all_text = "\n\n".join([f"=== Variant {i+1} (Time: {variant_times[i]:.1f}s) ===\n{r}" for i, r in enumerate(results)])
            download_path = save_text_to_file(all_text, f"result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt")

        print(f"[{datetime.now().strftime('%H:%M:%S')}] Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð° ÑƒÑÐ¿ÐµÑˆÐ½Ð¾ Ð·Ð° {elapsed_time:.1f}s")
        yield final_status, final_prompt, results, download_path, log_capture.get_logs()

    except Exception as e:
        print(f"[{datetime.now().strftime('%H:%M:%S')}] ÐžÑˆÐ¸Ð±ÐºÐ°: {str(e)}")
        yield f"âŒ Error: {str(e)}", final_prompt, [], None, log_capture.get_logs()
    finally:
        # Stop capturing console output
        log_capture.stop_capture()

        # Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ð¹ Ñ„Ð°Ð¹Ð»
        if temp_path and os.path.exists(temp_path):
            try:
                os.remove(temp_path)
            except:
                pass

        # Clean up GPU memory
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

def process_batch_images(
    files: List,
    description_type: str,
    description_length: str,
    custom_prompt: str,
    extra_options: list,
    character_name: str,
    num_variants: int,
    output_folder_name: str,
    export_formats: List[str],
    model_name: str,
    quantization: str,
    max_new_tokens: int,
    temperature: float,
    top_p: float,
    top_k: int,
    seed: int,
    is_video: bool = False,
    progress=gr.Progress(track_tqdm=True)
) -> Generator:
    """ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ° Ð¿Ð°ÐºÐµÑ‚Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹/Ð²Ð¸Ð´ÐµÐ¾ Ñ Ð¿Ñ€Ð¾Ð³Ñ€ÐµÑÑ-Ð±Ð°Ñ€Ð¾Ð¼ Ð¸ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð¾Ð¼"""
    global stop_generation_flag
    reset_stop_flag()
    start_time = time.time()

    if not files:
        yield get_text("error_no_images"), "", None
        return

    # Build prompt from type, length, custom, extra options and character name
    final_prompt = build_prompt(
        description_type, description_length, custom_prompt,
        extra_options=extra_options or [],
        character_name=character_name or "",
        is_video=is_video
    )
    if not final_prompt.strip():
        yield get_text("error_no_prompts"), "", None
        return

    num_variants = int(num_variants)
    total_files = len(files)
    all_results = []
    output_lines = []

    # Create output folder
    output_folder = create_output_folder(output_folder_name)

    media_type = "video" if is_video else get_text('processing_image')

    for idx, file in enumerate(progress.tqdm(files, desc=f"Processing {media_type}s")):
        # Check stop flag
        if stop_generation_flag:
            elapsed_time = time.time() - start_time
            final_status = f"ðŸ›‘ {get_text('generation_stopped')}\n"
            final_status += f"ðŸ“Š {idx} {get_text('of')} {total_files} files processed in {elapsed_time:.1f} {get_text('seconds')}"
            yield final_status, "\n".join(output_lines), None
            return

        image_path = file.name if hasattr(file, 'name') else file
        filename = os.path.basename(image_path)

        # Status update with memory info
        memory_info = get_memory_info()
        status_msg = f"â³ Processing {idx + 1} {get_text('of')} {total_files}: {filename} | {memory_info}"
        yield status_msg, "\n".join(output_lines), None

        descriptions = []
        variant_times = []

        for v in range(num_variants):
            # Check stop flag between variants
            if stop_generation_flag:
                break

            variant_start = time.time()
            variant_seed = seed if seed == -1 else seed + idx * num_variants + v

            result = generator.generate_description(
                image_path=image_path,
                prompt=final_prompt,
                model_name=model_name,
                quantization=quantization,
                max_new_tokens=max_new_tokens,
                temperature=temperature,
                top_p=top_p,
                top_k=top_k,
                seed=variant_seed,
                is_video=is_video
            )
            variant_time = time.time() - variant_start
            variant_times.append(variant_time)
            descriptions.append(result)

        if not descriptions:
            continue

        # Store result
        all_results.append({
            "image_path": image_path,
            "prompt": final_prompt,
            "descriptions": descriptions,
            "description": descriptions[0] if descriptions else ""
        })

        # Add to output with timing info
        output_lines.append(f"{'='*50}")
        output_lines.append(get_text("image_label").format(idx + 1, filename))
        output_lines.append(get_text("prompt_label").format(final_prompt))

        for v_idx, desc in enumerate(descriptions, 1):
            if num_variants > 1:
                timing_info = f" ({variant_times[v_idx-1]:.1f}s)" if v_idx-1 < len(variant_times) else ""
                output_lines.append(f"\n--- {get_text('variant')} {v_idx}{timing_info} ---")
            output_lines.append(f"{desc}\n")

        yield status_msg, "\n".join(output_lines), None

    # Save results in selected formats
    saved_paths = []
    if export_formats and all_results:
        if "TXT" in export_formats:
            txt_files = save_results_txt(all_results, output_folder)
            saved_paths.extend(txt_files)

        if "JSON" in export_formats:
            json_path = save_results_json(all_results, output_folder)
            saved_paths.append(json_path)

        if "CSV" in export_formats:
            csv_path = save_results_csv(all_results, output_folder)
            saved_paths.append(csv_path)

    # Calculate total time
    elapsed_time = time.time() - start_time
    memory_info = get_memory_info()

    # Final status
    final_status = f"{get_text('generation_complete')}\n"
    final_status += f"ðŸ“Š {total_files} images processed in {elapsed_time:.1f} {get_text('seconds')} | {memory_info}\n"
    if saved_paths:
        final_status += f"ðŸ’¾ Results saved to: {output_folder}"

    # Prepare download file for batch results
    download_path = None
    if all_results:
        download_path = save_text_to_file("\n".join(output_lines), f"batch_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt")

    yield final_status, "\n".join(output_lines), download_path

    # Clean up GPU memory
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

def random_seed() -> int:
    """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ ÑÐ»ÑƒÑ‡Ð°Ð¹Ð½Ð¾Ð³Ð¾ seed"""
    return random.randint(0, 2**32 - 1)

def update_examples():
    return [
        [get_text("example_1")],
        [get_text("example_2")],
        [get_text("example_3")],
        [get_text("example_4")]
    ]

def create_interface():
    """Create Gradio interface with current language and beautiful styling"""
    with gr.Blocks(
        title="SuperCaption Qwen3-VL PRO",
        theme=gr.themes.Soft(primary_hue="indigo", secondary_hue="purple", neutral_hue="slate"),
        css=CUSTOM_CSS
    ) as demo:
        # Beautiful gradient header with credits
        gr.HTML("""
        <div class="main-header">
            <h1>ðŸŽ¬ SuperCaption Qwen3-VL PRO</h1>
            <p>Ð“ÐµÐ½ÐµÑ€Ð°Ñ‚Ð¾Ñ€ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ð¹ Ð¸ Ñ‚ÐµÐ³Ð¾Ð² Ð´Ð»Ñ Ñ„Ð¾Ñ‚Ð¾ Ð¸ Ð²Ð¸Ð´ÐµÐ¾</p>
            <p style="font-size: 0.9rem; margin-top: 0.75rem; opacity: 0.85;">
                ÐŸÐ¾Ñ€Ñ‚Ð°Ñ‚Ð¸Ð²Ð½Ð°Ñ Ð²ÐµÑ€ÑÐ¸Ñ Ð¾Ñ‚ <a href="https://t.me/nerual_dreming" target="_blank">Nerual Dreming</a> Ð¸
                <a href="https://t.me/ruweb24" target="_blank">Slait</a> |
                <a href="https://t.me/neuroport" target="_blank">ðŸ‘¾ ÐÐ•Ð™Ð Ðž-Ð¡ÐžÐ¤Ð¢</a>
            </p>
        </div>
        """)

        # Header that will be updated for language
        header_md = gr.Markdown(f"""
        {get_text("subtitle")}
        """)
        
        # ÐžÐ±Ñ‰Ð¸Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ - Ð¼Ð¾Ð´ÐµÐ»ÑŒ, ÐºÐ²Ð°Ð½Ñ‚Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¸ ÑÐ·Ñ‹Ðº
        with gr.Row():
            model_dropdown = gr.Dropdown(
                choices=get_model_choices(),
                value="huihui-ai/Huihui-Qwen3-VL-2B-Instruct-abliterated",
                label=get_text("model_selection"),
                info=get_text("model_info"),
                scale=3
            )
            refresh_models_btn = gr.Button(
                "ðŸ”„",
                size="sm",
                scale=0,
                min_width=40
            )
            quantization_dropdown = gr.Dropdown(
                choices=[
                    ("4-bit (Ð ÐµÐºÐ¾Ð¼ÐµÐ½Ð´ÑƒÐµÑ‚ÑÑ)", "4-bit"),
                    ("8-bit (Ð›ÑƒÑ‡ÑˆÐµ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾)", "8-bit"),
                    ("Ð‘ÐµÐ· (ÐŸÐ¾Ð»Ð½Ð°Ñ Ñ‚Ð¾Ñ‡Ð½Ð¾ÑÑ‚ÑŒ)", "none"),
                ],
                value="4-bit",
                label=get_text("quantization"),
                info=get_text("quantization_info"),
                scale=1
            )
            language_dropdown = gr.Dropdown(
                choices=[("English", "en"), ("Ð ÑƒÑÑÐºÐ¸Ð¹", "ru"), ("ä¸­æ–‡", "zh")],
                value=current_language,
                label=get_text("language"),
                info=get_text("language_info"),
                scale=1
            )

        # Ð˜Ð½Ð´Ð¸ÐºÐ°Ñ‚Ð¾Ñ€ Ñ‚ÐµÐºÑƒÑ‰ÐµÐ¹ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½Ð¾Ð¹ Ð¼Ð¾Ð´ÐµÐ»Ð¸
        current_model_indicator = gr.Markdown(
            value="ðŸ“­ **ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð½Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð°** â€” Ð±ÑƒÐ´ÐµÑ‚ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð° Ð¿Ñ€Ð¸ Ð¿ÐµÑ€Ð²Ð¾Ð¹ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸",
            elem_id="model_indicator"
        )

        # Ð Ð°ÑÑˆÐ¸Ñ€ÐµÐ½Ð½Ñ‹Ðµ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñ‹
        advanced_accordion = gr.Accordion(get_text("advanced_params"), open=False)
        with advanced_accordion:
            with gr.Row():
                max_tokens_slider = gr.Slider(
                    minimum=1,
                    maximum=4096,
                    value=1024,
                    step=1,
                    label=get_text("max_tokens"),
                    info=get_text("max_tokens_info")
                )
                temperature_slider = gr.Slider(
                    minimum=0.1,
                    maximum=2.0,
                    value=0.6,
                    step=0.1,
                    label=get_text("temperature"),
                    info=get_text("temperature_info")
                )
            
            with gr.Row():
                top_p_slider = gr.Slider(
                    minimum=0.05,
                    maximum=1.0,
                    value=0.9,
                    step=0.05,
                    label=get_text("top_p"),
                    info=get_text("top_p_info")
                )
                top_k_slider = gr.Slider(
                    minimum=1,
                    maximum=1000,
                    value=50,
                    step=1,
                    label=get_text("top_k"),
                    info=get_text("top_k_info")
                )
            
            with gr.Row():
                seed_number = gr.Number(
                    value=-1,
                    label=get_text("seed"),
                    info=get_text("seed_info"),
                    precision=0
                )
                random_seed_btn = gr.Button(get_text("random_seed_btn"), size="sm")
        
        # Ð’ÐºÐ»Ð°Ð´ÐºÐ¸ Ð´Ð»Ñ Ð¾Ð´Ð¸Ð½Ð¾Ñ‡Ð½Ð¾Ð¹ Ð¸ Ð¿Ð°ÐºÐµÑ‚Ð½Ð¾Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸
        tabs = gr.Tabs()
        with tabs:
            # Ð’ÐºÐ»Ð°Ð´ÐºÐ° Ð¾Ð´Ð¸Ð½Ð¾Ñ‡Ð½Ð¾Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸
            single_tab = gr.TabItem(get_text("single_processing"))
            with single_tab:
                with gr.Row():
                    with gr.Column(scale=1, elem_classes="card-style"):
                        gr.Markdown("### ðŸ“· Ð’Ñ…Ð¾Ð´Ð½Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ")

                        # Tabs for Image and Video
                        media_tabs = gr.Tabs()
                        with media_tabs:
                            image_tab = gr.TabItem("ðŸ–¼ï¸ Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ")
                            with image_tab:
                                single_image = gr.Image(
                                    type="numpy",
                                    label=get_text("upload_image"),
                                    height=300
                                )
                                # Duplicate Generate/Stop buttons for quick access
                                with gr.Row():
                                    single_generate_btn_image = gr.Button(
                                        get_text("generate_btn"),
                                        variant="primary",
                                        elem_classes="generate-btn",
                                        scale=3
                                    )
                                    single_stop_btn_image = gr.Button(
                                        get_text("stop_btn"),
                                        variant="stop",
                                        scale=1
                                    )

                            video_tab = gr.TabItem("ðŸŽ¥ Ð’Ð¸Ð´ÐµÐ¾")
                            with video_tab:
                                single_video = gr.Video(
                                    label="Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ Ð²Ð¸Ð´ÐµÐ¾",
                                    height=300
                                )
                                # Duplicate Generate/Stop buttons for quick access
                                with gr.Row():
                                    single_generate_btn_video = gr.Button(
                                        get_text("generate_btn"),
                                        variant="primary",
                                        elem_classes="generate-btn",
                                        scale=3
                                    )
                                    single_stop_btn_video = gr.Button(
                                        get_text("stop_btn"),
                                        variant="stop",
                                        scale=1
                                    )

                        gr.Markdown("### ðŸ“ ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ")

                        single_desc_type = gr.Dropdown(
                            choices=get_description_types(),
                            value=get_description_types()[0],
                            label=get_text("description_type"),
                            info=get_text("description_type_info")
                        )
                        single_desc_length = gr.Dropdown(
                            choices=get_description_lengths(),
                            value=get_description_lengths()[0],
                            label=get_text("description_length"),
                            info=get_text("description_length_info")
                        )
                        single_num_variants = gr.Slider(
                            minimum=1,
                            maximum=5,
                            value=1,
                            step=1,
                            label=get_text("num_variants"),
                            info=get_text("num_variants_info")
                        )

                        # Custom prompt - visible by default
                        single_custom_prompt = gr.Textbox(
                            label=get_text("custom_prompt_override"),
                            placeholder=get_text("custom_prompt_placeholder"),
                            lines=3
                        )

                        # Extra options (will update based on media type)
                        with gr.Accordion(get_text("extra_options"), open=False):
                            single_extra_options = gr.CheckboxGroup(
                                choices=get_extra_options(is_video=False),  # Default to image
                                value=[],
                                label="",
                                info=get_text("extra_options_info"),
                                elem_id="single_extra_options"
                            )
                            # Hidden state to track if video is selected
                            single_is_video = gr.State(value=False)

                            # Character name field - hidden in accordion
                            single_character_name = gr.Textbox(
                                label=get_text("character_name"),
                                placeholder=get_text("character_name_placeholder"),
                                info=get_text("character_name_info"),
                                lines=1
                            )

                        # Prompt presets section - collapsed accordion at the bottom
                        with gr.Accordion("ðŸ“‹ ÐŸÑ€ÐµÑÐµÑ‚Ñ‹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚Ð¾Ð²", open=False):
                            with gr.Row():
                                single_preset = gr.Dropdown(
                                    choices=list(load_prompt_presets().keys()),
                                    value="None",
                                    label=get_text("prompt_preset"),
                                    info=get_text("prompt_preset_info"),
                                    scale=3
                                )
                                single_refresh_presets = gr.Button(
                                    "ðŸ”„",
                                    size="sm",
                                    scale=0,
                                    min_width=40
                                )
                            gr.Markdown("---")
                            gr.Markdown("**Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ñ‚ÐµÐºÑƒÑ‰Ð¸Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚ ÐºÐ°Ðº Ð¿Ñ€ÐµÑÐµÑ‚:**")
                            with gr.Row():
                                single_save_preset_name = gr.Textbox(
                                    label="Ð˜Ð¼Ñ Ð¿Ñ€ÐµÑÐµÑ‚Ð°",
                                    placeholder="Ð¼Ð¾Ð¹_Ð¿Ñ€ÐµÑÐµÑ‚",
                                    scale=2
                                )
                                single_save_preset_btn = gr.Button(
                                    "ðŸ’¾ Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ",
                                    size="sm",
                                    scale=1
                                )
                            single_save_preset_status = gr.Markdown("")

                        with gr.Row():
                            single_submit_btn = gr.Button(
                                get_text("generate_btn"),
                                variant="primary",
                                elem_classes="generate-btn",
                                scale=3
                            )
                            single_stop_btn = gr.Button(
                                get_text("stop_btn"),
                                variant="stop",
                                scale=1
                            )

                    with gr.Column(scale=1, elem_classes="card-style"):
                        gr.Markdown("### ðŸ“Š Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹")
                        single_status = gr.Textbox(
                            label=get_text("status"),
                            interactive=False,
                            elem_classes="status-box"
                        )
                        single_prompt_used = gr.Textbox(
                            label="Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚",
                            interactive=False,
                            lines=2
                        )

                        # Multiple variant outputs
                        single_outputs = []
                        for i in range(5):
                            with gr.Group(visible=(i == 0)) as variant_group:
                                variant_output = gr.Textbox(
                                    label=f"{get_text('variant')} {i+1}" if i > 0 else get_text("result"),
                                    lines=8,
                                    show_copy_button=True
                                )
                                single_outputs.append((variant_group, variant_output))

                        # Download result file
                        single_download = gr.File(
                            label=get_text("download_result"),
                            visible=True
                        )

                        # Console output accordion
                        with gr.Accordion("ðŸ“Ÿ ÐšÐ¾Ð½ÑÐ¾Ð»ÑŒ", open=False):
                            single_console_output = gr.Textbox(
                                label="",
                                lines=10,
                                max_lines=20,
                                interactive=False,
                                show_copy_button=True,
                                placeholder="Ð—Ð´ÐµÑÑŒ Ð±ÑƒÐ´ÑƒÑ‚ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶Ð°Ñ‚ÑŒÑÑ ÑÐ¸ÑÑ‚ÐµÐ¼Ð½Ñ‹Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ñ Ð¸ Ð»Ð¾Ð³Ð¸ Ð²Ð¾ Ð²Ñ€ÐµÐ¼Ñ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸..."
                            )

                # ÐšÐ»Ð¸ÐºÐ°Ð±ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¿Ñ€Ð¸Ð¼ÐµÑ€Ñ‹ Ð¿Ñ€Ð¾Ð¼Ñ‚Ð¾Ð²
                examples_title = gr.Markdown(f"### {get_text('examples_title')}")

            # Ð’ÐºÐ»Ð°Ð´ÐºÐ° Ð¿Ð°ÐºÐµÑ‚Ð½Ð¾Ð¹ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ - Ñ€Ð°Ð·Ð´ÐµÐ»ÐµÐ½Ð° Ð½Ð° Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð¸ Ð²Ð¸Ð´ÐµÐ¾
            batch_tab = gr.TabItem(get_text("batch_processing"))
            with batch_tab:
                # Sub-tabs for images and videos
                batch_media_tabs = gr.Tabs()
                with batch_media_tabs:
                    # BATCH IMAGES TAB
                    batch_images_tab = gr.TabItem("ðŸ“š ÐŸÐ°ÐºÐµÑ‚ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ð¹")
                    with batch_images_tab:
                        with gr.Row():
                            with gr.Column(scale=1, elem_classes="card-style"):
                                gr.Markdown("### ðŸ“ Ð’Ñ…Ð¾Ð´Ð½Ñ‹Ðµ Ñ„Ð°Ð¹Ð»Ñ‹")
                                batch_images = gr.File(
                                    file_count="multiple",
                                    label=get_text("upload_images"),
                                    file_types=["image"]
                                )

                                gr.Markdown("### ðŸ“ ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ")

                                # Prompt preset dropdown
                                with gr.Row():
                                    batch_preset = gr.Dropdown(
                                        choices=list(load_prompt_presets().keys()),
                                        value="None",
                                        label=get_text("prompt_preset"),
                                        info=get_text("prompt_preset_info"),
                                        scale=4
                                    )
                                    batch_refresh_presets = gr.Button(
                                        "ðŸ”„",
                                        size="sm",
                                        scale=0,
                                        min_width=40
                                    )

                                batch_desc_type = gr.Dropdown(
                                    choices=get_description_types(),
                                    value=get_description_types()[0],
                                    label=get_text("description_type"),
                                    info=get_text("description_type_info")
                                )
                                batch_desc_length = gr.Dropdown(
                                    choices=get_description_lengths(),
                                    value=get_description_lengths()[0],
                                    label=get_text("description_length"),
                                    info=get_text("description_length_info")
                                )
                                batch_num_variants = gr.Slider(
                                    minimum=1,
                                    maximum=3,
                                    value=1,
                                    step=1,
                                    label=get_text("num_variants"),
                                    info=get_text("num_variants_info")
                                )

                                # Character name field
                                batch_character_name = gr.Textbox(
                                    label=get_text("character_name"),
                                    placeholder=get_text("character_name_placeholder"),
                                    info=get_text("character_name_info"),
                                    lines=1
                                )

                                # Extra options for images
                                with gr.Accordion(get_text("extra_options"), open=False):
                                    batch_extra_options = gr.CheckboxGroup(
                                        choices=get_extra_options(is_video=False),
                                        value=[],
                                        label="",
                                        info=get_text("extra_options_info")
                                    )

                                with gr.Accordion(get_text("custom_prompt_override"), open=False):
                                    batch_custom_prompt = gr.Textbox(
                                        placeholder=get_text("custom_prompt_placeholder"),
                                        lines=3,
                                        label=""
                                    )

                                gr.Markdown("### ðŸ’¾ ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð°")
                                batch_output_folder = gr.Textbox(
                                    label=get_text("output_folder"),
                                    placeholder=get_text("output_folder_placeholder"),
                                    value=""
                                )
                                batch_export_formats = gr.CheckboxGroup(
                                    choices=["TXT", "JSON", "CSV"],
                                    value=["TXT"],
                                    label=get_text("export_format")
                                )

                                with gr.Row():
                                    batch_submit_btn = gr.Button(
                                        get_text("process_batch_btn"),
                                        variant="primary",
                                        elem_classes="generate-btn",
                                        scale=3
                                    )
                                    batch_stop_btn = gr.Button(
                                        get_text("stop_btn"),
                                        variant="stop",
                                        scale=1
                                    )

                            with gr.Column(scale=1, elem_classes="card-style"):
                                gr.Markdown("### ðŸ“Š Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹")
                                batch_status = gr.Textbox(
                                    label=get_text("status"),
                                    interactive=False,
                                    elem_classes="status-box"
                                )
                                batch_output = gr.Textbox(
                                    label=get_text("results"),
                                    lines=20,
                                    show_copy_button=True
                                )

                                # Download result file
                                batch_download = gr.File(
                                    label=get_text("download_result"),
                                    visible=True
                                )

                    # BATCH VIDEOS TAB
                    batch_videos_tab = gr.TabItem("ðŸŽ¬ ÐŸÐ°ÐºÐµÑ‚ Ð²Ð¸Ð´ÐµÐ¾")
                    with batch_videos_tab:
                        with gr.Row():
                            with gr.Column(scale=1, elem_classes="card-style"):
                                gr.Markdown("### ðŸ“ Ð’Ñ…Ð¾Ð´Ð½Ñ‹Ðµ Ð²Ð¸Ð´ÐµÐ¾ Ñ„Ð°Ð¹Ð»Ñ‹")
                                batch_videos = gr.File(
                                    file_count="multiple",
                                    label="Ð—Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚Ðµ Ð²Ð¸Ð´ÐµÐ¾",
                                    file_types=["video"]
                                )

                                gr.Markdown("### ðŸ“ ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ñ")

                                # Prompt preset dropdown
                                with gr.Row():
                                    batch_video_preset = gr.Dropdown(
                                        choices=list(load_prompt_presets().keys()),
                                        value="None",
                                        label=get_text("prompt_preset"),
                                        info=get_text("prompt_preset_info"),
                                        scale=4
                                    )
                                    batch_video_refresh_presets = gr.Button(
                                        "ðŸ”„",
                                        size="sm",
                                        scale=0,
                                        min_width=40
                                    )

                                batch_video_desc_type = gr.Dropdown(
                                    choices=get_description_types(),
                                    value=get_description_types()[0],
                                    label=get_text("description_type"),
                                    info=get_text("description_type_info")
                                )
                                batch_video_desc_length = gr.Dropdown(
                                    choices=get_description_lengths(),
                                    value=get_description_lengths()[0],
                                    label=get_text("description_length"),
                                    info=get_text("description_length_info")
                                )
                                batch_video_num_variants = gr.Slider(
                                    minimum=1,
                                    maximum=3,
                                    value=1,
                                    step=1,
                                    label=get_text("num_variants"),
                                    info=get_text("num_variants_info")
                                )

                                # Character name field
                                batch_video_character_name = gr.Textbox(
                                    label=get_text("character_name"),
                                    placeholder=get_text("character_name_placeholder"),
                                    info=get_text("character_name_info"),
                                    lines=1
                                )

                                # Extra options for videos
                                with gr.Accordion(get_text("extra_options"), open=False):
                                    batch_video_extra_options = gr.CheckboxGroup(
                                        choices=get_extra_options(is_video=True),
                                        value=[],
                                        label="",
                                        info=get_text("extra_options_info")
                                    )

                                with gr.Accordion(get_text("custom_prompt_override"), open=False):
                                    batch_video_custom_prompt = gr.Textbox(
                                        placeholder=get_text("custom_prompt_placeholder"),
                                        lines=3,
                                        label=""
                                    )

                                gr.Markdown("### ðŸ’¾ ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ¸ ÑÐºÑÐ¿Ð¾Ñ€Ñ‚Ð°")
                                batch_video_output_folder = gr.Textbox(
                                    label=get_text("output_folder"),
                                    placeholder=get_text("output_folder_placeholder"),
                                    value=""
                                )
                                batch_video_export_formats = gr.CheckboxGroup(
                                    choices=["TXT", "JSON", "CSV"],
                                    value=["TXT"],
                                    label=get_text("export_format")
                                )

                                with gr.Row():
                                    batch_video_submit_btn = gr.Button(
                                        "ðŸš€ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ð²Ð¸Ð´ÐµÐ¾",
                                        variant="primary",
                                        elem_classes="generate-btn",
                                        scale=3
                                    )
                                    batch_video_stop_btn = gr.Button(
                                        get_text("stop_btn"),
                                        variant="stop",
                                        scale=1
                                    )

                            with gr.Column(scale=1, elem_classes="card-style"):
                                gr.Markdown("### ðŸ“Š Ð ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹")
                                batch_video_status = gr.Textbox(
                                    label=get_text("status"),
                                    interactive=False,
                                    elem_classes="status-box"
                                )
                                batch_video_output = gr.Textbox(
                                    label=get_text("results"),
                                    lines=20,
                                    show_copy_button=True
                                )

                                # Download result file
                                batch_video_download = gr.File(
                                    label=get_text("download_result"),
                                    visible=True
                                )
        
        # ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ñ‡Ð¸ÐºÐ¸ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ð¹

        # Function to update extra options based on media type
        def update_extra_options_for_media(is_video):
            return gr.update(choices=get_extra_options(is_video=is_video), value=[])

        # Media tab selection handlers - update extra options when switching tabs
        def on_image_tab_select():
            return gr.update(choices=get_extra_options(is_video=False), value=[]), False

        def on_video_tab_select():
            return gr.update(choices=get_extra_options(is_video=True), value=[]), True

        # Connect media tab selection to extra options update
        image_tab.select(fn=on_image_tab_select, outputs=[single_extra_options, single_is_video])
        video_tab.select(fn=on_video_tab_select, outputs=[single_extra_options, single_is_video])

        def change_language(lang):
            global current_language
            current_language = lang

            # Return updated text for key components
            return [
                f"{get_text('subtitle')}",  # header_md
                gr.update(label=get_text("model_selection"), info=get_text("model_info")),  # model_dropdown
                gr.update(label=get_text("quantization"), info=get_text("quantization_info")),  # quantization_dropdown
                gr.update(label=get_text("language"), info=get_text("language_info")),  # language_dropdown
                gr.update(label=get_text("advanced_params")),  # advanced_accordion
                gr.update(value=get_text("generate_btn")),  # single_submit_btn
                gr.update(value=get_text("process_batch_btn")),  # batch_submit_btn
                gr.update(choices=get_description_types(), value=get_description_types()[0]),  # single_desc_type
                gr.update(choices=get_description_lengths(), value=get_description_lengths()[0]),  # single_desc_length
                gr.update(choices=get_description_types(), value=get_description_types()[0]),  # batch_desc_type
                gr.update(choices=get_description_lengths(), value=get_description_lengths()[0]),  # batch_desc_length
                gr.update(choices=get_extra_options(is_video=False), value=[]),  # single_extra_options
                gr.update(choices=get_extra_options(is_video=False), value=[]),  # batch_extra_options
                gr.update(choices=get_extra_options(is_video=True), value=[]),  # batch_video_extra_options
                gr.update(value=get_text("stop_btn")),  # single_stop_btn
                gr.update(value=get_text("stop_btn")),  # batch_stop_btn
                gr.update(value=get_text("stop_btn")),  # batch_video_stop_btn
                gr.update(value=get_text("generate_btn")),  # single_generate_btn_image
                gr.update(value=get_text("stop_btn")),  # single_stop_btn_image
                gr.update(value=get_text("generate_btn")),  # single_generate_btn_video
                gr.update(value=get_text("stop_btn")),  # single_stop_btn_video
            ]

        language_dropdown.change(
            fn=change_language,
            inputs=language_dropdown,
            outputs=[
                header_md,
                model_dropdown,
                quantization_dropdown,
                language_dropdown,
                advanced_accordion,
                single_submit_btn,
                batch_submit_btn,
                single_desc_type,
                single_desc_length,
                batch_desc_type,
                batch_desc_length,
                single_extra_options,
                batch_extra_options,
                batch_video_extra_options,
                single_stop_btn,
                batch_stop_btn,
                batch_video_stop_btn,
                single_generate_btn_image,
                single_stop_btn_image,
                single_generate_btn_video,
                single_stop_btn_video,
            ]
        )

        # Stop button handlers
        single_stop_btn.click(
            fn=stop_generation,
            outputs=single_status
        )

        batch_stop_btn.click(
            fn=stop_generation,
            outputs=batch_status
        )

        batch_video_stop_btn.click(
            fn=stop_generation,
            outputs=batch_video_status
        )

        # Model list refresh handler
        def refresh_model_list():
            """ÐžÐ±Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ñ Ð°ÐºÑ‚ÑƒÐ°Ð»ÑŒÐ½Ñ‹Ð¼ ÑÑ‚Ð°Ñ‚ÑƒÑÐ¾Ð¼ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸"""
            return gr.update(choices=get_model_choices())

        refresh_models_btn.click(
            fn=refresh_model_list,
            outputs=model_dropdown
        )

        # Preset refresh handlers
        def refresh_presets():
            presets = load_prompt_presets()
            return gr.update(choices=list(presets.keys()), value="None")

        single_refresh_presets.click(
            fn=refresh_presets,
            outputs=single_preset
        )

        batch_refresh_presets.click(
            fn=refresh_presets,
            outputs=batch_preset
        )

        batch_video_refresh_presets.click(
            fn=refresh_presets,
            outputs=batch_video_preset
        )

        # Preset selection handlers (load preset text into custom prompt)
        def load_preset(preset_name):
            presets = load_prompt_presets()
            if preset_name and preset_name != "None":
                return presets.get(preset_name, "")
            return ""

        single_preset.change(
            fn=load_preset,
            inputs=single_preset,
            outputs=single_custom_prompt
        )

        batch_preset.change(
            fn=load_preset,
            inputs=batch_preset,
            outputs=batch_custom_prompt
        )

        batch_video_preset.change(
            fn=load_preset,
            inputs=batch_video_preset,
            outputs=batch_video_custom_prompt
        )

        random_seed_btn.click(
            fn=random_seed,
            outputs=seed_number
        )

        # Update variant visibility based on slider
        def update_variant_visibility(num_variants):
            updates = []
            for i in range(5):
                updates.append(gr.update(visible=(i < num_variants)))
            return updates

        single_num_variants.change(
            fn=update_variant_visibility,
            inputs=[single_num_variants],
            outputs=[group for group, _ in single_outputs]
        )

        # Single image processing with button lock
        def process_single_wrapper(image, video, desc_type, desc_length, custom_prompt,
                                   extra_options, character_name, num_variants,
                                   model_name, quantization, max_tokens, temperature, top_p, top_k, seed):
            # Start capturing console output
            log_capture.clear_logs()
            log_capture.start_capture()

            # Model indicator - loading
            model_indicator = f"â³ **Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸** {model_name}..."

            # Disable button at start
            yield gr.update(value=get_text("generating"), interactive=False), "", "", *[gr.update(value="") for _ in range(5)], None, "", model_indicator

            results = []
            download_path = None

            # Process and yield results
            for status, prompt_used, results, download_path in process_single_image(
                image, video, desc_type, desc_length, custom_prompt,
                extra_options, character_name, num_variants,
                model_name, quantization, max_tokens, temperature, top_p, top_k, seed
            ):
                # Prepare outputs for each variant box
                variant_outputs = []
                for i in range(5):
                    if i < len(results):
                        variant_outputs.append(gr.update(value=results[i]))
                    else:
                        variant_outputs.append(gr.update(value=""))

                # Update model indicator
                cached_size = get_model_cache_size(model_name)
                size_str = f" [{cached_size}]" if cached_size else ""
                model_indicator = f"âœ… **{model_name}**{size_str} | {quantization}"

                # Get current console logs
                console_logs = log_capture.get_logs()
                yield gr.update(value=get_text("generating"), interactive=False), status, prompt_used, *variant_outputs, download_path, console_logs, model_indicator

            # Stop capturing and get final logs
            log_capture.stop_capture()
            final_logs = log_capture.get_logs()

            # Re-enable button at end
            final_outputs = []
            for i in range(5):
                if i < len(results):
                    final_outputs.append(gr.update(value=results[i]))
                else:
                    final_outputs.append(gr.update(value=""))

            # Final model indicator
            cached_size = get_model_cache_size(model_name)
            size_str = f" [{cached_size}]" if cached_size else ""
            final_model_indicator = f"âœ… **{model_name}**{size_str} | {quantization}"

            yield gr.update(value=get_text("generate_btn"), interactive=True), status, prompt_used, *final_outputs, download_path, final_logs, final_model_indicator

        single_submit_btn.click(
            fn=process_single_wrapper,
            inputs=[
                single_image,
                single_video,
                single_desc_type,
                single_desc_length,
                single_custom_prompt,
                single_extra_options,
                single_character_name,
                single_num_variants,
                model_dropdown,
                quantization_dropdown,
                max_tokens_slider,
                temperature_slider,
                top_p_slider,
                top_k_slider,
                seed_number
            ],
            outputs=[single_submit_btn, single_status, single_prompt_used] + [output for _, output in single_outputs] + [single_download, single_console_output, current_model_indicator]
        )

        # Duplicate Generate buttons in Image/Video tabs - same functionality
        single_generate_btn_image.click(
            fn=process_single_wrapper,
            inputs=[
                single_image,
                single_video,
                single_desc_type,
                single_desc_length,
                single_custom_prompt,
                single_extra_options,
                single_character_name,
                single_num_variants,
                model_dropdown,
                quantization_dropdown,
                max_tokens_slider,
                temperature_slider,
                top_p_slider,
                top_k_slider,
                seed_number
            ],
            outputs=[single_submit_btn, single_status, single_prompt_used] + [output for _, output in single_outputs] + [single_download, single_console_output, current_model_indicator]
        )

        single_generate_btn_video.click(
            fn=process_single_wrapper,
            inputs=[
                single_image,
                single_video,
                single_desc_type,
                single_desc_length,
                single_custom_prompt,
                single_extra_options,
                single_character_name,
                single_num_variants,
                model_dropdown,
                quantization_dropdown,
                max_tokens_slider,
                temperature_slider,
                top_p_slider,
                top_k_slider,
                seed_number
            ],
            outputs=[single_submit_btn, single_status, single_prompt_used] + [output for _, output in single_outputs] + [single_download, single_console_output, current_model_indicator]
        )

        # Duplicate Stop buttons in Image/Video tabs
        single_stop_btn_image.click(
            fn=stop_generation,
            outputs=single_status
        )

        single_stop_btn_video.click(
            fn=stop_generation,
            outputs=single_status
        )

        # Save preset handler
        def save_preset(name, prompt):
            if not name:
                return "âŒ Please enter a preset name"
            msg = save_prompt_preset(name, prompt)
            new_presets = list(load_prompt_presets().keys())
            return msg, gr.update(choices=new_presets, value=name if "successfully" in msg else None)

        single_save_preset_btn.click(
            fn=save_preset,
            inputs=[single_save_preset_name, single_custom_prompt],
            outputs=[single_save_preset_status, single_preset]
        )

        # Batch processing with button lock
        def process_batch_wrapper(files, desc_type, desc_length, custom_prompt,
                                  extra_options, character_name, num_variants,
                                  output_folder, export_formats, model_name, quantization,
                                  max_tokens, temperature, top_p, top_k, seed):
            # Disable button at start
            yield gr.update(value=get_text("generating"), interactive=False), "", "", None

            download_path = None

            # Process and yield results
            for status, output_text, download_path in process_batch_images(
                files, desc_type, desc_length, custom_prompt,
                extra_options, character_name, num_variants,
                output_folder, export_formats, model_name, quantization,
                max_tokens, temperature, top_p, top_k, seed
            ):
                yield gr.update(value=get_text("generating"), interactive=False), status, output_text, download_path

            # Re-enable button at end
            yield gr.update(value=get_text("process_batch_btn"), interactive=True), status, output_text, download_path

        batch_submit_btn.click(
            fn=process_batch_wrapper,
            inputs=[
                batch_images,
                batch_desc_type,
                batch_desc_length,
                batch_custom_prompt,
                batch_extra_options,
                batch_character_name,
                batch_num_variants,
                batch_output_folder,
                batch_export_formats,
                model_dropdown,
                quantization_dropdown,
                max_tokens_slider,
                temperature_slider,
                top_p_slider,
                top_k_slider,
                seed_number
            ],
            outputs=[batch_submit_btn, batch_status, batch_output, batch_download]
        )

        # Batch video processing with is_video=True
        def process_batch_video_wrapper(files, desc_type, desc_length, custom_prompt,
                                        extra_options, character_name, num_variants,
                                        output_folder, export_formats, model_name, quantization,
                                        max_tokens, temperature, top_p, top_k, seed):
            # Disable button at start
            yield gr.update(value="â³ Processing...", interactive=False), "", "", None

            download_path = None

            # Process and yield results with is_video=True
            for status, output_text, download_path in process_batch_images(
                files, desc_type, desc_length, custom_prompt,
                extra_options, character_name, num_variants,
                output_folder, export_formats, model_name, quantization,
                max_tokens, temperature, top_p, top_k, seed,
                is_video=True  # KEY DIFFERENCE: process as videos
            ):
                yield gr.update(value="â³ Processing...", interactive=False), status, output_text, download_path

            # Re-enable button at end
            yield gr.update(value="ðŸš€ ÐžÐ±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ð²Ð¸Ð´ÐµÐ¾", interactive=True), status, output_text, download_path

        batch_video_submit_btn.click(
            fn=process_batch_video_wrapper,
            inputs=[
                batch_videos,
                batch_video_desc_type,
                batch_video_desc_length,
                batch_video_custom_prompt,
                batch_video_extra_options,
                batch_video_character_name,
                batch_video_num_variants,
                batch_video_output_folder,
                batch_video_export_formats,
                model_dropdown,
                quantization_dropdown,
                max_tokens_slider,
                temperature_slider,
                top_p_slider,
                top_k_slider,
                seed_number
            ],
            outputs=[batch_video_submit_btn, batch_video_status, batch_video_output, batch_video_download]
        )

        return demo

# Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð¸Ð½Ñ‚ÐµÑ€Ñ„ÐµÐ¹Ñ Gradio
demo = create_interface()

if __name__ == "__main__":
    # Enable queue for progress bar support
    demo.queue(max_size=20, default_concurrency_limit=1).launch(
        server_name="127.0.0.1",
        server_port=None,
        share=False,
        show_error=True,
        inbrowser=True
    )
