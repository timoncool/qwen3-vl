import gradio as gr
import torch
from transformers import Qwen3VLForConditionalGeneration, AutoProcessor, BitsAndBytesConfig, TextIteratorStreamer
from qwen_vl_utils import process_vision_info
from PIL import Image
import random
import os
import warnings
from typing import List, Tuple, Optional, Generator
import gc
import json
import csv
import shutil
from datetime import datetime
import time
import tempfile
from threading import Thread
import io
import sys
import logging

# Optional: psutil for memory monitoring
try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False
    print("Note: psutil not installed. RAM monitoring will be limited.")

# Suppress meta device warning (not useful)
warnings.filterwarnings('ignore', message='.*meta device.*')

# Global flag for stopping generation
stop_generation_flag = False

# ==========================================
# Console Log Capture for UI display
# ==========================================
class LogCapture:
    """Captures stdout and logs for real-time console output in UI"""
    def __init__(self):
        self.log_buffer = io.StringIO()
        self.original_stdout = sys.stdout
        self.is_capturing = False

    def start_capture(self):
        """Start capturing stdout"""
        if not self.is_capturing:
            sys.stdout = self
            self.is_capturing = True

    def stop_capture(self):
        """Stop capturing stdout"""
        if self.is_capturing:
            sys.stdout = self.original_stdout
            self.is_capturing = False

    def write(self, message):
        """Write to both original stdout and buffer"""
        self.original_stdout.write(message)
        self.log_buffer.write(message)

    def flush(self):
        """Flush stdout"""
        self.original_stdout.flush()

    def get_logs(self):
        """Get captured logs"""
        return self.log_buffer.getvalue()

    def clear_logs(self):
        """Clear log buffer"""
        self.log_buffer = io.StringIO()

# Global log capture instance
log_capture = LogCapture()

# Base directory for portable app
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
TEMP_DIR = os.path.join(SCRIPT_DIR, "temp")
OUTPUT_DIR = os.path.join(SCRIPT_DIR, "output")
DATASETS_DIR = os.path.join(SCRIPT_DIR, "datasets")
PROMPTS_DIR = os.path.join(SCRIPT_DIR, "prompts")

# Create directories if they don't exist
os.makedirs(TEMP_DIR, exist_ok=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(DATASETS_DIR, exist_ok=True)
os.makedirs(PROMPTS_DIR, exist_ok=True)

# Huggingface cache directory - check env variables first, then platform-specific defaults
def get_hf_cache_dir():
    """Get HuggingFace cache directory, respecting environment variables and platform defaults"""
    # Check HuggingFace environment variables first
    if os.environ.get("HUGGINGFACE_HUB_CACHE"):
        return os.environ["HUGGINGFACE_HUB_CACHE"]
    if os.environ.get("HF_HOME"):
        return os.path.join(os.environ["HF_HOME"], "hub")
    if os.environ.get("HF_HUB_CACHE"):
        return os.environ["HF_HUB_CACHE"]

    # Platform-specific defaults
    if os.name == 'nt':  # Windows
        # Windows: typically in USERPROFILE\.cache\huggingface\hub
        local_app_data = os.environ.get("LOCALAPPDATA")
        if local_app_data:
            cache_in_localappdata = os.path.join(local_app_data, "huggingface", "hub")
            if os.path.exists(cache_in_localappdata):
                return cache_in_localappdata
        # Fall back to home directory
        return os.path.join(os.path.expanduser("~"), ".cache", "huggingface", "hub")
    else:
        # Linux/Mac
        xdg_cache = os.environ.get("XDG_CACHE_HOME", os.path.join(os.path.expanduser("~"), ".cache"))
        return os.path.join(xdg_cache, "huggingface", "hub")

HF_CACHE_DIR = get_hf_cache_dir()

def get_model_cache_size(model_id: str) -> Optional[str]:
    """Check if model is downloaded and return its size on disk"""
    try:
        # Convert model_id to cache folder name format
        # huihui-ai/Huihui-Qwen3-VL-2B-Instruct-abliterated -> models--huihui-ai--Huihui-Qwen3-VL-2B-Instruct-abliterated
        cache_name = "models--" + model_id.replace("/", "--")
        cache_path = os.path.join(HF_CACHE_DIR, cache_name)

        if os.path.exists(cache_path):
            # Calculate total size
            total_size = 0
            for dirpath, dirnames, filenames in os.walk(cache_path):
                for f in filenames:
                    fp = os.path.join(dirpath, f)
                    if os.path.exists(fp):
                        total_size += os.path.getsize(fp)

            # Convert to human-readable format
            if total_size >= 1024 ** 3:
                return f"{total_size / (1024 ** 3):.1f}GB"
            elif total_size >= 1024 ** 2:
                return f"{total_size / (1024 ** 2):.0f}MB"
            else:
                return f"{total_size / 1024:.0f}KB"
        return None
    except:
        return None

# Available models (without MOE models which have different architecture)
AVAILABLE_MODELS = [
    # Abliterated models (Ğ±ĞµĞ· Ñ†ĞµĞ½Ğ·ÑƒÑ€Ñ‹) - Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµĞ¼Ñ‹Ğµ
    ("2B Instruct Abliterated", "huihui-ai/Huihui-Qwen3-VL-2B-Instruct-abliterated"),
    ("2B Thinking Abliterated", "huihui-ai/Huihui-Qwen3-VL-2B-Thinking-abliterated"),
    ("4B Instruct Abliterated", "huihui-ai/Huihui-Qwen3-VL-4B-Instruct-abliterated"),
    ("4B Thinking Abliterated", "huihui-ai/Huihui-Qwen3-VL-4B-Thinking-abliterated"),
    ("8B Instruct Abliterated", "huihui-ai/Huihui-Qwen3-VL-8B-Instruct-abliterated"),
    ("8B Thinking Abliterated", "huihui-ai/Huihui-Qwen3-VL-8B-Thinking-abliterated"),
    ("32B Instruct Abliterated", "huihui-ai/Huihui-Qwen3-VL-32B-Instruct-abliterated"),
    ("32B Thinking Abliterated", "huihui-ai/Huihui-Qwen3-VL-32B-Thinking-abliterated"),
    # Original Qwen models
    ("Qwen 2B Instruct", "Qwen/Qwen3-VL-2B-Instruct"),
    ("Qwen 4B Instruct", "Qwen/Qwen3-VL-4B-Instruct"),
    ("Qwen 8B Instruct", "Qwen/Qwen3-VL-8B-Instruct"),
]

def get_model_choices():
    """Get model choices with download status indicator"""
    choices = []
    for name, model_id in AVAILABLE_MODELS:
        cached_size = get_model_cache_size(model_id)
        if cached_size:
            # Model is downloaded - show size
            display_name = f"âœ… {name} [{cached_size}]"
        else:
            # Model not downloaded - will be downloaded on first use
            display_name = f"â¬‡ï¸ {name} [Ğ½Ğµ ÑĞºĞ°Ñ‡Ğ°Ğ½Ğ°]"
        choices.append((display_name, model_id))
    return choices

# Extra options for description enhancement (IMAGE)
EXTRA_OPTIONS = {
    "en": {
        "Include lighting info": "Include information about lighting.",
        "Include camera angle": "Include information about camera angle.",
        "Include watermark info": "Include information about whether there is a watermark or not.",
        "Include JPEG artifacts info": "Include information about whether there are JPEG artifacts or not.",
        "Include camera/photo details": "If it is a photo, include information about what camera was likely used and details such as aperture, shutter speed, ISO, etc.",
        "Keep it SFW/PG": "Do NOT include anything sexual; keep it PG.",
        "Don't mention resolution": "Do NOT mention the image's resolution.",
        "Include aesthetic quality": "Include information about the subjective aesthetic quality of the image from low to very high.",
        "Include composition style": "Include information on the image's composition style, such as leading lines, rule of thirds, or symmetry.",
        "Don't mention text in image": "Do NOT mention any text that is in the image.",
        "Include depth of field": "Specify the depth of field and whether the background is in focus or blurred.",
        "Describe only key elements": "ONLY describe the most important elements of the image."
    },
    "ru": {
        "Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ± Ğ¾ÑĞ²ĞµÑ‰ĞµĞ½Ğ¸Ğ¸": "Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ± Ğ¾ÑĞ²ĞµÑ‰ĞµĞ½Ğ¸Ğ¸.",
        "Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ñ€Ğ°ĞºÑƒÑ€Ñ ĞºĞ°Ğ¼ĞµÑ€Ñ‹": "Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ Ñ€Ğ°ĞºÑƒÑ€ÑĞµ ĞºĞ°Ğ¼ĞµÑ€Ñ‹.",
        "Ğ£Ğ¿Ğ¾Ğ¼ÑĞ½ÑƒÑ‚ÑŒ Ğ²Ğ¾Ğ´ÑĞ½Ğ¾Ğ¹ Ğ·Ğ½Ğ°Ğº": "Ğ£ĞºĞ°Ğ¶Ğ¸, ĞµÑÑ‚ÑŒ Ğ»Ğ¸ Ğ²Ğ¾Ğ´ÑĞ½Ğ¾Ğ¹ Ğ·Ğ½Ğ°Ğº Ğ½Ğ° Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¸.",
        "Ğ£Ğ¿Ğ¾Ğ¼ÑĞ½ÑƒÑ‚ÑŒ JPEG Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ñ‹": "Ğ£ĞºĞ°Ğ¶Ğ¸, ĞµÑÑ‚ÑŒ Ğ»Ğ¸ JPEG Ğ°Ñ€Ñ‚ĞµÑ„Ğ°ĞºÑ‚Ñ‹ Ğ½Ğ° Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¸.",
        "Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ´ĞµÑ‚Ğ°Ğ»Ğ¸ ĞºĞ°Ğ¼ĞµÑ€Ñ‹/Ñ„Ğ¾Ñ‚Ğ¾": "Ğ•ÑĞ»Ğ¸ ÑÑ‚Ğ¾ Ñ„Ğ¾Ñ‚Ğ¾Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ, ÑƒĞºĞ°Ğ¶Ğ¸ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ ĞºĞ°Ğ¼ĞµÑ€Ğµ, Ğ°Ğ¿ĞµÑ€Ñ‚ÑƒÑ€Ğµ, Ğ²Ñ‹Ğ´ĞµÑ€Ğ¶ĞºĞµ, ISO Ğ¸ Ñ‚.Ğ´.",
        "Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ SFW/PG Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³": "ĞĞ• Ğ²ĞºĞ»ÑÑ‡Ğ°Ğ¹ ÑĞµĞºÑÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚, ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞ¹ Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³ PG.",
        "ĞĞµ ÑƒĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ñ‚ÑŒ Ñ€Ğ°Ğ·Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ": "ĞĞ• ÑƒĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ğ¹ Ñ€Ğ°Ğ·Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ.",
        "Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ ÑÑÑ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºÑƒÑ Ğ¾Ñ†ĞµĞ½ĞºÑƒ": "Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ ÑÑƒĞ±ÑŠĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¼ ÑÑÑ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¼ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğµ Ğ¾Ñ‚ Ğ½Ğ¸Ğ·ĞºĞ¾Ğ³Ğ¾ Ğ´Ğ¾ Ğ¾Ñ‡ĞµĞ½ÑŒ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ³Ğ¾.",
        "Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ ÑÑ‚Ğ¸Ğ»ÑŒ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸": "Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ ÑÑ‚Ğ¸Ğ»Ğµ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ (Ğ²ĞµĞ´ÑƒÑ‰Ğ¸Ğµ Ğ»Ğ¸Ğ½Ğ¸Ğ¸, Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ¾ Ñ‚Ñ€ĞµÑ‚ĞµĞ¹, ÑĞ¸Ğ¼Ğ¼ĞµÑ‚Ñ€Ğ¸Ñ).",
        "ĞĞµ ÑƒĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ñ‚ÑŒ Ñ‚ĞµĞºÑÑ‚ Ğ½Ğ° Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¸": "ĞĞ• ÑƒĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ğ¹ Ñ‚ĞµĞºÑÑ‚, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¹ ĞµÑÑ‚ÑŒ Ğ½Ğ° Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¸.",
        "Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ñƒ Ñ€ĞµĞ·ĞºĞ¾ÑÑ‚Ğ¸": "Ğ£ĞºĞ°Ğ¶Ğ¸ Ğ³Ğ»ÑƒĞ±Ğ¸Ğ½Ñƒ Ñ€ĞµĞ·ĞºĞ¾ÑÑ‚Ğ¸ Ğ¸ Ñ€Ğ°Ğ·Ğ¼Ñ‹Ñ‚Ğ¾ÑÑ‚ÑŒ Ñ„Ğ¾Ğ½Ğ°.",
        "ĞĞ¿Ğ¸ÑÑ‹Ğ²Ğ°Ñ‚ÑŒ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ñ‹": "ĞĞ¿Ğ¸ÑÑ‹Ğ²Ğ°Ğ¹ Ğ¢ĞĞ›Ğ¬ĞšĞ ÑĞ°Ğ¼Ñ‹Ğµ Ğ²Ğ°Ğ¶Ğ½Ñ‹Ğµ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ."
    },
    "zh": {
        "åŒ…å«å…‰ç…§ä¿¡æ¯": "åŒ…å«å…‰ç…§ä¿¡æ¯ã€‚",
        "åŒ…å«ç›¸æœºè§’åº¦": "åŒ…å«ç›¸æœºè§’åº¦ä¿¡æ¯ã€‚",
        "æåŠæ°´å°": "è¯´æ˜å›¾ç‰‡æ˜¯å¦æœ‰æ°´å°ã€‚",
        "æåŠJPEGä¼ªå½±": "è¯´æ˜å›¾ç‰‡æ˜¯å¦æœ‰JPEGä¼ªå½±ã€‚",
        "åŒ…å«ç›¸æœº/ç…§ç‰‡è¯¦æƒ…": "å¦‚æœæ˜¯ç…§ç‰‡ï¼ŒåŒ…å«å¯èƒ½ä½¿ç”¨çš„ç›¸æœºä¿¡æ¯ï¼Œå¦‚å…‰åœˆã€å¿«é—¨é€Ÿåº¦ã€ISOç­‰ã€‚",
        "ä¿æŒSFW/PGçº§åˆ«": "ä¸è¦åŒ…å«ä»»ä½•æ€§ç›¸å…³å†…å®¹ï¼Œä¿æŒPGçº§åˆ«ã€‚",
        "ä¸è¦æåŠåˆ†è¾¨ç‡": "ä¸è¦æåŠå›¾ç‰‡çš„åˆ†è¾¨ç‡ã€‚",
        "åŒ…å«ç¾å­¦è´¨é‡è¯„ä»·": "åŒ…å«ä»ä½åˆ°éå¸¸é«˜çš„ä¸»è§‚ç¾å­¦è´¨é‡è¯„ä»·ã€‚",
        "åŒ…å«æ„å›¾é£æ ¼": "åŒ…å«æ„å›¾é£æ ¼ä¿¡æ¯ï¼Œå¦‚å¼•å¯¼çº¿ã€ä¸‰åˆ†æ³•åˆ™æˆ–å¯¹ç§°æ€§ã€‚",
        "ä¸è¦æåŠå›¾ç‰‡ä¸­çš„æ–‡å­—": "ä¸è¦æåŠå›¾ç‰‡ä¸­çš„ä»»ä½•æ–‡å­—ã€‚",
        "åŒ…å«æ™¯æ·±ä¿¡æ¯": "è¯´æ˜æ™¯æ·±ä»¥åŠèƒŒæ™¯æ˜¯å¦æ¨¡ç³Šã€‚",
        "åªæè¿°å…³é”®å…ƒç´ ": "åªæè¿°å›¾ç‰‡ä¸­æœ€é‡è¦çš„å…ƒç´ ã€‚"
    }
}

# Extra options for VIDEO description enhancement
EXTRA_OPTIONS_VIDEO = {
    "en": {
        "Describe camera movement": "Describe camera movements (panning, zooming, static, etc.).",
        "Include audio description": "If the video has audio, describe it (music, speech, sound effects).",
        "Describe plot/story": "Describe the plot or story progression in the video.",
        "Include lighting info": "Include information about lighting changes throughout the video.",
        "Include editing style": "Describe the editing style (cuts, transitions, effects).",
        "Keep it SFW/PG": "Do NOT include anything sexual; keep it PG.",
        "Describe only key moments": "ONLY describe the most important moments in the video.",
        "Include aesthetic quality": "Include information about the subjective aesthetic quality from low to very high."
    },
    "ru": {
        "ĞĞ¿Ğ¸ÑĞ°Ñ‚ÑŒ Ğ´Ğ²Ğ¸Ğ¶ĞµĞ½Ğ¸Ğµ ĞºĞ°Ğ¼ĞµÑ€Ñ‹": "ĞĞ¿Ğ¸ÑˆĞ¸ Ğ´Ğ²Ğ¸Ğ¶ĞµĞ½Ğ¸Ñ ĞºĞ°Ğ¼ĞµÑ€Ñ‹ (Ğ¿Ğ°Ğ½Ğ¾Ñ€Ğ°Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ, Ğ·ÑƒĞ¼, ÑÑ‚Ğ°Ñ‚Ğ¸Ñ‡Ğ½Ğ°Ñ Ğ¸ Ñ‚.Ğ´.).",
        "Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ·Ğ²ÑƒĞºĞ°": "Ğ•ÑĞ»Ğ¸ Ğ² Ğ²Ğ¸Ğ´ĞµĞ¾ ĞµÑÑ‚ÑŒ Ğ·Ğ²ÑƒĞº, Ğ¾Ğ¿Ğ¸ÑˆĞ¸ ĞµĞ³Ğ¾ (Ğ¼ÑƒĞ·Ñ‹ĞºĞ°, Ñ€ĞµÑ‡ÑŒ, Ğ·Ğ²ÑƒĞºĞ¾Ğ²Ñ‹Ğµ ÑÑ„Ñ„ĞµĞºÑ‚Ñ‹).",
        "ĞĞ¿Ğ¸ÑĞ°Ñ‚ÑŒ ÑÑĞ¶ĞµÑ‚/Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ": "ĞĞ¿Ğ¸ÑˆĞ¸ ÑÑĞ¶ĞµÑ‚ Ğ¸Ğ»Ğ¸ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ğµ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ² Ğ²Ğ¸Ğ´ĞµĞ¾.",
        "Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ± Ğ¾ÑĞ²ĞµÑ‰ĞµĞ½Ğ¸Ğ¸": "Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ± Ğ¸Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸ÑÑ… Ğ¾ÑĞ²ĞµÑ‰ĞµĞ½Ğ¸Ñ Ğ² Ñ‚ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ²Ğ¸Ğ´ĞµĞ¾.",
        "Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ ÑÑ‚Ğ¸Ğ»ÑŒ Ğ¼Ğ¾Ğ½Ñ‚Ğ°Ğ¶Ğ°": "ĞĞ¿Ğ¸ÑˆĞ¸ ÑÑ‚Ğ¸Ğ»ÑŒ Ğ¼Ğ¾Ğ½Ñ‚Ğ°Ğ¶Ğ° (Ğ¿ĞµÑ€ĞµÑ…Ğ¾Ğ´Ñ‹, ÑÑ„Ñ„ĞµĞºÑ‚Ñ‹).",
        "Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ SFW/PG Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³": "ĞĞ• Ğ²ĞºĞ»ÑÑ‡Ğ°Ğ¹ ÑĞµĞºÑÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚, ÑĞ¾Ñ…Ñ€Ğ°Ğ½ÑĞ¹ Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³ PG.",
        "ĞĞ¿Ğ¸ÑÑ‹Ğ²Ğ°Ñ‚ÑŒ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚Ñ‹": "ĞĞ¿Ğ¸ÑÑ‹Ğ²Ğ°Ğ¹ Ğ¢ĞĞ›Ğ¬ĞšĞ ÑĞ°Ğ¼Ñ‹Ğµ Ğ²Ğ°Ğ¶Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ¼ĞµĞ½Ñ‚Ñ‹ Ğ²Ğ¸Ğ´ĞµĞ¾.",
        "Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ ÑÑÑ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºÑƒÑ Ğ¾Ñ†ĞµĞ½ĞºÑƒ": "Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ ÑÑƒĞ±ÑŠĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ¼ ÑÑÑ‚ĞµÑ‚Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ¼ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğµ Ğ¾Ñ‚ Ğ½Ğ¸Ğ·ĞºĞ¾Ğ³Ğ¾ Ğ´Ğ¾ Ğ¾Ñ‡ĞµĞ½ÑŒ Ğ²Ñ‹ÑĞ¾ĞºĞ¾Ğ³Ğ¾."
    },
    "zh": {
        "æè¿°é•œå¤´è¿åŠ¨": "æè¿°é•œå¤´è¿åŠ¨ï¼ˆå¹³ç§»ã€ç¼©æ”¾ã€é™æ­¢ç­‰ï¼‰ã€‚",
        "åŒ…å«éŸ³é¢‘æè¿°": "å¦‚æœè§†é¢‘æœ‰éŸ³é¢‘ï¼Œæè¿°å®ƒï¼ˆéŸ³ä¹ã€è¯­éŸ³ã€éŸ³æ•ˆï¼‰ã€‚",
        "æè¿°æƒ…èŠ‚/æ•…äº‹": "æè¿°è§†é¢‘ä¸­çš„æƒ…èŠ‚æˆ–æ•…äº‹å‘å±•ã€‚",
        "åŒ…å«å…‰ç…§ä¿¡æ¯": "åŒ…å«è§†é¢‘ä¸­å…‰ç…§å˜åŒ–çš„ä¿¡æ¯ã€‚",
        "åŒ…å«å‰ªè¾‘é£æ ¼": "æè¿°å‰ªè¾‘é£æ ¼ï¼ˆåˆ‡æ¢ã€è¿‡æ¸¡ã€æ•ˆæœï¼‰ã€‚",
        "ä¿æŒSFW/PGçº§åˆ«": "ä¸è¦åŒ…å«ä»»ä½•æ€§ç›¸å…³å†…å®¹ï¼Œä¿æŒPGçº§åˆ«ã€‚",
        "åªæè¿°å…³é”®æ—¶åˆ»": "åªæè¿°è§†é¢‘ä¸­æœ€é‡è¦çš„æ—¶åˆ»ã€‚",
        "åŒ…å«ç¾å­¦è´¨é‡è¯„ä»·": "åŒ…å«ä»ä½åˆ°éå¸¸é«˜çš„ä¸»è§‚ç¾å­¦è´¨é‡è¯„ä»·ã€‚"
    }
}

def get_memory_info() -> str:
    """Get current memory usage information"""
    info_parts = []

    # GPU memory
    if torch.cuda.is_available():
        try:
            allocated = torch.cuda.memory_allocated() / (1024 ** 3)
            reserved = torch.cuda.memory_reserved() / (1024 ** 3)
            total = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)
            info_parts.append(f"GPU: {allocated:.1f}/{total:.1f} GB (reserved: {reserved:.1f} GB)")
        except:
            pass

    # RAM
    if PSUTIL_AVAILABLE:
        try:
            process = psutil.Process(os.getpid())
            ram_usage = process.memory_info().rss / (1024 ** 3)
            info_parts.append(f"RAM: {ram_usage:.1f} GB")
        except:
            pass

    return " | ".join(info_parts) if info_parts else "Memory info unavailable"

def load_prompt_presets() -> dict:
    """Load prompt presets from the prompts directory"""
    presets = {"None": ""}

    if not os.path.exists(PROMPTS_DIR):
        return presets

    for filename in os.listdir(PROMPTS_DIR):
        if filename.endswith('.txt'):
            preset_name = os.path.splitext(filename)[0]
            try:
                with open(os.path.join(PROMPTS_DIR, filename), 'r', encoding='utf-8') as f:
                    presets[preset_name] = f.read().strip()
            except:
                pass

    return presets

def save_prompt_preset(name: str, prompt: str) -> str:
    """Save a prompt preset to the prompts directory"""
    if not name or not name.strip():
        if current_language == "ru":
            return "âŒ Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ¸Ğ¼Ñ Ğ¿Ñ€ĞµÑĞµÑ‚Ğ°"
        return "âŒ Please provide a preset name"

    if not prompt or not prompt.strip():
        if current_language == "ru":
            return "âŒ Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ´Ğ»Ñ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ"
        return "âŒ Please provide a prompt to save"

    # Sanitize filename
    safe_name = "".join(c for c in name if c.isalnum() or c in "_ -").strip()
    if not safe_name:
        if current_language == "ru":
            return "âŒ ĞĞµĞ´Ğ¾Ğ¿ÑƒÑÑ‚Ğ¸Ğ¼Ğ¾Ğµ Ğ¸Ğ¼Ñ Ğ¿Ñ€ĞµÑĞµÑ‚Ğ°"
        return "âŒ Invalid preset name"

    try:
        os.makedirs(PROMPTS_DIR, exist_ok=True)
        filepath = os.path.join(PROMPTS_DIR, f"{safe_name}.txt")
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(prompt.strip())
        if current_language == "ru":
            return f"âœ… ĞŸÑ€ĞµÑĞµÑ‚ '{safe_name}' ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½!"
        return f"âœ… Preset '{safe_name}' saved successfully!"
    except Exception as e:
        if current_language == "ru":
            return f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ: {str(e)}"
        return f"âŒ Error saving preset: {str(e)}"

def save_text_to_file(text: str, filename: str = "result.txt") -> str:
    """Save text to a temporary file and return the path"""
    temp_file = os.path.join(TEMP_DIR, filename)
    with open(temp_file, 'w', encoding='utf-8') as f:
        f.write(text)
    return temp_file

def stop_generation():
    """Set the stop flag to True"""
    global stop_generation_flag
    stop_generation_flag = True
    return "ğŸ›‘ Stopping generation..."

def reset_stop_flag():
    """Reset the stop flag"""
    global stop_generation_flag
    stop_generation_flag = False

# Custom CSS for beautiful UI
CUSTOM_CSS = """
/* Main container styling */
.gradio-container {
    background: linear-gradient(135deg, #f8fafc 0%, #e2e8f0 100%) !important;
}

/* Card style blocks */
.card-style {
    background: rgba(255, 255, 255, 0.9) !important;
    border: 1px solid rgba(203, 213, 225, 0.5) !important;
    box-shadow: 0 8px 32px rgba(100, 116, 139, 0.1) !important;
    border-radius: 16px !important;
    padding: 1.5rem !important;
    margin-bottom: 1rem !important;
}

/* Main header with gradient */
.main-header {
    background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
    padding: 2rem;
    border-radius: 20px;
    margin-bottom: 1.5rem;
    text-align: center;
    box-shadow: 0 10px 40px rgba(102, 126, 234, 0.3);
}

.main-header h1 {
    color: white !important;
    font-size: 2.5rem !important;
    font-weight: 700 !important;
    margin: 0 !important;
    text-shadow: 0 2px 4px rgba(0,0,0,0.3);
}

.main-header p {
    color: rgba(255,255,255,0.9) !important;
    font-size: 1.1rem !important;
    margin: 0.5rem 0 0 0 !important;
}

.main-header a {
    color: white !important;
    text-decoration: underline;
}

/* Generate button styling */
.generate-btn {
    min-height: 36px !important;
    font-size: 0.95rem !important;
    font-weight: 500 !important;
    padding: 8px 16px !important;
}

/* Status box */
.status-box {
    background: linear-gradient(135deg, #f0f9ff 0%, #e0f2fe 100%) !important;
    border: 1px solid #7dd3fc !important;
    border-radius: 12px !important;
    padding: 1rem !important;
}

/* Progress info */
.progress-info {
    background: #f0fdf4 !important;
    border: 1px solid #86efac !important;
    border-radius: 8px !important;
    padding: 0.75rem !important;
}

/* Dark mode support */
.dark .gradio-container {
    background: linear-gradient(135deg, #0f172a 0%, #1e293b 100%) !important;
}

.dark .card-style {
    background: rgba(30, 41, 59, 0.9) !important;
    border: 1px solid rgba(51, 65, 85, 0.5) !important;
    box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3) !important;
}

.dark .status-box {
    background: linear-gradient(135deg, #1e3a5f 0%, #1e293b 100%) !important;
    border: 1px solid #3b82f6 !important;
}

.dark .progress-info {
    background: #14532d !important;
    border: 1px solid #22c55e !important;
}

/* Accordion styling */
.settings-accordion {
    border-radius: 12px !important;
    overflow: hidden !important;
}

/* Result variants */
.variant-box {
    border: 2px solid #e2e8f0;
    border-radius: 12px;
    padding: 1rem;
    margin-bottom: 0.5rem;
    transition: all 0.2s ease;
}

.variant-box:hover {
    border-color: #667eea;
    box-shadow: 0 4px 12px rgba(102, 126, 234, 0.15);
}

/* Export buttons */
.export-btn {
    margin: 0.25rem !important;
}
"""

# Description types with prompts
DESCRIPTION_TYPES = {
    "en": {
        "Descriptive (Formal)": "Write a detailed and formal description of this image.",
        "Descriptive (Informal)": "Write a casual, friendly description of this image.",
        "Product Description": "Write a compelling product description for e-commerce based on this image.",
        "SEO Description": "Write an SEO-optimized description for this image, maximum 160 characters.",
        "Stable Diffusion Prompt": "Write a detailed Stable Diffusion prompt to recreate this image.",
        "MidJourney Prompt": "Write a MidJourney prompt to recreate this image.",
        "Booru Tags": "Write a list of Booru-style tags for this image, separated by commas.",
        "Art Critic Analysis": "Analyze this image like an art critic, discussing composition, style, color, lighting, and artistic elements.",
        "Social Media Caption": "Write an engaging social media caption for this image.",
        "OCR: Extract all text": "Extract ALL text from the image. Read every word, number, and symbol visible.",
        "OCR: Text with coordinates": "Extract all text and provide position coordinates [x1, y1, x2, y2] for each text region.",
        "OCR: Table to HTML": "If there is a table, convert it to HTML format using <table>, <tr>, and <td> tags.",
        "OCR: Structured JSON": "Extract all information in structured JSON format with key-value pairs.",
        "Custom": ""
    },
    "ru": {
        "ĞĞ¿Ğ¸ÑĞ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ (Ñ„Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹)": "ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¸ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ.",
        "ĞĞ¿Ğ¸ÑĞ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ (Ğ½ĞµÑ„Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹)": "ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ğ½ĞµĞ¿Ñ€Ğ¸Ğ½ÑƒĞ¶Ğ´Ñ‘Ğ½Ğ½Ğ¾Ğµ, Ğ´Ñ€ÑƒĞ¶ĞµĞ»ÑĞ±Ğ½Ğ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ.",
        "ĞĞ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ°": "ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ğ¿Ñ€Ğ¸Ğ²Ğ»ĞµĞºĞ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ° Ğ´Ğ»Ñ Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚-Ğ¼Ğ°Ğ³Ğ°Ğ·Ğ¸Ğ½Ğ° Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ.",
        "SEO Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ": "ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ SEO-Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ, Ğ¼Ğ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ 160 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ².",
        "ĞŸÑ€Ğ¾Ğ¼Ğ¿Ñ‚ Stable Diffusion": "ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ´Ğ»Ñ Stable Diffusion, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ²Ğ¾ÑÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ ÑÑ‚Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ.",
        "ĞŸÑ€Ğ¾Ğ¼Ğ¿Ñ‚ MidJourney": "ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ´Ğ»Ñ MidJourney, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ²Ğ¾ÑÑĞ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ ÑÑ‚Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ.",
        "Ğ¢ĞµĞ³Ğ¸ Booru": "ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ ÑĞ¿Ğ¸ÑĞ¾Ğº Ñ‚ĞµĞ³Ğ¾Ğ² Ğ² ÑÑ‚Ğ¸Ğ»Ğµ Booru Ğ´Ğ»Ñ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ, Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ñ‘Ğ½Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ¿ÑÑ‚Ñ‹Ğ¼Ğ¸.",
        "ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ¸ÑĞºÑƒÑÑÑ‚Ğ²Ğ¾Ğ²ĞµĞ´Ğ°": "ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞ¹ ÑÑ‚Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ ĞºĞ°Ğº Ğ¸ÑĞºÑƒÑÑÑ‚Ğ²Ğ¾Ğ²ĞµĞ´, Ğ¾Ğ±ÑÑƒĞ¶Ğ´Ğ°Ñ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ, ÑÑ‚Ğ¸Ğ»ÑŒ, Ñ†Ğ²ĞµÑ‚, Ğ¾ÑĞ²ĞµÑ‰ĞµĞ½Ğ¸Ğµ Ğ¸ Ñ…ÑƒĞ´Ğ¾Ğ¶ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğµ ÑĞ»ĞµĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ.",
        "ĞŸĞ¾ÑÑ‚ Ğ´Ğ»Ñ ÑĞ¾Ñ†ÑĞµÑ‚ĞµĞ¹": "ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ğ¿Ñ€Ğ¸Ğ²Ğ»ĞµĞºĞ°Ñ‚ĞµĞ»ÑŒĞ½ÑƒÑ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑÑŒ Ğ´Ğ»Ñ ÑĞ¾Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ÑĞµÑ‚ĞµĞ¹ Ğº ÑÑ‚Ğ¾Ğ¼Ñƒ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ.",
        "OCR: Ğ˜Ğ·Ğ²Ğ»ĞµÑ‡ÑŒ Ğ²ĞµÑÑŒ Ñ‚ĞµĞºÑÑ‚": "Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ¸ Ğ’Ğ•Ğ¡Ğ¬ Ñ‚ĞµĞºÑÑ‚ Ñ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ. ĞŸÑ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ğ¹ ĞºĞ°Ğ¶Ğ´Ğ¾Ğµ ÑĞ»Ğ¾Ğ²Ğ¾, Ñ†Ğ¸Ñ„Ñ€Ñƒ Ğ¸ ÑĞ¸Ğ¼Ğ²Ğ¾Ğ».",
        "OCR: Ğ¢ĞµĞºÑÑ‚ Ñ ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ‚Ğ°Ğ¼Ğ¸": "Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ¸ Ğ²ĞµÑÑŒ Ñ‚ĞµĞºÑÑ‚ Ğ¸ ÑƒĞºĞ°Ğ¶Ğ¸ ĞºĞ¾Ğ¾Ñ€Ğ´Ğ¸Ğ½Ğ°Ñ‚Ñ‹ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ [x1, y1, x2, y2] Ğ´Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ²Ğ¾Ğ¹ Ğ¾Ğ±Ğ»Ğ°ÑÑ‚Ğ¸.",
        "OCR: Ğ¢Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ° Ğ² HTML": "Ğ•ÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ğ°, Ğ¿Ñ€ĞµĞ¾Ğ±Ñ€Ğ°Ğ·ÑƒĞ¹ ĞµÑ‘ Ğ² HTML Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ñ Ñ‚ĞµĞ³Ğ°Ğ¼Ğ¸ <table>, <tr> Ğ¸ <td>.",
        "OCR: Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ JSON": "Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ¸ Ğ²ÑÑ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ² ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ğ¾Ğ¼ JSON Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ Ñ ĞºĞ»ÑÑ‡Ğ°Ğ¼Ğ¸ Ğ¸ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸ÑĞ¼Ğ¸.",
        "Ğ¡Ğ²Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚": ""
    },
    "zh": {
        "æè¿°æ€§ï¼ˆæ­£å¼ï¼‰": "å†™ä¸€ä¸ªè¯¦ç»†æ­£å¼çš„å›¾åƒæè¿°ã€‚",
        "æè¿°æ€§ï¼ˆéæ­£å¼ï¼‰": "å†™ä¸€ä¸ªè½»æ¾å‹å¥½çš„å›¾åƒæè¿°ã€‚",
        "äº§å“æè¿°": "æ ¹æ®è¿™å¼ å›¾ç‰‡ä¸ºç”µå•†å¹³å°å†™ä¸€ä¸ªå¸å¼•äººçš„äº§å“æè¿°ã€‚",
        "SEOæè¿°": "ä¸ºè¿™å¼ å›¾ç‰‡å†™ä¸€ä¸ªSEOä¼˜åŒ–çš„æè¿°ï¼Œæœ€å¤š160ä¸ªå­—ç¬¦ã€‚",
        "Stable Diffusionæç¤ºè¯": "å†™ä¸€ä¸ªè¯¦ç»†çš„Stable Diffusionæç¤ºè¯æ¥é‡ç°è¿™å¼ å›¾ç‰‡ã€‚",
        "MidJourneyæç¤ºè¯": "å†™ä¸€ä¸ªMidJourneyæç¤ºè¯æ¥é‡ç°è¿™å¼ å›¾ç‰‡ã€‚",
        "Booruæ ‡ç­¾": "ä¸ºè¿™å¼ å›¾ç‰‡å†™ä¸€ä¸ªBoorué£æ ¼çš„æ ‡ç­¾åˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš”ã€‚",
        "è‰ºæœ¯è¯„è®ºåˆ†æ": "åƒè‰ºæœ¯è¯„è®ºå®¶ä¸€æ ·åˆ†æè¿™å¼ å›¾ç‰‡ï¼Œè®¨è®ºæ„å›¾ã€é£æ ¼ã€è‰²å½©ã€å…‰çº¿å’Œè‰ºæœ¯å…ƒç´ ã€‚",
        "ç¤¾äº¤åª’ä½“æ–‡æ¡ˆ": "ä¸ºè¿™å¼ å›¾ç‰‡å†™ä¸€ä¸ªå¸å¼•äººçš„ç¤¾äº¤åª’ä½“æ–‡æ¡ˆã€‚",
        "OCR: æå–æ‰€æœ‰æ–‡å­—": "æå–å›¾ç‰‡ä¸­çš„æ‰€æœ‰æ–‡å­—ã€‚è¯»å–æ¯ä¸ªå•è¯ã€æ•°å­—å’Œç¬¦å·ã€‚",
        "OCR: æ–‡å­—ä¸åæ ‡": "æå–æ‰€æœ‰æ–‡å­—å¹¶æä¾›æ¯ä¸ªæ–‡å­—åŒºåŸŸçš„ä½ç½®åæ ‡[x1, y1, x2, y2]ã€‚",
        "OCR: è¡¨æ ¼è½¬HTML": "å¦‚æœæœ‰è¡¨æ ¼ï¼Œå°†å…¶è½¬æ¢ä¸ºHTMLæ ¼å¼ï¼Œä½¿ç”¨<table>ã€<tr>å’Œ<td>æ ‡ç­¾ã€‚",
        "OCR: ç»“æ„åŒ–JSON": "ä»¥ç»“æ„åŒ–JSONæ ¼å¼æå–æ‰€æœ‰ä¿¡æ¯ï¼ŒåŒ…å«é”®å€¼å¯¹ã€‚",
        "è‡ªå®šä¹‰": ""
    }
}

# Description lengths
DESCRIPTION_LENGTHS = {
    "en": {
        "Any": "",
        "Very Short (1-2 sentences)": "Keep it very short, 1-2 sentences maximum.",
        "Short (3-4 sentences)": "Keep it short, 3-4 sentences.",
        "Medium (1 paragraph)": "Write a medium-length description, about one paragraph.",
        "Long (2-3 paragraphs)": "Write a detailed description, 2-3 paragraphs.",
        "Very Long (comprehensive)": "Write a comprehensive and very detailed description."
    },
    "ru": {
        "Ğ›ÑĞ±Ğ°Ñ": "",
        "ĞÑ‡ĞµĞ½ÑŒ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ°Ñ (1-2 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ)": "Ğ¡Ğ´ĞµĞ»Ğ°Ğ¹ Ğ¾Ñ‡ĞµĞ½ÑŒ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¾, Ğ¼Ğ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ 1-2 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ.",
        "ĞšĞ¾Ñ€Ğ¾Ñ‚ĞºĞ°Ñ (3-4 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ)": "Ğ¡Ğ´ĞµĞ»Ğ°Ğ¹ ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¾, 3-4 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ.",
        "Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ (1 Ğ°Ğ±Ğ·Ğ°Ñ†)": "ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ ÑÑ€ĞµĞ´Ğ½ĞµĞ¹ Ğ´Ğ»Ğ¸Ğ½Ñ‹, Ğ¾ĞºĞ¾Ğ»Ğ¾ Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ°Ğ±Ğ·Ğ°Ñ†Ğ°.",
        "Ğ”Ğ»Ğ¸Ğ½Ğ½Ğ°Ñ (2-3 Ğ°Ğ±Ğ·Ğ°Ñ†Ğ°)": "ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ, 2-3 Ğ°Ğ±Ğ·Ğ°Ñ†Ğ°.",
        "ĞÑ‡ĞµĞ½ÑŒ Ğ´Ğ»Ğ¸Ğ½Ğ½Ğ°Ñ (Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ°Ñ)": "ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ğ¸ÑÑ‡ĞµÑ€Ğ¿Ñ‹Ğ²Ğ°ÑÑ‰ĞµĞµ Ğ¸ Ğ¾Ñ‡ĞµĞ½ÑŒ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ."
    },
    "zh": {
        "ä»»æ„": "",
        "éå¸¸çŸ­ï¼ˆ1-2å¥ï¼‰": "ä¿æŒéå¸¸ç®€çŸ­ï¼Œæœ€å¤š1-2å¥ã€‚",
        "çŸ­ï¼ˆ3-4å¥ï¼‰": "ä¿æŒç®€çŸ­ï¼Œ3-4å¥ã€‚",
        "ä¸­ç­‰ï¼ˆ1æ®µï¼‰": "å†™ä¸€ä¸ªä¸­ç­‰é•¿åº¦çš„æè¿°ï¼Œå¤§çº¦ä¸€æ®µã€‚",
        "é•¿ï¼ˆ2-3æ®µï¼‰": "å†™ä¸€ä¸ªè¯¦ç»†çš„æè¿°ï¼Œ2-3æ®µã€‚",
        "éå¸¸é•¿ï¼ˆå…¨é¢ï¼‰": "å†™ä¸€ä¸ªå…¨é¢ä¸”éå¸¸è¯¦ç»†çš„æè¿°ã€‚"
    }
}

# Multi-language support
TRANSLATIONS = {
    "en": {
        "title": "Qwen VL Image Description Generator",
        "header": "ğŸ–¼ï¸ Image Description Generator based on Qwen Vision Language Models",
        "subtitle": "Upload an image and enter a prompt to generate a description using Qwen VL models.",
        "language": "Language",
        "language_info": "Select language",
        "model_selection": "Model Selection",
        "model_info": "Select a model for generating descriptions",
        "advanced_params": "âš™ï¸ Advanced Parameters",
        "max_tokens": "Max New Tokens",
        "max_tokens_info": "Maximum number of tokens to generate",
        "temperature": "Temperature",
        "temperature_info": "Controls randomness of generation",
        "top_p": "Top-p (nucleus sampling)",
        "top_p_info": "Probability threshold for token sampling",
        "top_k": "Top-k",
        "top_k_info": "Number of most probable tokens to consider",
        "seed": "Seed",
        "seed_info": "Seed for reproducibility (-1 for random)",
        "random_seed_btn": "ğŸ² Random Seed",
        "single_processing": "ğŸ“„ Single Processing",
        "batch_processing": "ğŸ“š Batch Processing",
        "upload_image": "Upload Image",
        "image_url": "Or enter Image URL",
        "image_url_placeholder": "https://example.com/image.jpg",
        "prompt": "Prompt",
        "prompt_placeholder": "For example: Create a product description for online store",
        "generate_btn": "ğŸš€ Generate Description",
        "result": "Result",
        "upload_images": "Upload Images",
        "prompts_multiline": "Prompts (one per line)",
        "prompts_placeholder": "Create a product description for online store\nCreate SEO Description for product\n...",
        "prompts_info": "Specify one prompt for all images or one prompt per image",
        "process_batch_btn": "ğŸš€ Process Batch",
        "results": "Results",
        "examples_title": "ğŸ’¡ Example Prompts:",
        "example_1": "Create a product description for online store",
        "example_2": "Create an SEO description for a product with a maximum of 160 characters.",
        "example_3": "Create an attractive product description for marketplace",
        "example_4": "Describe image in detail for product catalog",
        "error_no_image": "Please upload an image or provide an image URL",
        "error_no_prompt": "Please enter a prompt",
        "error_no_images": "Please upload images",
        "error_no_prompts": "Please enter prompts (one per line)",
        "error_prompt_mismatch": "Number of prompts ({}) does not match number of images ({}). Specify either one prompt for all images or one prompt per image.",
        "error_generation": "Error generating description: {}",
        "error_url_load": "Error loading image from URL: {}",
        "loading_model": "Loading model: {}",
        "model_loaded": "Model {} successfully loaded on {}",
        "image_label": "=== Image {}: {} ===",
        "prompt_label": "Prompt: {}",
        "result_label": "Result: {}",
        "model_size_warning": "âš ï¸ Note: Large models (8B+) may use CPU offloading if GPU memory is insufficient, which can slow down generation.",
        "quantization": "Quantization",
        "quantization_info": "Memory optimization (4-bit = ~75% less VRAM)",
        "quant_4bit": "4-bit (Recommended)",
        "quant_8bit": "8-bit (Better quality)",
        "quant_none": "None (Full precision)",
        "description_type": "Description Type",
        "description_type_info": "Select the type/style of description",
        "description_length": "Description Length",
        "description_length_info": "Select desired length",
        "num_variants": "Number of Variants",
        "num_variants_info": "Generate multiple description variants",
        "custom_prompt_override": "Custom Prompt (overrides type selection)",
        "custom_prompt_placeholder": "Enter your custom prompt here...",
        "status": "Status",
        "processing_time": "Processing time",
        "generating": "â³ Generating...",
        "stop_btn": "ğŸ›‘ Stop",
        "save_results": "ğŸ’¾ Save Results",
        "output_folder": "Output Folder Name",
        "output_folder_placeholder": "my_dataset",
        "export_format": "Export Format",
        "export_txt": "TXT (one file per image)",
        "export_json": "JSON (all results)",
        "export_csv": "CSV (table format)",
        "variant": "Variant",
        "copy_btn": "ğŸ“‹ Copy",
        "download_btn": "â¬‡ï¸ Download",
        "generation_complete": "âœ… Generation complete!",
        "seconds": "seconds",
        "processing_image": "Processing image",
        "of": "of",
        "extra_options": "Extra Options",
        "extra_options_info": "Additional modifiers for description",
        "character_name": "Character/Person Name",
        "character_name_placeholder": "e.g., John, Alice, or leave empty",
        "character_name_info": "If provided, will use this name instead of generic terms",
        "prompt_preset": "Prompt Preset",
        "prompt_preset_info": "Load a preset from prompts/ folder",
        "refresh_presets": "Refresh",
        "memory_usage": "Memory Usage",
        "download_result": "Download Result",
        "generation_stopped": "Generation stopped by user",
        "stopping": "Stopping..."
    },
    "ru": {
        "title": "Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğ¹ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Qwen VL",
        "header": "ğŸ–¼ï¸ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğ¹ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Qwen Vision Language Models",
        "subtitle": "Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¸ Ğ²Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ¿Ñ€Ğ¾Ğ¼Ñ‚ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Qwen VL.",
        "language": "Ğ¯Ğ·Ñ‹Ğº",
        "language_info": "Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ ÑĞ·Ñ‹Ğº",
        "model_selection": "Ğ’Ñ‹Ğ±Ğ¾Ñ€ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸",
        "model_info": "Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğ¹",
        "advanced_params": "âš™ï¸ Ğ Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ñ‹Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹",
        "max_tokens": "ĞœĞ°ĞºÑ. ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ½Ğ¾Ğ²Ñ‹Ñ… Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²",
        "max_tokens_info": "ĞœĞ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸",
        "temperature": "Ğ¢ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ°",
        "temperature_info": "ĞšĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»Ğ¸Ñ€ÑƒĞµÑ‚ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ğ¾ÑÑ‚ÑŒ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸",
        "top_p": "Top-p (nucleus sampling)",
        "top_p_info": "Ğ’ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ñ€Ğ¾Ğ³ Ğ´Ğ»Ñ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞ¸ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²",
        "top_k": "Top-k",
        "top_k_info": "ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ½Ğ°Ğ¸Ğ±Ğ¾Ğ»ĞµĞµ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ñ‹Ñ… Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ´Ğ»Ñ Ñ€Ğ°ÑÑĞ¼Ğ¾Ñ‚Ñ€ĞµĞ½Ğ¸Ñ",
        "seed": "Seed",
        "seed_info": "Seed Ğ´Ğ»Ñ Ğ²Ğ¾ÑĞ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ (-1 Ğ´Ğ»Ñ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ğ¾Ğ³Ğ¾)",
        "random_seed_btn": "ğŸ² Ğ¡Ğ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ñ‹Ğ¹ seed",
        "single_processing": "ğŸ“„ ĞĞ´Ğ¸Ğ½Ğ¾Ñ‡Ğ½Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°",
        "batch_processing": "ğŸ“š ĞŸĞ°ĞºĞµÑ‚Ğ½Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°",
        "upload_image": "Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ",
        "image_url": "Ğ˜Ğ»Ğ¸ Ğ²Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ URL Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ",
        "image_url_placeholder": "https://example.com/image.jpg",
        "prompt": "ĞŸÑ€Ğ¾Ğ¼Ñ‚",
        "prompt_placeholder": "ĞĞ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€: Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ° Ğ´Ğ»Ñ Ğ¾Ğ½Ğ»Ğ°Ğ¹Ğ½ Ğ¼Ğ°Ğ³Ğ°Ğ·Ğ¸Ğ½Ğ°",
        "generate_btn": "ğŸš€ Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ",
        "result": "Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚",
        "upload_images": "Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ",
        "prompts_multiline": "ĞŸÑ€Ğ¾Ğ¼Ñ‚Ñ‹ (Ğ¿Ğ¾ Ğ¾Ğ´Ğ½Ğ¾Ğ¼Ñƒ Ğ½Ğ° ÑÑ‚Ñ€Ğ¾ĞºÑƒ)",
        "prompts_placeholder": "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ° Ğ´Ğ»Ñ Ğ¾Ğ½Ğ»Ğ°Ğ¹Ğ½ Ğ¼Ğ°Ğ³Ğ°Ğ·Ğ¸Ğ½Ğ°\nĞ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ SEO-Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ°\n...",
        "prompts_info": "Ğ£ĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ Ğ¾Ğ´Ğ¸Ğ½ Ğ¿Ñ€Ğ¾Ğ¼Ñ‚ Ğ´Ğ»Ñ Ğ²ÑĞµÑ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ Ğ¸Ğ»Ğ¸ Ğ¿Ğ¾ Ğ¾Ğ´Ğ½Ğ¾Ğ¼Ñƒ Ğ¿Ñ€Ğ¾Ğ¼Ñ‚Ñƒ Ğ½Ğ° ĞºĞ°Ğ¶Ğ´Ğ¾Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ",
        "process_batch_btn": "ğŸš€ ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ğ¿Ğ°ĞºĞµÑ‚",
        "results": "Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹",
        "examples_title": "ğŸ’¡ ĞŸÑ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ¿Ñ€Ğ¾Ğ¼Ñ‚Ğ¾Ğ²:",
        "example_1": "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ° ''  Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ",
        "example_2": "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ SEO-Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ° Ğ¼Ğ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ 160 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ² Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ",
        "example_3": "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ²Ğ»ĞµĞºĞ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾Ğµ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ğ° Ğ´Ğ»Ñ Ğ¼Ğ°Ñ€ĞºĞµÑ‚Ğ¿Ğ»ĞµĞ¹ÑĞ° Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ",
        "example_4": "Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ¾Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ Ğ´Ğ»Ñ ĞºĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³Ğ° Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ¾Ğ² Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ",
        "error_no_image": "ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ Ğ¸Ğ»Ğ¸ ÑƒĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ URL Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ",
        "error_no_prompt": "ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ²Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ¿Ñ€Ğ¾Ğ¼Ñ‚",
        "error_no_images": "ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ·Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ",
        "error_no_prompts": "ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ²Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ Ğ¿Ñ€Ğ¾Ğ¼Ñ‚Ñ‹ (Ğ¿Ğ¾ Ğ¾Ğ´Ğ½Ğ¾Ğ¼Ñƒ Ğ½Ğ° ÑÑ‚Ñ€Ğ¾ĞºÑƒ)",
        "error_prompt_mismatch": "ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¿Ñ€Ğ¾Ğ¼Ñ‚Ğ¾Ğ² ({}) Ğ½Ğµ ÑĞ¾Ğ²Ğ¿Ğ°Ğ´Ğ°ĞµÑ‚ Ñ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾Ğ¼ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹ ({}). Ğ£ĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ Ğ»Ğ¸Ğ±Ğ¾ Ğ¾Ğ´Ğ¸Ğ½ Ğ¿Ñ€Ğ¾Ğ¼Ñ‚ Ğ´Ğ»Ñ Ğ²ÑĞµÑ… Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹, Ğ»Ğ¸Ğ±Ğ¾ Ğ¿Ğ¾ Ğ¾Ğ´Ğ½Ğ¾Ğ¼Ñƒ Ğ¿Ñ€Ğ¾Ğ¼Ñ‚Ñƒ Ğ½Ğ° ĞºĞ°Ğ¶Ğ´Ğ¾Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ.",
        "error_generation": "ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ: {}",
        "error_url_load": "ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¿Ğ¾ URL: {}",
        "loading_model": "Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸: {}",
        "model_loaded": "ĞœĞ¾Ğ´ĞµĞ»ÑŒ {} ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ° Ğ½Ğ° {}",
        "image_label": "=== Ğ˜Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ {}: {} ===",
        "prompt_label": "ĞŸÑ€Ğ¾Ğ¼Ñ‚: {}",
        "result_label": "Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: {}",
        "model_size_warning": "âš ï¸ ĞŸÑ€Ğ¸Ğ¼ĞµÑ‡Ğ°Ğ½Ğ¸Ğµ: Ğ‘Ğ¾Ğ»ÑŒÑˆĞ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (8B+) Ğ¼Ğ¾Ğ³ÑƒÑ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ²Ñ‹Ğ³Ñ€ÑƒĞ·ĞºÑƒ Ğ½Ğ° CPU Ğ¿Ñ€Ğ¸ Ğ½ĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚ĞºĞµ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ GPU, Ñ‡Ñ‚Ğ¾ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ·Ğ°Ğ¼ĞµĞ´Ğ»Ğ¸Ñ‚ÑŒ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ.",
        "quantization": "ĞšĞ²Ğ°Ğ½Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ",
        "quantization_info": "ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ (4-bit = ~75% Ğ¼ĞµĞ½ÑŒÑˆĞµ Ğ²Ğ¸Ğ´ĞµĞ¾Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸)",
        "quant_4bit": "4-bit (Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ)",
        "quant_8bit": "8-bit (Ğ›ÑƒÑ‡ÑˆĞµ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾)",
        "quant_none": "ĞĞµÑ‚ (ĞŸĞ¾Ğ»Ğ½Ğ°Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ)",
        "description_type": "Ğ¢Ğ¸Ğ¿ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ",
        "description_type_info": "Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ñ‚Ğ¸Ğ¿/ÑÑ‚Ğ¸Ğ»ÑŒ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ",
        "description_length": "Ğ”Ğ»Ğ¸Ğ½Ğ° Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ",
        "description_length_info": "Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸Ñ‚Ğµ Ğ¶ĞµĞ»Ğ°ĞµĞ¼ÑƒÑ Ğ´Ğ»Ğ¸Ğ½Ñƒ",
        "num_variants": "ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ğ¾Ğ²",
        "num_variants_info": "Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ğ¾Ğ² Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ",
        "custom_prompt_override": "Ğ¡Ğ²Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ (Ğ¿ĞµÑ€ĞµĞ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚ Ğ²Ñ‹Ğ±Ğ¾Ñ€ Ñ‚Ğ¸Ğ¿Ğ°)",
        "custom_prompt_placeholder": "Ğ’Ğ²ĞµĞ´Ğ¸Ñ‚Ğµ ÑĞ²Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ·Ğ´ĞµÑÑŒ...",
        "status": "Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ",
        "processing_time": "Ğ’Ñ€ĞµĞ¼Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸",
        "generating": "â³ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ...",
        "stop_btn": "ğŸ›‘ ĞÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ",
        "save_results": "ğŸ’¾ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹",
        "output_folder": "ĞĞ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ°Ğ¿ĞºĞ¸",
        "output_folder_placeholder": "Ğ¼Ğ¾Ğ¹_Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚",
        "export_format": "Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ°",
        "export_txt": "TXT (Ğ¾Ğ´Ğ¸Ğ½ Ñ„Ğ°Ğ¹Ğ» Ğ½Ğ° Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ)",
        "export_json": "JSON (Ğ²ÑĞµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹)",
        "export_csv": "CSV (Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ‡Ğ½Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚)",
        "variant": "Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚",
        "copy_btn": "ğŸ“‹ ĞšĞ¾Ğ¿Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ",
        "download_btn": "â¬‡ï¸ Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ",
        "generation_complete": "âœ… Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°!",
        "seconds": "ÑĞµĞºÑƒĞ½Ğ´",
        "processing_image": "ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ",
        "of": "Ğ¸Ğ·",
        "extra_options": "Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¾Ğ¿Ñ†Ğ¸Ğ¸",
        "extra_options_info": "Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´Ğ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€Ñ‹ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ",
        "character_name": "Ğ˜Ğ¼Ñ Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ¶Ğ°/Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞºĞ°",
        "character_name_placeholder": "Ğ½Ğ°Ğ¿Ñ€., Ğ˜Ğ²Ğ°Ğ½, ĞĞ»Ğ¸ÑĞ°, Ğ¸Ğ»Ğ¸ Ğ¾ÑÑ‚Ğ°Ğ²ÑŒÑ‚Ğµ Ğ¿ÑƒÑÑ‚Ñ‹Ğ¼",
        "character_name_info": "Ğ•ÑĞ»Ğ¸ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¾, Ğ±ÑƒĞ´ĞµÑ‚ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ Ğ²Ğ¼ĞµÑÑ‚Ğ¾ Ğ¾Ğ±Ñ‰Ğ¸Ñ… Ñ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ¾Ğ²",
        "prompt_preset": "ĞŸÑ€ĞµÑĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ°",
        "prompt_preset_info": "Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚ÑŒ Ğ¿Ñ€ĞµÑĞµÑ‚ Ğ¸Ğ· Ğ¿Ğ°Ğ¿ĞºĞ¸ prompts/",
        "refresh_presets": "ĞĞ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ",
        "memory_usage": "Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸",
        "download_result": "Ğ¡ĞºĞ°Ñ‡Ğ°Ñ‚ÑŒ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚",
        "generation_stopped": "Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ° Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¼",
        "stopping": "ĞÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ°..."
    },
    "zh": {
        "title": "Qwen VL å›¾åƒæè¿°ç”Ÿæˆå™¨",
        "header": "ğŸ–¼ï¸ åŸºäº Qwen Vision Language Models çš„å›¾åƒæè¿°ç”Ÿæˆå™¨",
        "subtitle": "ä¸Šä¼ å›¾åƒå¹¶è¾“å…¥æç¤ºè¯ï¼Œä½¿ç”¨ Qwen VL æ¨¡å‹ç”Ÿæˆæè¿°ã€‚",
        "language": "è¯­è¨€",
        "language_info": "é€‰æ‹©è¯­è¨€",
        "model_selection": "æ¨¡å‹é€‰æ‹©",
        "model_info": "é€‰æ‹©ç”¨äºç”Ÿæˆæè¿°çš„æ¨¡å‹",
        "advanced_params": "âš™ï¸ é«˜çº§å‚æ•°",
        "max_tokens": "æœ€å¤§æ–°ä»¤ç‰Œæ•°",
        "max_tokens_info": "ç”Ÿæˆçš„æœ€å¤§ä»¤ç‰Œæ•°",
        "temperature": "æ¸©åº¦",
        "temperature_info": "æ§åˆ¶ç”Ÿæˆçš„éšæœºæ€§",
        "top_p": "Top-pï¼ˆæ ¸é‡‡æ ·ï¼‰",
        "top_p_info": "ä»¤ç‰Œé‡‡æ ·çš„æ¦‚ç‡é˜ˆå€¼",
        "top_k": "Top-k",
        "top_k_info": "è€ƒè™‘çš„æœ€å¯èƒ½ä»¤ç‰Œæ•°",
        "seed": "éšæœºç§å­",
        "seed_info": "ç”¨äºå¯é‡ç°æ€§çš„ç§å­ï¼ˆ-1 è¡¨ç¤ºéšæœºï¼‰",
        "random_seed_btn": "ğŸ² éšæœºç§å­",
        "single_processing": "ğŸ“„ å•å¼ å¤„ç†",
        "batch_processing": "ğŸ“š æ‰¹é‡å¤„ç†",
        "upload_image": "ä¸Šä¼ å›¾åƒ",
        "image_url": "æˆ–è¾“å…¥å›¾åƒURL",
        "image_url_placeholder": "https://example.com/image.jpg",
        "prompt": "æç¤ºè¯",
        "prompt_placeholder": "ä¾‹å¦‚ï¼šä¸ºåœ¨çº¿å•†åº—åˆ›å»ºäº§å“æè¿°",
        "generate_btn": "ğŸš€ ç”Ÿæˆæè¿°",
        "result": "ç»“æœ",
        "upload_images": "ä¸Šä¼ å›¾åƒ",
        "prompts_multiline": "æç¤ºè¯ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
        "prompts_placeholder": "ä¸ºåœ¨çº¿å•†åº—åˆ›å»ºäº§å“æè¿°\nä¸ºäº§å“åˆ›å»ºSEOæè¿°\n...",
        "prompts_info": "ä¸ºæ‰€æœ‰å›¾åƒæŒ‡å®šä¸€ä¸ªæç¤ºè¯ï¼Œæˆ–ä¸ºæ¯ä¸ªå›¾åƒæŒ‡å®šä¸€ä¸ªæç¤ºè¯",
        "process_batch_btn": "ğŸš€ å¤„ç†æ‰¹æ¬¡",
        "results": "ç»“æœ",
        "examples_title": "ğŸ’¡ ç¤ºä¾‹æç¤ºè¯ï¼š",
        "example_1": "ä¸ºåœ¨çº¿å•†åº—åˆ›å»ºäº§å“æè¿°",
        "example_2": "ä¸ºäº§å“åˆ›å»ºSEOæè¿°æœ€å¤š 160 ä¸ªå­—ç¬¦",
        "example_3": "ä¸ºå¸‚åœºåˆ›å»ºæœ‰å¸å¼•åŠ›çš„äº§å“æè¿°",
        "example_4": "è¯¦ç»†æè¿°äº§å“ç›®å½•çš„å›¾åƒ",
        "error_no_image": "è¯·ä¸Šä¼ å›¾åƒæˆ–æä¾›å›¾åƒURL",
        "error_no_prompt": "è¯·è¾“å…¥æç¤ºè¯",
        "error_no_images": "è¯·ä¸Šä¼ å›¾åƒ",
        "error_no_prompts": "è¯·è¾“å…¥æç¤ºè¯ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
        "error_prompt_mismatch": "æç¤ºè¯æ•°é‡ï¼ˆ{}ï¼‰ä¸å›¾åƒæ•°é‡ï¼ˆ{}ï¼‰ä¸åŒ¹é…ã€‚è¯·ä¸ºæ‰€æœ‰å›¾åƒæŒ‡å®šä¸€ä¸ªæç¤ºè¯ï¼Œæˆ–ä¸ºæ¯ä¸ªå›¾åƒæŒ‡å®šä¸€ä¸ªæç¤ºè¯ã€‚",
        "error_generation": "ç”Ÿæˆæè¿°æ—¶å‡ºé”™ï¼š{}",
        "error_url_load": "ä»URLåŠ è½½å›¾åƒæ—¶å‡ºé”™ï¼š{}",
        "loading_model": "æ­£åœ¨åŠ è½½æ¨¡å‹ï¼š{}",
        "model_loaded": "æ¨¡å‹ {} å·²æˆåŠŸåŠ è½½åˆ° {}",
        "image_label": "=== å›¾åƒ {}: {} ===",
        "prompt_label": "æç¤ºè¯ï¼š{}",
        "result_label": "ç»“æœï¼š{}",
        "model_size_warning": "âš ï¸ æ³¨æ„ï¼šå¦‚æœ GPU å†…å­˜ä¸è¶³ï¼Œå¤§å‹æ¨¡å‹ï¼ˆ8B+ï¼‰å¯èƒ½ä¼šä½¿ç”¨ CPU å¸è½½ï¼Œè¿™å¯èƒ½ä¼šå‡æ…¢ç”Ÿæˆé€Ÿåº¦ã€‚",
        "quantization": "é‡åŒ–",
        "quantization_info": "å†…å­˜ä¼˜åŒ–ï¼ˆ4ä½ = å‡å°‘çº¦75%æ˜¾å­˜ï¼‰",
        "quant_4bit": "4ä½ï¼ˆæ¨èï¼‰",
        "quant_8bit": "8ä½ï¼ˆæ›´é«˜è´¨é‡ï¼‰",
        "quant_none": "æ— ï¼ˆå…¨ç²¾åº¦ï¼‰",
        "description_type": "æè¿°ç±»å‹",
        "description_type_info": "é€‰æ‹©æè¿°ç±»å‹/é£æ ¼",
        "description_length": "æè¿°é•¿åº¦",
        "description_length_info": "é€‰æ‹©æ‰€éœ€é•¿åº¦",
        "num_variants": "å˜ä½“æ•°é‡",
        "num_variants_info": "ç”Ÿæˆå¤šä¸ªæè¿°å˜ä½“",
        "custom_prompt_override": "è‡ªå®šä¹‰æç¤ºè¯ï¼ˆè¦†ç›–ç±»å‹é€‰æ‹©ï¼‰",
        "custom_prompt_placeholder": "åœ¨æ­¤è¾“å…¥æ‚¨çš„è‡ªå®šä¹‰æç¤ºè¯...",
        "status": "çŠ¶æ€",
        "processing_time": "å¤„ç†æ—¶é—´",
        "generating": "â³ ç”Ÿæˆä¸­...",
        "stop_btn": "ğŸ›‘ åœæ­¢",
        "save_results": "ğŸ’¾ ä¿å­˜ç»“æœ",
        "output_folder": "è¾“å‡ºæ–‡ä»¶å¤¹åç§°",
        "output_folder_placeholder": "æˆ‘çš„æ•°æ®é›†",
        "export_format": "å¯¼å‡ºæ ¼å¼",
        "export_txt": "TXTï¼ˆæ¯å¼ å›¾ç‰‡ä¸€ä¸ªæ–‡ä»¶ï¼‰",
        "export_json": "JSONï¼ˆæ‰€æœ‰ç»“æœï¼‰",
        "export_csv": "CSVï¼ˆè¡¨æ ¼æ ¼å¼ï¼‰",
        "variant": "å˜ä½“",
        "copy_btn": "ğŸ“‹ å¤åˆ¶",
        "download_btn": "â¬‡ï¸ ä¸‹è½½",
        "generation_complete": "âœ… ç”Ÿæˆå®Œæˆï¼",
        "seconds": "ç§’",
        "processing_image": "å¤„ç†å›¾åƒ",
        "of": "/",
        "extra_options": "é¢å¤–é€‰é¡¹",
        "extra_options_info": "æè¿°çš„é¢å¤–ä¿®é¥°ç¬¦",
        "character_name": "è§’è‰²/äººç‰©åç§°",
        "character_name_placeholder": "ä¾‹å¦‚ï¼šå°æ˜ã€å°çº¢ï¼Œæˆ–ç•™ç©º",
        "character_name_info": "å¦‚æœæä¾›ï¼Œå°†ä½¿ç”¨æ­¤åç§°ä»£æ›¿é€šç”¨æœ¯è¯­",
        "prompt_preset": "æç¤ºè¯é¢„è®¾",
        "prompt_preset_info": "ä»prompts/æ–‡ä»¶å¤¹åŠ è½½é¢„è®¾",
        "refresh_presets": "åˆ·æ–°",
        "memory_usage": "å†…å­˜ä½¿ç”¨",
        "download_result": "ä¸‹è½½ç»“æœ",
        "generation_stopped": "ç”¨æˆ·åœæ­¢äº†ç”Ÿæˆ",
        "stopping": "åœæ­¢ä¸­..."
    }
}

# Default language
current_language = "ru"

def get_text(key: str) -> str:
    """Get translated text for the current language"""
    return TRANSLATIONS[current_language].get(key, key)

def get_description_types() -> list:
    """Get description types for current language"""
    return list(DESCRIPTION_TYPES.get(current_language, DESCRIPTION_TYPES["en"]).keys())

def get_description_lengths() -> list:
    """Get description lengths for current language"""
    return list(DESCRIPTION_LENGTHS.get(current_language, DESCRIPTION_LENGTHS["en"]).keys())

def get_extra_options(is_video: bool = False) -> list:
    """Get extra options for current language and media type"""
    options_dict = EXTRA_OPTIONS_VIDEO if is_video else EXTRA_OPTIONS
    return list(options_dict.get(current_language, options_dict["en"]).keys())

def get_extra_option_prompt(option: str, is_video: bool = False) -> str:
    """Get the prompt text for an extra option"""
    options_dict = EXTRA_OPTIONS_VIDEO if is_video else EXTRA_OPTIONS
    lang_options = options_dict.get(current_language, options_dict["en"])
    return lang_options.get(option, "")

def build_prompt(
    description_type: str,
    description_length: str,
    custom_prompt: str,
    base_prompt: str = "",
    extra_options: list = None,
    character_name: str = "",
    is_video: bool = False
) -> str:
    """Build the final prompt based on type, length, custom input, extra options and character name.
    Automatically replaces 'image' with 'video' when is_video=True for context-aware prompts."""
    # If custom prompt is provided, use it (but still add character name if present)
    if custom_prompt and custom_prompt.strip():
        final_prompt = custom_prompt.strip()
    else:
        # Get type prompt
        types_dict = DESCRIPTION_TYPES.get(current_language, DESCRIPTION_TYPES["en"])
        type_prompt = types_dict.get(description_type, "")

        # If type is Custom, use base prompt
        if not type_prompt:
            if is_video:
                type_prompt = base_prompt if base_prompt else "Describe this video."
            else:
                type_prompt = base_prompt if base_prompt else "Describe this image."

        # Get length modifier
        lengths_dict = DESCRIPTION_LENGTHS.get(current_language, DESCRIPTION_LENGTHS["en"])
        length_modifier = lengths_dict.get(description_length, "")

        # Combine type and length
        if length_modifier:
            final_prompt = f"{type_prompt} {length_modifier}"
        else:
            final_prompt = type_prompt

    # Context-aware: Replace "image" with "video" when processing video
    if is_video:
        # English replacements
        final_prompt = final_prompt.replace(" image.", " video.")
        final_prompt = final_prompt.replace(" image ", " video ")
        final_prompt = final_prompt.replace("this image", "this video")
        final_prompt = final_prompt.replace("the image", "the video")
        final_prompt = final_prompt.replace("an image", "a video")
        # Russian replacements
        final_prompt = final_prompt.replace("Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ", "Ğ²Ğ¸Ğ´ĞµĞ¾")
        final_prompt = final_prompt.replace("Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¸", "Ğ²Ğ¸Ğ´ĞµĞ¾")
        final_prompt = final_prompt.replace("Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ", "Ğ²Ğ¸Ğ´ĞµĞ¾")
        # Chinese replacements
        final_prompt = final_prompt.replace("å›¾ç‰‡", "è§†é¢‘")
        final_prompt = final_prompt.replace("å›¾åƒ", "è§†é¢‘")

    # Add character name instruction if provided
    if character_name and character_name.strip():
        name = character_name.strip()
        media_term_ru = "Ğ²Ğ¸Ğ´ĞµĞ¾" if is_video else "Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¸"
        media_term_zh = "è§†é¢‘" if is_video else "å›¾ç‰‡"
        media_term_en = "video" if is_video else "image"

        if current_language == "ru":
            final_prompt += f" Ğ•ÑĞ»Ğ¸ Ğ½Ğ° {media_term_ru} ĞµÑÑ‚ÑŒ Ñ‡ĞµĞ»Ğ¾Ğ²ĞµĞº Ğ¸Ğ»Ğ¸ Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ¶, Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ Ğ¸Ğ¼Ñ '{name}' Ğ²Ğ¼ĞµÑÑ‚Ğ¾ Ğ¾Ğ±Ñ‰Ğ¸Ñ… Ñ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ¾Ğ²."
        elif current_language == "zh":
            final_prompt += f" å¦‚æœ{media_term_zh}ä¸­æœ‰äººæˆ–è§’è‰²ï¼Œè¯·ä½¿ç”¨åå­—'{name}'è€Œä¸æ˜¯é€šç”¨æœ¯è¯­ã€‚"
        else:
            final_prompt += f" If there is a person or character in the {media_term_en}, use the name '{name}' instead of generic terms."

    # Add extra options
    if extra_options:
        for option in extra_options:
            option_prompt = get_extra_option_prompt(option, is_video=is_video)
            if option_prompt:
                final_prompt += f" {option_prompt}"

    return final_prompt

def create_output_folder(folder_name: str = None) -> str:
    """Create and return path to output folder"""
    if folder_name and folder_name.strip():
        # Sanitize folder name
        safe_name = "".join(c for c in folder_name if c.isalnum() or c in "_ -").strip()
        if not safe_name:
            safe_name = f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    else:
        safe_name = f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

    folder_path = os.path.join(DATASETS_DIR, safe_name)
    os.makedirs(folder_path, exist_ok=True)
    return folder_path

def save_results_txt(results: List[dict], output_folder: str) -> List[str]:
    """Save results as individual TXT files"""
    saved_files = []
    for result in results:
        filename = os.path.splitext(os.path.basename(result.get("image_path", "image")))[0]
        txt_path = os.path.join(output_folder, f"{filename}.txt")
        with open(txt_path, "w", encoding="utf-8") as f:
            if isinstance(result.get("descriptions"), list):
                for i, desc in enumerate(result["descriptions"], 1):
                    f.write(f"=== Variant {i} ===\n{desc}\n\n")
            else:
                f.write(result.get("description", ""))
        saved_files.append(txt_path)

        # Copy image if exists
        if result.get("image_path") and os.path.exists(result["image_path"]):
            img_dest = os.path.join(output_folder, os.path.basename(result["image_path"]))
            if not os.path.exists(img_dest):
                shutil.copy2(result["image_path"], img_dest)

    return saved_files

def save_results_json(results: List[dict], output_folder: str) -> str:
    """Save all results as a single JSON file"""
    json_path = os.path.join(output_folder, "results.json")
    export_data = []
    for result in results:
        export_data.append({
            "image": os.path.basename(result.get("image_path", "")),
            "prompt": result.get("prompt", ""),
            "descriptions": result.get("descriptions", [result.get("description", "")]),
            "timestamp": datetime.now().isoformat()
        })

    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(export_data, f, ensure_ascii=False, indent=2)

    return json_path

def save_results_csv(results: List[dict], output_folder: str) -> str:
    """Save all results as a CSV file"""
    csv_path = os.path.join(output_folder, "results.csv")

    with open(csv_path, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(["Image", "Prompt", "Description", "Variant"])

        for result in results:
            image_name = os.path.basename(result.get("image_path", ""))
            prompt = result.get("prompt", "")
            descriptions = result.get("descriptions", [result.get("description", "")])

            for i, desc in enumerate(descriptions, 1):
                writer.writerow([image_name, prompt, desc, i])

    return csv_path

class ImageDescriptionGenerator:
    def __init__(self):
        self.model = None
        self.processor = None
        self.current_model_name = None
        self.current_quantization = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"

    def load_model(self, model_name: str, quantization: str = "4-bit"):
        """Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ñ ĞºĞ²Ğ°Ğ½Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸ĞµĞ¹ BitsAndBytes"""
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ğ½ÑƒĞ¶Ğ½Ğ° Ğ»Ğ¸ Ğ¿ĞµÑ€ĞµĞ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ°
        if (self.current_model_name == model_name and
            self.current_quantization == quantization and
            self.model is not None):
            print(f"âœ… ĞœĞ¾Ğ´ĞµĞ»ÑŒ {model_name} ÑƒĞ¶Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°")
            return

        print(f"\n{'='*50}")
        print(f"ğŸ§  Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸: {model_name}")
        print(f"âš™ï¸ ĞšĞ²Ğ°Ğ½Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ: {quantization}")
        print(f"ğŸ’» Ğ£ÑÑ‚Ñ€Ğ¾Ğ¹ÑÑ‚Ğ²Ğ¾: {self.device}")
        print(f"{'='*50}")

        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, ÑĞºĞ°Ñ‡Ğ°Ğ½Ğ° Ğ»Ğ¸ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
        cached_size = get_model_cache_size(model_name)
        if cached_size:
            print(f"âœ… ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ° Ğ² ĞºÑÑˆĞµ [{cached_size}]")
        else:
            print(f"â¬‡ï¸ ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ° Ğ² ĞºÑÑˆĞµ - Ğ±ÑƒĞ´ĞµÑ‚ ÑĞºĞ°Ñ‡Ğ°Ğ½Ğ° Ñ HuggingFace...")
            print(f"â³ Ğ­Ñ‚Ğ¾ Ğ¼Ğ¾Ğ¶ĞµÑ‚ Ğ·Ğ°Ğ½ÑÑ‚ÑŒ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ¼Ğ¸Ğ½ÑƒÑ‚ Ğ¿Ñ€Ğ¸ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ¼ Ğ·Ğ°Ğ¿ÑƒÑĞºĞµ")

        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ ÑÑ‚Ğ°Ñ€ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğ° ÑĞ»ÑƒÑ‡Ğ°Ğ¹ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸
        old_model = self.model
        old_processor = self.processor
        old_model_name = self.current_model_name
        old_quantization = self.current_quantization

        try:
            # ĞÑĞ²Ğ¾Ğ±Ğ¾Ğ¶Ğ´Ğ°ĞµĞ¼ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ Ğ¾Ñ‚ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰ĞµĞ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
            if self.model is not None:
                print(f"ğŸ—‘ï¸ Ğ’Ñ‹Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ: {old_model_name}")
                self.model = None
                self.processor = None
                del old_model
                del old_processor
                gc.collect()
                if torch.cuda.is_available():
                    torch.cuda.empty_cache()
                    torch.cuda.synchronize()
                print(f"âœ… ĞŸĞ°Ğ¼ÑÑ‚ÑŒ Ğ¾Ñ‡Ğ¸Ñ‰ĞµĞ½Ğ°")

            # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° ĞºĞ²Ğ°Ğ½Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ BitsAndBytes
            bnb_config = None
            dtype = torch.bfloat16 if torch.cuda.is_available() else torch.float32

            if quantization == "4-bit" and torch.cuda.is_available():
                bnb_config = BitsAndBytesConfig(
                    load_in_4bit=True,
                    bnb_4bit_compute_dtype=torch.bfloat16,
                    bnb_4bit_quant_type="nf4",
                    bnb_4bit_use_double_quant=True,
                )
                print("âš¡ 4-bit ĞºĞ²Ğ°Ğ½Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ (NF4) â€” ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ ~75% VRAM")
            elif quantization == "8-bit" and torch.cuda.is_available():
                bnb_config = BitsAndBytesConfig(
                    load_in_8bit=True,
                )
                print("âš¡ 8-bit ĞºĞ²Ğ°Ğ½Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ â€” ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ ~50% VRAM")
            else:
                print("ğŸ“Š ĞŸĞ¾Ğ»Ğ½Ğ°Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ (bfloat16/float32)")

            # Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ½Ğ¾Ğ²ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ñ Ğ¿Ğ¾Ğ´Ğ°Ğ²Ğ»ĞµĞ½Ğ¸ĞµĞ¼ Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ğ¹
            print(f"ğŸ”„ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸...")
            load_start_time = time.time()

            with warnings.catch_warnings():
                warnings.filterwarnings('ignore')
                load_kwargs = {
                    "device_map": "auto",
                    "trust_remote_code": True,
                }

                if bnb_config is not None:
                    load_kwargs["quantization_config"] = bnb_config
                else:
                    load_kwargs["torch_dtype"] = dtype

                # SDPA (Scaled Dot Product Attention) - Ğ²ÑÑ‚Ñ€Ğ¾ĞµĞ½ Ğ² PyTorch 2.0+
                # Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ Ğ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°ĞµÑ‚ Ğ½Ğ° Windows Ğ±ĞµĞ· Ğ´Ğ¾Ğ¿. Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ĞµĞ¹
                if torch.cuda.is_available():
                    load_kwargs["attn_implementation"] = "sdpa"
                    print("ğŸš€ SDPA attention (PyTorch native)")

                self.model = Qwen3VLForConditionalGeneration.from_pretrained(
                    model_name,
                    **load_kwargs
                )
                print(f"ğŸ”„ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ñ€Ğ°...")
                self.processor = AutoProcessor.from_pretrained(model_name, trust_remote_code=True)

            load_time = time.time() - load_start_time
            self.current_model_name = model_name
            self.current_quantization = quantization

            # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸
            memory_info = get_memory_info()
            print(f"\n{'='*50}")
            print(f"âœ… ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ° Ğ·Ğ° {load_time:.1f} ÑĞµĞº")
            print(f"ğŸ“Š {memory_info}")
            print(f"{'='*50}\n")

        except Exception as e:
            # ĞŸÑ€Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ - Ğ¾Ñ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ğµ
            print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸: {str(e)}")
            self.model = None
            self.processor = None
            self.current_model_name = None
            self.current_quantization = None
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            raise Exception(f"ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ {model_name}: {str(e)}")
    
    def _prepare_inputs(
        self,
        media_path: str,
        prompt: str,
        model_name: str,
        quantization: str,
        seed: int,
        is_video: bool = False,
        video_start_time = None,
        video_end_time = None
    ):
        """Prepare inputs for generation"""
        # Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ ĞµÑĞ»Ğ¸ Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾
        self.load_model(model_name, quantization)

        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‡Ñ‚Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°
        if self.model is None or self.processor is None:
            raise Exception("ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°. ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ Ğ²Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ´Ñ€ÑƒĞ³ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¸Ğ»Ğ¸ Ğ¿ĞµÑ€ĞµĞ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ.")

        # Ğ£ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ seed ĞµÑĞ»Ğ¸ ÑƒĞºĞ°Ğ·Ğ°Ğ½
        if seed != -1:
            torch.manual_seed(seed)
            if torch.cuda.is_available():
                torch.cuda.manual_seed(seed)

        # ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
        # Use "video" type for videos, "image" for images
        if is_video:
            content_item = {
                "type": "video",
                "video": media_path,
            }
            # Add video segment parameters if provided
            if video_start_time is not None and video_start_time > 0:
                content_item["video_start"] = float(video_start_time)
            if video_end_time is not None and video_end_time > 0:
                content_item["video_end"] = float(video_end_time)
        else:
            content_item = {
                "type": "image",
                "image": media_path,
            }

        messages = [
            {
                "role": "user",
                "content": [
                    content_item,
                    {"type": "text", "text": prompt},
                ],
            }
        ]

        # ĞŸĞ¾Ğ´Ğ³Ğ¾Ñ‚Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµĞ¼ Ñ‚ĞµĞºÑÑ‚ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
        text = self.processor.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True
        )

        # ĞĞ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ/Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ¸ Ñ‚ĞµĞºÑÑ‚
        image_inputs, video_inputs = process_vision_info(messages)
        inputs = self.processor(
            text=[text],
            images=image_inputs,
            videos=video_inputs,
            padding=True,
            return_tensors="pt",
        )
        inputs = inputs.to(self.device)
        return inputs

    def generate_description(
        self,
        image_path: str,
        prompt: str,
        model_name: str,
        quantization: str = "4-bit",
        max_new_tokens: int = 1024,
        temperature: float = 0.6,
        top_p: float = 0.9,
        top_k: int = 50,
        seed: int = -1,
        is_video: bool = False,
        video_start_time = None,
        video_end_time = None
    ) -> str:
        """Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ/Ğ²Ğ¸Ğ´ĞµĞ¾ (Ğ±ĞµĞ· streaming)"""
        try:
            inputs = self._prepare_inputs(
                image_path, prompt, model_name, quantization, seed, is_video,
                video_start_time, video_end_time
            )

            # Non-streaming generation (inference_mode Ğ±Ñ‹ÑÑ‚Ñ€ĞµĞµ Ñ‡ĞµĞ¼ no_grad)
            with torch.inference_mode():
                generated_ids = self.model.generate(
                    **inputs,
                    max_new_tokens=max_new_tokens,
                    temperature=temperature,
                    top_p=top_p,
                    top_k=top_k,
                    do_sample=True if temperature > 0 else False,
                    use_cache=True,  # KV ĞºÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ´Ğ»Ñ ÑƒÑĞºĞ¾Ñ€ĞµĞ½Ğ¸Ñ
                )

            # Ğ”ĞµĞºĞ¾Ğ´Ğ¸Ñ€ÑƒĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
            generated_ids_trimmed = [
                out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
            ]
            output_text = self.processor.batch_decode(
                generated_ids_trimmed,
                skip_special_tokens=True,
                clean_up_tokenization_spaces=False
            )

            return output_text[0]

        except Exception as e:
            error_msg = get_text("error_generation").format(str(e))
            return error_msg

    def generate_description_stream(
        self,
        image_path: str,
        prompt: str,
        model_name: str,
        quantization: str = "4-bit",
        max_new_tokens: int = 1024,
        temperature: float = 0.6,
        top_p: float = 0.9,
        top_k: int = 50,
        seed: int = -1,
        is_video: bool = False,
        video_start_time = None,
        video_end_time = None
    ) -> Generator[str, None, None]:
        """Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ/Ğ²Ğ¸Ğ´ĞµĞ¾ ÑĞ¾ streaming"""
        try:
            inputs = self._prepare_inputs(
                image_path, prompt, model_name, quantization, seed, is_video,
                video_start_time, video_end_time
            )

            streamer = TextIteratorStreamer(
                self.processor.tokenizer,
                skip_special_tokens=True,
                skip_prompt=True
            )

            generation_kwargs = {
                **inputs,
                "max_new_tokens": max_new_tokens,
                "temperature": temperature,
                "top_p": top_p,
                "top_k": top_k,
                "do_sample": True if temperature > 0 else False,
                "use_cache": True,
                "streamer": streamer,
            }

            # Run generation in a separate thread
            thread = Thread(target=self.model.generate, kwargs=generation_kwargs)
            thread.start()

            # Yield tokens as they come
            generated_text = ""
            for new_text in streamer:
                generated_text += new_text
                yield generated_text

            thread.join()

        except Exception as e:
            error_msg = get_text("error_generation").format(str(e))
            yield error_msg

# Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ³Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ÑĞºĞ·ĞµĞ¼Ğ¿Ğ»ÑÑ€ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€Ğ°
generator = ImageDescriptionGenerator()

def process_single_image(
    image,
    video,
    video_start_time,
    video_end_time,
    description_type: str,
    description_length: str,
    custom_prompt: str,
    extra_options: list,
    character_name: str,
    num_variants: int,
    model_name: str,
    quantization: str,
    max_new_tokens: int,
    temperature: float,
    top_p: float,
    top_k: int,
    seed: int,
    use_streaming: bool = True,
    progress=gr.Progress(track_tqdm=True)
) -> Generator:
    """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¾Ğ´Ğ½Ğ¾Ğ³Ğ¾ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ/Ğ²Ğ¸Ğ´ĞµĞ¾ Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸ĞµĞ¹ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ğ¾Ğ² Ğ¸ streaming output"""
    global stop_generation_flag
    reset_stop_flag()
    start_time = time.time()

    # Start capturing console output
    log_capture.clear_logs()
    log_capture.start_capture()
    print(f"[{datetime.now().strftime('%H:%M:%S')}] ĞĞ°Ñ‡Ğ°Ğ»Ğ¾ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸...")

    # Check if we have either uploaded image or video
    if image is None and video is None:
        yield get_text("error_no_image"), "", [], None, log_capture.get_logs()
        return

    # Determine if processing video
    is_video = video is not None

    # Build prompt from type, length, custom, extra options and character name
    final_prompt = build_prompt(
        description_type, description_length, custom_prompt,
        extra_options=extra_options or [],
        character_name=character_name or "",
        is_video=is_video
    )
    if not final_prompt.strip():
        yield get_text("error_no_prompt"), "", [], None, log_capture.get_logs()
        return

    temp_path = None
    num_variants = int(num_variants) if num_variants and str(num_variants).strip() else 1

    try:
        # Priority: video > image
        if video is not None:
            # Video uploaded - use it directly
            media_path = video
            is_video = True
        elif hasattr(image, 'shape'):
            # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğµ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ ĞµÑĞ»Ğ¸ ÑÑ‚Ğ¾ numpy array
            temp_path = os.path.join(TEMP_DIR, "temp_image.jpg")
            Image.fromarray(image).save(temp_path)
            media_path = temp_path
            is_video = False
        else:
            media_path = image
            is_video = False

        results = []
        variant_times = []  # Track time for each variant

        for i in range(num_variants):
            # Check stop flag
            if stop_generation_flag:
                elapsed_time = time.time() - start_time
                print(f"[{datetime.now().strftime('%H:%M:%S')}] Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ° Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¼")
                yield f"ğŸ›‘ {get_text('generation_stopped')} ({get_text('processing_time')}: {elapsed_time:.1f} {get_text('seconds')})", final_prompt, results, None, log_capture.get_logs()
                return

            variant_start = time.time()
            variant_seed = seed if seed == -1 else seed + i
            memory_info = get_memory_info()
            status_msg = f"{get_text('generating')} ({get_text('variant')} {i+1}/{num_variants}) | {memory_info}"
            print(f"[{datetime.now().strftime('%H:%M:%S')}] Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ²Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚Ğ° {i+1}/{num_variants}, seed={variant_seed}")

            if use_streaming:
                # Stream the generation for real-time output
                current_result = ""
                for partial_result in generator.generate_description_stream(
                    image_path=media_path,
                    prompt=final_prompt,
                    model_name=model_name,
                    quantization=quantization,
                    max_new_tokens=max_new_tokens,
                    temperature=temperature,
                    top_p=top_p,
                    top_k=top_k,
                    seed=variant_seed,
                    is_video=is_video,
                    video_start_time=video_start_time,
                    video_end_time=video_end_time
                ):
                    if stop_generation_flag:
                        break
                    current_result = partial_result
                    # Update results with streaming text
                    temp_results = results + [current_result]
                    yield status_msg, final_prompt, temp_results, None, log_capture.get_logs()

                result = current_result
            else:
                # Non-streaming generation
                yield status_msg, final_prompt, results, None, log_capture.get_logs()
                result = generator.generate_description(
                    image_path=media_path,
                    prompt=final_prompt,
                    model_name=model_name,
                    quantization=quantization,
                    max_new_tokens=max_new_tokens,
                    temperature=temperature,
                    top_p=top_p,
                    top_k=top_k,
                    seed=variant_seed,
                    is_video=is_video,
                    video_start_time=video_start_time,
                    video_end_time=video_end_time
                )

            variant_time = time.time() - variant_start
            variant_times.append(variant_time)
            results.append(result)
            print(f"[{datetime.now().strftime('%H:%M:%S')}] Ğ’Ğ°Ñ€Ğ¸Ğ°Ğ½Ñ‚ {i+1} Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½ Ğ·Ğ° {variant_time:.1f}s")

        # Calculate processing time
        elapsed_time = time.time() - start_time
        memory_info = get_memory_info()

        # Build detailed status with per-variant timing
        timing_details = " | ".join([f"V{i+1}: {t:.1f}s" for i, t in enumerate(variant_times)])
        final_status = f"{get_text('generation_complete')} | Total: {elapsed_time:.1f}s ({timing_details}) | {memory_info}"

        # Prepare download file
        download_path = None
        if results:
            all_text = "\n\n".join([f"=== Variant {i+1} (Time: {variant_times[i]:.1f}s) ===\n{r}" for i, r in enumerate(results)])
            download_path = save_text_to_file(all_text, f"result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt")

        print(f"[{datetime.now().strftime('%H:%M:%S')}] Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ° ÑƒÑĞ¿ĞµÑˆĞ½Ğ¾ Ğ·Ğ° {elapsed_time:.1f}s")
        yield final_status, final_prompt, results, download_path, log_capture.get_logs()

    except Exception as e:
        print(f"[{datetime.now().strftime('%H:%M:%S')}] ĞÑˆĞ¸Ğ±ĞºĞ°: {str(e)}")
        yield f"âŒ Error: {str(e)}", final_prompt, [], None, log_capture.get_logs()
    finally:
        # Stop capturing console output
        log_capture.stop_capture()

        # Ğ£Ğ´Ğ°Ğ»ÑĞµĞ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ»
        if temp_path and os.path.exists(temp_path):
            try:
                os.remove(temp_path)
            except:
                pass

        # Clean up GPU memory
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

def process_batch_images(
    files: List,
    description_type: str,
    description_length: str,
    custom_prompt: str,
    extra_options: list,
    character_name: str,
    num_variants: int,
    output_folder_name: str,
    export_formats: List[str],
    model_name: str,
    quantization: str,
    max_new_tokens: int,
    temperature: float,
    top_p: float,
    top_k: int,
    seed: int,
    is_video: bool = False,
    progress=gr.Progress(track_tqdm=True)
) -> Generator:
    """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¿Ğ°ĞºĞµÑ‚Ğ° Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹/Ğ²Ğ¸Ğ´ĞµĞ¾ Ñ Ğ¿Ñ€Ğ¾Ğ³Ñ€ĞµÑÑ-Ğ±Ğ°Ñ€Ğ¾Ğ¼ Ğ¸ ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¾Ğ¼"""
    global stop_generation_flag
    reset_stop_flag()
    start_time = time.time()

    if not files:
        yield get_text("error_no_images"), "", None
        return

    # Build prompt from type, length, custom, extra options and character name
    final_prompt = build_prompt(
        description_type, description_length, custom_prompt,
        extra_options=extra_options or [],
        character_name=character_name or "",
        is_video=is_video
    )
    if not final_prompt.strip():
        yield get_text("error_no_prompts"), "", None
        return

    num_variants = int(num_variants)
    total_files = len(files)
    all_results = []
    output_lines = []

    # Create output folder
    output_folder = create_output_folder(output_folder_name)

    media_type = "video" if is_video else get_text('processing_image')

    for idx, file in enumerate(progress.tqdm(files, desc=f"Processing {media_type}s")):
        # Check stop flag
        if stop_generation_flag:
            elapsed_time = time.time() - start_time
            final_status = f"ğŸ›‘ {get_text('generation_stopped')}\n"
            final_status += f"ğŸ“Š {idx} {get_text('of')} {total_files} files processed in {elapsed_time:.1f} {get_text('seconds')}"
            yield final_status, "\n".join(output_lines), None
            return

        image_path = file.name if hasattr(file, 'name') else file
        filename = os.path.basename(image_path)

        # Status update with memory info
        memory_info = get_memory_info()
        status_msg = f"â³ Processing {idx + 1} {get_text('of')} {total_files}: {filename} | {memory_info}"
        yield status_msg, "\n".join(output_lines), None

        descriptions = []
        variant_times = []

        for v in range(num_variants):
            # Check stop flag between variants
            if stop_generation_flag:
                break

            variant_start = time.time()
            variant_seed = seed if seed == -1 else seed + idx * num_variants + v

            result = generator.generate_description(
                image_path=image_path,
                prompt=final_prompt,
                model_name=model_name,
                quantization=quantization,
                max_new_tokens=max_new_tokens,
                temperature=temperature,
                top_p=top_p,
                top_k=top_k,
                seed=variant_seed,
                is_video=is_video
            )
            variant_time = time.time() - variant_start
            variant_times.append(variant_time)
            descriptions.append(result)

        if not descriptions:
            continue

        # Store result
        all_results.append({
            "image_path": image_path,
            "prompt": final_prompt,
            "descriptions": descriptions,
            "description": descriptions[0] if descriptions else ""
        })

        # Add to output with timing info
        output_lines.append(f"{'='*50}")
        output_lines.append(get_text("image_label").format(idx + 1, filename))
        output_lines.append(get_text("prompt_label").format(final_prompt))

        for v_idx, desc in enumerate(descriptions, 1):
            if num_variants > 1:
                timing_info = f" ({variant_times[v_idx-1]:.1f}s)" if v_idx-1 < len(variant_times) else ""
                output_lines.append(f"\n--- {get_text('variant')} {v_idx}{timing_info} ---")
            output_lines.append(f"{desc}\n")

        yield status_msg, "\n".join(output_lines), None

    # Save results in selected formats
    saved_paths = []
    if export_formats and all_results:
        if "TXT" in export_formats:
            txt_files = save_results_txt(all_results, output_folder)
            saved_paths.extend(txt_files)

        if "JSON" in export_formats:
            json_path = save_results_json(all_results, output_folder)
            saved_paths.append(json_path)

        if "CSV" in export_formats:
            csv_path = save_results_csv(all_results, output_folder)
            saved_paths.append(csv_path)

    # Calculate total time
    elapsed_time = time.time() - start_time
    memory_info = get_memory_info()

    # Final status
    final_status = f"{get_text('generation_complete')}\n"
    final_status += f"ğŸ“Š {total_files} images processed in {elapsed_time:.1f} {get_text('seconds')} | {memory_info}\n"
    if saved_paths:
        final_status += f"ğŸ’¾ Results saved to: {output_folder}"

    # Prepare download file for batch results
    download_path = None
    if all_results:
        download_path = save_text_to_file("\n".join(output_lines), f"batch_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt")

    yield final_status, "\n".join(output_lines), download_path

    # Clean up GPU memory
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

def random_seed() -> int:
    """Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ ÑĞ»ÑƒÑ‡Ğ°Ğ¹Ğ½Ğ¾Ğ³Ğ¾ seed"""
    return random.randint(0, 2**32 - 1)

def update_examples():
    return [
        [get_text("example_1")],
        [get_text("example_2")],
        [get_text("example_3")],
        [get_text("example_4")]
    ]

def create_interface():
    """Create Gradio interface with current language and beautiful styling"""
    with gr.Blocks(
        title="SuperCaption Qwen3-VL NSFW",
        theme=gr.themes.Soft(primary_hue="indigo", secondary_hue="purple", neutral_hue="slate"),
        css=CUSTOM_CSS
    ) as demo:
        # Beautiful gradient header with credits
        gr.HTML("""
        <div class="main-header">
            <h1>ğŸ¬ SuperCaption Qwen3-VL NSFW</h1>
            <p>Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğ¹ Ğ¸ Ñ‚ĞµĞ³Ğ¾Ğ² Ğ´Ğ»Ñ Ñ„Ğ¾Ñ‚Ğ¾ Ğ¸ Ğ²Ğ¸Ğ´ĞµĞ¾</p>
            <p style="font-size: 0.85rem; margin-top: 0.5rem; opacity: 0.9;">
                ğŸ”“ Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒÑÑ‚ÑÑ <b>Abliterated</b> Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ â€” Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ° Ñ Ğ»ÑĞ±Ñ‹Ğ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ¾Ğ¼ Ğ±ĞµĞ· Ñ†ĞµĞ½Ğ·ÑƒÑ€Ñ‹
            </p>
            <p style="font-size: 0.9rem; margin-top: 0.75rem; opacity: 0.85;">
                ĞŸĞ¾Ñ€Ñ‚Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ Ğ¾Ñ‚ <a href="https://t.me/nerual_dreming" target="_blank">Nerual Dreming</a> Ğ¸
                <a href="https://t.me/ruweb24" target="_blank">Slait</a> |
                <a href="https://t.me/neuroport" target="_blank">ğŸ‘¾ ĞĞ•Ğ™Ğ Ğ-Ğ¡ĞĞ¤Ğ¢</a>
            </p>
        </div>
        """)

        # Header that will be updated for language
        header_md = gr.Markdown(f"""
        {get_text("subtitle")}
        """)
        
        # ĞĞ±Ñ‰Ğ¸Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ - Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ, ĞºĞ²Ğ°Ğ½Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸ ÑĞ·Ñ‹Ğº
        with gr.Row():
            model_dropdown = gr.Dropdown(
                choices=get_model_choices(),
                value="huihui-ai/Huihui-Qwen3-VL-2B-Instruct-abliterated",
                label=get_text("model_selection"),
                info=get_text("model_info"),
                scale=3
            )
            refresh_models_btn = gr.Button(
                "ğŸ”„",
                size="sm",
                scale=0,
                min_width=40
            )
            quantization_dropdown = gr.Dropdown(
                choices=[
                    ("4-bit (Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´ÑƒĞµÑ‚ÑÑ)", "4-bit"),
                    ("8-bit (Ğ›ÑƒÑ‡ÑˆĞµ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾)", "8-bit"),
                    ("Ğ‘ĞµĞ· (ĞŸĞ¾Ğ»Ğ½Ğ°Ñ Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ)", "none"),
                ],
                value="4-bit",
                label=get_text("quantization"),
                info=get_text("quantization_info"),
                scale=1
            )
            language_dropdown = gr.Dropdown(
                choices=[("English", "en"), ("Ğ ÑƒÑÑĞºĞ¸Ğ¹", "ru"), ("ä¸­æ–‡", "zh")],
                value=current_language,
                label=get_text("language"),
                info=get_text("language_info"),
                scale=1
            )

        # Ğ˜Ğ½Ğ´Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ¹ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
        current_model_indicator = gr.Markdown(
            value="ğŸ“­ **ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ°** â€” Ğ±ÑƒĞ´ĞµÑ‚ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ° Ğ¿Ñ€Ğ¸ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ¹ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸",
            elem_id="model_indicator"
        )

        # Ğ Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ñ‹Ğµ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹
        advanced_accordion = gr.Accordion(get_text("advanced_params"), open=False)
        with advanced_accordion:
            with gr.Row():
                max_tokens_slider = gr.Slider(
                    minimum=1,
                    maximum=4096,
                    value=1024,
                    step=1,
                    label=get_text("max_tokens"),
                    info=get_text("max_tokens_info")
                )
                temperature_slider = gr.Slider(
                    minimum=0.1,
                    maximum=2.0,
                    value=0.6,
                    step=0.1,
                    label=get_text("temperature"),
                    info=get_text("temperature_info")
                )
            
            with gr.Row():
                top_p_slider = gr.Slider(
                    minimum=0.05,
                    maximum=1.0,
                    value=0.9,
                    step=0.05,
                    label=get_text("top_p"),
                    info=get_text("top_p_info")
                )
                top_k_slider = gr.Slider(
                    minimum=1,
                    maximum=1000,
                    value=50,
                    step=1,
                    label=get_text("top_k"),
                    info=get_text("top_k_info")
                )
            
            with gr.Row():
                seed_number = gr.Number(
                    value=-1,
                    label=get_text("seed"),
                    info=get_text("seed_info"),
                    precision=0
                )
                random_seed_btn = gr.Button(get_text("random_seed_btn"), size="sm")
        
        # Ğ’ĞºĞ»Ğ°Ğ´ĞºĞ¸ Ğ´Ğ»Ñ Ğ¾Ğ´Ğ¸Ğ½Ğ¾Ñ‡Ğ½Ğ¾Ğ¹ Ğ¸ Ğ¿Ğ°ĞºĞµÑ‚Ğ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸
        tabs = gr.Tabs()
        with tabs:
            # Ğ’ĞºĞ»Ğ°Ğ´ĞºĞ° Ğ¾Ğ´Ğ¸Ğ½Ğ¾Ñ‡Ğ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸
            single_tab = gr.TabItem(get_text("single_processing"))
            with single_tab:
                with gr.Row():
                    with gr.Column(scale=1, elem_classes="card-style"):
                        gr.Markdown("### ğŸ“· Ğ’Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ")

                        # Tabs for Image and Video
                        media_tabs = gr.Tabs()
                        with media_tabs:
                            image_tab = gr.TabItem("ğŸ–¼ï¸ Ğ˜Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğµ")
                            with image_tab:
                                single_image = gr.Image(
                                    type="numpy",
                                    label=get_text("upload_image"),
                                    height=300
                                )
                                # Duplicate Generate/Stop buttons for quick access
                                with gr.Row():
                                    single_generate_btn_image = gr.Button(
                                        get_text("generate_btn"),
                                        variant="primary",
                                        elem_classes="generate-btn",
                                        scale=3
                                    )
                                    single_stop_btn_image = gr.Button(
                                        get_text("stop_btn"),
                                        variant="stop",
                                        scale=1
                                    )

                            video_tab = gr.TabItem("ğŸ¥ Ğ’Ğ¸Ğ´ĞµĞ¾")
                            with video_tab:
                                single_video = gr.Video(
                                    label="Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚Ğµ Ğ²Ğ¸Ğ´ĞµĞ¾",
                                    height=300
                                )
                                # Video segment controls
                                with gr.Row():
                                    video_start_time = gr.Number(
                                        label="â±ï¸ ĞĞ°Ñ‡Ğ°Ğ»Ğ¾ (ÑĞµĞºÑƒĞ½Ğ´Ñ‹)",
                                        value=None,
                                        minimum=0,
                                        info="ĞÑÑ‚Ğ°Ğ²ÑŒÑ‚Ğµ Ğ¿ÑƒÑÑ‚Ñ‹Ğ¼ Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ñ Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ²Ğ¸Ğ´ĞµĞ¾"
                                    )
                                    video_end_time = gr.Number(
                                        label="â±ï¸ ĞšĞ¾Ğ½ĞµÑ† (ÑĞµĞºÑƒĞ½Ğ´Ñ‹)",
                                        value=None,
                                        minimum=0,
                                        info="ĞÑÑ‚Ğ°Ğ²ÑŒÑ‚Ğµ Ğ¿ÑƒÑÑ‚Ñ‹Ğ¼ Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ´Ğ¾ ĞºĞ¾Ğ½Ñ†Ğ° Ğ²Ğ¸Ğ´ĞµĞ¾"
                                    )
                                # Duplicate Generate/Stop buttons for quick access
                                with gr.Row():
                                    single_generate_btn_video = gr.Button(
                                        get_text("generate_btn"),
                                        variant="primary",
                                        elem_classes="generate-btn",
                                        scale=3
                                    )
                                    single_stop_btn_video = gr.Button(
                                        get_text("stop_btn"),
                                        variant="stop",
                                        scale=1
                                    )

                        gr.Markdown("### ğŸ“ ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ")

                        single_desc_type = gr.Dropdown(
                            choices=get_description_types(),
                            value=get_description_types()[0],
                            label=get_text("description_type"),
                            info=get_text("description_type_info")
                        )
                        single_desc_length = gr.Dropdown(
                            choices=get_description_lengths(),
                            value=get_description_lengths()[0],
                            label=get_text("description_length"),
                            info=get_text("description_length_info")
                        )
                        single_num_variants = gr.Slider(
                            minimum=1,
                            maximum=5,
                            value=1,
                            step=1,
                            label=get_text("num_variants"),
                            info=get_text("num_variants_info")
                        )

                        # Custom prompt - visible by default
                        single_custom_prompt = gr.Textbox(
                            label=get_text("custom_prompt_override"),
                            placeholder=get_text("custom_prompt_placeholder"),
                            lines=3
                        )

                        # Extra options (will update based on media type)
                        with gr.Accordion(get_text("extra_options"), open=False):
                            single_extra_options = gr.CheckboxGroup(
                                choices=get_extra_options(is_video=False),  # Default to image
                                value=[],
                                label="",
                                info=get_text("extra_options_info"),
                                elem_id="single_extra_options"
                            )
                            # Hidden state to track if video is selected
                            single_is_video = gr.State(value=False)

                            # Character name field - hidden in accordion
                            single_character_name = gr.Textbox(
                                label=get_text("character_name"),
                                placeholder=get_text("character_name_placeholder"),
                                info=get_text("character_name_info"),
                                lines=1
                            )

                        # Prompt presets section - collapsed accordion at the bottom
                        with gr.Accordion("ğŸ“‹ ĞŸÑ€ĞµÑĞµÑ‚Ñ‹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ¾Ğ²", open=False):
                            with gr.Row():
                                single_preset = gr.Dropdown(
                                    choices=list(load_prompt_presets().keys()),
                                    value="None",
                                    label=get_text("prompt_preset"),
                                    info=get_text("prompt_preset_info"),
                                    scale=3
                                )
                                single_refresh_presets = gr.Button(
                                    "ğŸ”„",
                                    size="sm",
                                    scale=0,
                                    min_width=40
                                )
                            gr.Markdown("---")
                            gr.Markdown("**Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ ĞºĞ°Ğº Ğ¿Ñ€ĞµÑĞµÑ‚:**")
                            with gr.Row():
                                single_save_preset_name = gr.Textbox(
                                    label="Ğ˜Ğ¼Ñ Ğ¿Ñ€ĞµÑĞµÑ‚Ğ°",
                                    placeholder="Ğ¼Ğ¾Ğ¹_Ğ¿Ñ€ĞµÑĞµÑ‚",
                                    scale=2
                                )
                                single_save_preset_btn = gr.Button(
                                    "ğŸ’¾ Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ",
                                    size="sm",
                                    scale=1
                                )
                            single_save_preset_status = gr.Markdown("")

                        with gr.Row():
                            single_submit_btn = gr.Button(
                                get_text("generate_btn"),
                                variant="primary",
                                elem_classes="generate-btn",
                                scale=3
                            )
                            single_stop_btn = gr.Button(
                                get_text("stop_btn"),
                                variant="stop",
                                scale=1
                            )

                    with gr.Column(scale=1, elem_classes="card-style"):
                        gr.Markdown("### ğŸ“Š Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹")
                        single_status = gr.Textbox(
                            label=get_text("status"),
                            interactive=False,
                            elem_classes="status-box"
                        )
                        single_prompt_used = gr.Textbox(
                            label="Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚",
                            interactive=False,
                            lines=2
                        )

                        # Multiple variant outputs
                        single_outputs = []
                        for i in range(5):
                            with gr.Group(visible=(i == 0)) as variant_group:
                                variant_output = gr.Textbox(
                                    label=f"{get_text('variant')} {i+1}" if i > 0 else get_text("result"),
                                    lines=8,
                                    show_copy_button=True
                                )
                                single_outputs.append((variant_group, variant_output))

                        # Download result file
                        single_download = gr.File(
                            label=get_text("download_result"),
                            visible=True
                        )

                        # Console output accordion
                        with gr.Accordion("ğŸ“Ÿ ĞšĞ¾Ğ½ÑĞ¾Ğ»ÑŒ", open=False):
                            single_console_output = gr.Textbox(
                                label="",
                                lines=10,
                                max_lines=20,
                                interactive=False,
                                show_copy_button=True,
                                placeholder="Ğ—Ğ´ĞµÑÑŒ Ğ±ÑƒĞ´ÑƒÑ‚ Ğ¾Ñ‚Ğ¾Ğ±Ñ€Ğ°Ğ¶Ğ°Ñ‚ÑŒÑÑ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ Ğ¸ Ğ»Ğ¾Ğ³Ğ¸ Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸..."
                            )

                # ĞšĞ»Ğ¸ĞºĞ°Ğ±ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ñ‹ Ğ¿Ñ€Ğ¾Ğ¼Ñ‚Ğ¾Ğ²
                examples_title = gr.Markdown(f"### {get_text('examples_title')}")

            # Ğ’ĞºĞ»Ğ°Ğ´ĞºĞ° Ğ¿Ğ°ĞºĞµÑ‚Ğ½Ğ¾Ğ¹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ - Ñ€Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½Ğ° Ğ½Ğ° Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ Ğ¸ Ğ²Ğ¸Ğ´ĞµĞ¾
            batch_tab = gr.TabItem(get_text("batch_processing"))
            with batch_tab:
                # Sub-tabs for images and videos
                batch_media_tabs = gr.Tabs()
                with batch_media_tabs:
                    # BATCH IMAGES TAB
                    batch_images_tab = gr.TabItem("ğŸ“š ĞŸĞ°ĞºĞµÑ‚ Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ğ¹")
                    with batch_images_tab:
                        with gr.Row():
                            with gr.Column(scale=1, elem_classes="card-style"):
                                gr.Markdown("### ğŸ“ Ğ’Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹")
                                batch_images = gr.File(
                                    file_count="multiple",
                                    label=get_text("upload_images"),
                                    file_types=["image"]
                                )

                                gr.Markdown("### ğŸ“ ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ")

                                # Prompt preset dropdown
                                with gr.Row():
                                    batch_preset = gr.Dropdown(
                                        choices=list(load_prompt_presets().keys()),
                                        value="None",
                                        label=get_text("prompt_preset"),
                                        info=get_text("prompt_preset_info"),
                                        scale=4
                                    )
                                    batch_refresh_presets = gr.Button(
                                        "ğŸ”„",
                                        size="sm",
                                        scale=0,
                                        min_width=40
                                    )

                                batch_desc_type = gr.Dropdown(
                                    choices=get_description_types(),
                                    value=get_description_types()[0],
                                    label=get_text("description_type"),
                                    info=get_text("description_type_info")
                                )
                                batch_desc_length = gr.Dropdown(
                                    choices=get_description_lengths(),
                                    value=get_description_lengths()[0],
                                    label=get_text("description_length"),
                                    info=get_text("description_length_info")
                                )
                                batch_num_variants = gr.Slider(
                                    minimum=1,
                                    maximum=3,
                                    value=1,
                                    step=1,
                                    label=get_text("num_variants"),
                                    info=get_text("num_variants_info")
                                )

                                # Character name field
                                batch_character_name = gr.Textbox(
                                    label=get_text("character_name"),
                                    placeholder=get_text("character_name_placeholder"),
                                    info=get_text("character_name_info"),
                                    lines=1
                                )

                                # Extra options for images
                                with gr.Accordion(get_text("extra_options"), open=False):
                                    batch_extra_options = gr.CheckboxGroup(
                                        choices=get_extra_options(is_video=False),
                                        value=[],
                                        label="",
                                        info=get_text("extra_options_info")
                                    )

                                with gr.Accordion(get_text("custom_prompt_override"), open=False):
                                    batch_custom_prompt = gr.Textbox(
                                        placeholder=get_text("custom_prompt_placeholder"),
                                        lines=3,
                                        label=""
                                    )

                                gr.Markdown("### ğŸ’¾ ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ°")
                                batch_output_folder = gr.Textbox(
                                    label=get_text("output_folder"),
                                    placeholder=get_text("output_folder_placeholder"),
                                    value=""
                                )
                                batch_export_formats = gr.CheckboxGroup(
                                    choices=["TXT", "JSON", "CSV"],
                                    value=["TXT"],
                                    label=get_text("export_format")
                                )

                                with gr.Row():
                                    batch_submit_btn = gr.Button(
                                        get_text("process_batch_btn"),
                                        variant="primary",
                                        elem_classes="generate-btn",
                                        scale=3
                                    )
                                    batch_stop_btn = gr.Button(
                                        get_text("stop_btn"),
                                        variant="stop",
                                        scale=1
                                    )

                            with gr.Column(scale=1, elem_classes="card-style"):
                                gr.Markdown("### ğŸ“Š Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹")
                                batch_status = gr.Textbox(
                                    label=get_text("status"),
                                    interactive=False,
                                    elem_classes="status-box"
                                )
                                batch_output = gr.Textbox(
                                    label=get_text("results"),
                                    lines=20,
                                    show_copy_button=True
                                )

                                # Download result file
                                batch_download = gr.File(
                                    label=get_text("download_result"),
                                    visible=True
                                )

                    # BATCH VIDEOS TAB
                    batch_videos_tab = gr.TabItem("ğŸ¬ ĞŸĞ°ĞºĞµÑ‚ Ğ²Ğ¸Ğ´ĞµĞ¾")
                    with batch_videos_tab:
                        with gr.Row():
                            with gr.Column(scale=1, elem_classes="card-style"):
                                gr.Markdown("### ğŸ“ Ğ’Ñ…Ğ¾Ğ´Ğ½Ñ‹Ğµ Ğ²Ğ¸Ğ´ĞµĞ¾ Ñ„Ğ°Ğ¹Ğ»Ñ‹")
                                batch_videos = gr.File(
                                    file_count="multiple",
                                    label="Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚Ğµ Ğ²Ğ¸Ğ´ĞµĞ¾",
                                    file_types=["video"]
                                )

                                gr.Markdown("### ğŸ“ ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ñ")

                                # Prompt preset dropdown
                                with gr.Row():
                                    batch_video_preset = gr.Dropdown(
                                        choices=list(load_prompt_presets().keys()),
                                        value="None",
                                        label=get_text("prompt_preset"),
                                        info=get_text("prompt_preset_info"),
                                        scale=4
                                    )
                                    batch_video_refresh_presets = gr.Button(
                                        "ğŸ”„",
                                        size="sm",
                                        scale=0,
                                        min_width=40
                                    )

                                batch_video_desc_type = gr.Dropdown(
                                    choices=get_description_types(),
                                    value=get_description_types()[0],
                                    label=get_text("description_type"),
                                    info=get_text("description_type_info")
                                )
                                batch_video_desc_length = gr.Dropdown(
                                    choices=get_description_lengths(),
                                    value=get_description_lengths()[0],
                                    label=get_text("description_length"),
                                    info=get_text("description_length_info")
                                )
                                batch_video_num_variants = gr.Slider(
                                    minimum=1,
                                    maximum=3,
                                    value=1,
                                    step=1,
                                    label=get_text("num_variants"),
                                    info=get_text("num_variants_info")
                                )

                                # Character name field
                                batch_video_character_name = gr.Textbox(
                                    label=get_text("character_name"),
                                    placeholder=get_text("character_name_placeholder"),
                                    info=get_text("character_name_info"),
                                    lines=1
                                )

                                # Extra options for videos
                                with gr.Accordion(get_text("extra_options"), open=False):
                                    batch_video_extra_options = gr.CheckboxGroup(
                                        choices=get_extra_options(is_video=True),
                                        value=[],
                                        label="",
                                        info=get_text("extra_options_info")
                                    )

                                with gr.Accordion(get_text("custom_prompt_override"), open=False):
                                    batch_video_custom_prompt = gr.Textbox(
                                        placeholder=get_text("custom_prompt_placeholder"),
                                        lines=3,
                                        label=""
                                    )

                                gr.Markdown("### ğŸ’¾ ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ ÑĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ°")
                                batch_video_output_folder = gr.Textbox(
                                    label=get_text("output_folder"),
                                    placeholder=get_text("output_folder_placeholder"),
                                    value=""
                                )
                                batch_video_export_formats = gr.CheckboxGroup(
                                    choices=["TXT", "JSON", "CSV"],
                                    value=["TXT"],
                                    label=get_text("export_format")
                                )

                                with gr.Row():
                                    batch_video_submit_btn = gr.Button(
                                        "ğŸš€ ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ğ²Ğ¸Ğ´ĞµĞ¾",
                                        variant="primary",
                                        elem_classes="generate-btn",
                                        scale=3
                                    )
                                    batch_video_stop_btn = gr.Button(
                                        get_text("stop_btn"),
                                        variant="stop",
                                        scale=1
                                    )

                            with gr.Column(scale=1, elem_classes="card-style"):
                                gr.Markdown("### ğŸ“Š Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹")
                                batch_video_status = gr.Textbox(
                                    label=get_text("status"),
                                    interactive=False,
                                    elem_classes="status-box"
                                )
                                batch_video_output = gr.Textbox(
                                    label=get_text("results"),
                                    lines=20,
                                    show_copy_button=True
                                )

                                # Download result file
                                batch_video_download = gr.File(
                                    label=get_text("download_result"),
                                    visible=True
                                )
        
        # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸ĞºĞ¸ ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ğ¹

        # Function to update extra options based on media type
        def update_extra_options_for_media(is_video):
            return gr.update(choices=get_extra_options(is_video=is_video), value=[])

        # Media tab selection handlers - update extra options when switching tabs
        def on_image_tab_select():
            return gr.update(choices=get_extra_options(is_video=False), value=[]), False

        def on_video_tab_select():
            return gr.update(choices=get_extra_options(is_video=True), value=[]), True

        # Connect media tab selection to extra options update
        image_tab.select(fn=on_image_tab_select, outputs=[single_extra_options, single_is_video])
        video_tab.select(fn=on_video_tab_select, outputs=[single_extra_options, single_is_video])

        def change_language(lang):
            global current_language
            current_language = lang

            # Return updated text for key components
            return [
                f"{get_text('subtitle')}",  # header_md
                gr.update(label=get_text("model_selection"), info=get_text("model_info")),  # model_dropdown
                gr.update(label=get_text("quantization"), info=get_text("quantization_info")),  # quantization_dropdown
                gr.update(label=get_text("language"), info=get_text("language_info")),  # language_dropdown
                gr.update(label=get_text("advanced_params")),  # advanced_accordion
                gr.update(value=get_text("generate_btn")),  # single_submit_btn
                gr.update(value=get_text("process_batch_btn")),  # batch_submit_btn
                gr.update(choices=get_description_types(), value=get_description_types()[0]),  # single_desc_type
                gr.update(choices=get_description_lengths(), value=get_description_lengths()[0]),  # single_desc_length
                gr.update(choices=get_description_types(), value=get_description_types()[0]),  # batch_desc_type
                gr.update(choices=get_description_lengths(), value=get_description_lengths()[0]),  # batch_desc_length
                gr.update(choices=get_extra_options(is_video=False), value=[]),  # single_extra_options
                gr.update(choices=get_extra_options(is_video=False), value=[]),  # batch_extra_options
                gr.update(choices=get_extra_options(is_video=True), value=[]),  # batch_video_extra_options
                gr.update(value=get_text("stop_btn")),  # single_stop_btn
                gr.update(value=get_text("stop_btn")),  # batch_stop_btn
                gr.update(value=get_text("stop_btn")),  # batch_video_stop_btn
                gr.update(value=get_text("generate_btn")),  # single_generate_btn_image
                gr.update(value=get_text("stop_btn")),  # single_stop_btn_image
                gr.update(value=get_text("generate_btn")),  # single_generate_btn_video
                gr.update(value=get_text("stop_btn")),  # single_stop_btn_video
            ]

        language_dropdown.change(
            fn=change_language,
            inputs=language_dropdown,
            outputs=[
                header_md,
                model_dropdown,
                quantization_dropdown,
                language_dropdown,
                advanced_accordion,
                single_submit_btn,
                batch_submit_btn,
                single_desc_type,
                single_desc_length,
                batch_desc_type,
                batch_desc_length,
                single_extra_options,
                batch_extra_options,
                batch_video_extra_options,
                single_stop_btn,
                batch_stop_btn,
                batch_video_stop_btn,
                single_generate_btn_image,
                single_stop_btn_image,
                single_generate_btn_video,
                single_stop_btn_video,
            ]
        )

        # Stop button handlers
        single_stop_btn.click(
            fn=stop_generation,
            outputs=single_status
        )

        batch_stop_btn.click(
            fn=stop_generation,
            outputs=batch_status
        )

        batch_video_stop_btn.click(
            fn=stop_generation,
            outputs=batch_video_status
        )

        # Model list refresh handler
        def refresh_model_list():
            """ĞĞ±Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ñ Ğ°ĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğ¼ ÑÑ‚Ğ°Ñ‚ÑƒÑĞ¾Ğ¼ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸"""
            return gr.update(choices=get_model_choices())

        refresh_models_btn.click(
            fn=refresh_model_list,
            outputs=model_dropdown
        )

        # Preset refresh handlers
        def refresh_presets():
            presets = load_prompt_presets()
            return gr.update(choices=list(presets.keys()), value="None")

        single_refresh_presets.click(
            fn=refresh_presets,
            outputs=single_preset
        )

        batch_refresh_presets.click(
            fn=refresh_presets,
            outputs=batch_preset
        )

        batch_video_refresh_presets.click(
            fn=refresh_presets,
            outputs=batch_video_preset
        )

        # Preset selection handlers (load preset text into custom prompt)
        def load_preset(preset_name):
            presets = load_prompt_presets()
            if preset_name and preset_name != "None":
                return presets.get(preset_name, "")
            return ""

        single_preset.change(
            fn=load_preset,
            inputs=single_preset,
            outputs=single_custom_prompt
        )

        batch_preset.change(
            fn=load_preset,
            inputs=batch_preset,
            outputs=batch_custom_prompt
        )

        batch_video_preset.change(
            fn=load_preset,
            inputs=batch_video_preset,
            outputs=batch_video_custom_prompt
        )

        random_seed_btn.click(
            fn=random_seed,
            outputs=seed_number
        )

        # Update variant visibility based on slider
        def update_variant_visibility(num_variants):
            updates = []
            for i in range(5):
                updates.append(gr.update(visible=(i < num_variants)))
            return updates

        single_num_variants.change(
            fn=update_variant_visibility,
            inputs=[single_num_variants],
            outputs=[group for group, _ in single_outputs]
        )

        # Single image processing with button lock
        def process_single_wrapper(image, video, video_start_time, video_end_time, desc_type, desc_length, custom_prompt,
                                   extra_options, character_name, num_variants,
                                   model_name, quantization, max_tokens, temperature, top_p, top_k, seed):
            # Start capturing console output
            log_capture.clear_logs()
            log_capture.start_capture()

            # Model indicator - loading
            model_indicator = f"â³ **Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸** {model_name}..."

            # Disable button at start
            yield gr.update(value=get_text("generating"), interactive=False), "", "", *[gr.update(value="") for _ in range(5)], None, "", model_indicator

            results = []
            download_path = None

            # Process and yield results
            for status, prompt_used, results, download_path, console_logs in process_single_image(
                image, video, video_start_time, video_end_time, desc_type, desc_length, custom_prompt,
                extra_options, character_name, num_variants,
                model_name, quantization, max_tokens, temperature, top_p, top_k, seed
            ):
                # Prepare outputs for each variant box
                variant_outputs = []
                for i in range(5):
                    if i < len(results):
                        variant_outputs.append(gr.update(value=results[i]))
                    else:
                        variant_outputs.append(gr.update(value=""))

                # Update model indicator
                cached_size = get_model_cache_size(model_name)
                size_str = f" [{cached_size}]" if cached_size else ""
                model_indicator = f"âœ… **{model_name}**{size_str} | {quantization}"

                # console_logs already received from process_single_image
                yield gr.update(value=get_text("generating"), interactive=False), status, prompt_used, *variant_outputs, download_path, console_logs, model_indicator

            # Stop capturing and get final logs
            log_capture.stop_capture()
            final_logs = log_capture.get_logs()

            # Re-enable button at end
            final_outputs = []
            for i in range(5):
                if i < len(results):
                    final_outputs.append(gr.update(value=results[i]))
                else:
                    final_outputs.append(gr.update(value=""))

            # Final model indicator
            cached_size = get_model_cache_size(model_name)
            size_str = f" [{cached_size}]" if cached_size else ""
            final_model_indicator = f"âœ… **{model_name}**{size_str} | {quantization}"

            yield gr.update(value=get_text("generate_btn"), interactive=True), status, prompt_used, *final_outputs, download_path, final_logs, final_model_indicator

        single_submit_btn.click(
            fn=process_single_wrapper,
            inputs=[
                single_image,
                single_video,
                single_desc_type,
                single_desc_length,
                single_custom_prompt,
                single_extra_options,
                single_character_name,
                single_num_variants,
                model_dropdown,
                quantization_dropdown,
                max_tokens_slider,
                temperature_slider,
                top_p_slider,
                top_k_slider,
                seed_number
            ],
            outputs=[single_submit_btn, single_status, single_prompt_used] + [output for _, output in single_outputs] + [single_download, single_console_output, current_model_indicator]
        )

        # Duplicate Generate buttons in Image/Video tabs - same functionality
        single_generate_btn_image.click(
            fn=process_single_wrapper,
            inputs=[
                single_image,
                single_video,
                video_start_time,
                video_end_time,
                single_desc_type,
                single_desc_length,
                single_custom_prompt,
                single_extra_options,
                single_character_name,
                single_num_variants,
                model_dropdown,
                quantization_dropdown,
                max_tokens_slider,
                temperature_slider,
                top_p_slider,
                top_k_slider,
                seed_number
            ],
            outputs=[single_submit_btn, single_status, single_prompt_used] + [output for _, output in single_outputs] + [single_download, single_console_output, current_model_indicator]
        )

        single_generate_btn_video.click(
            fn=process_single_wrapper,
            inputs=[
                single_image,
                single_video,
                video_start_time,
                video_end_time,
                single_desc_type,
                single_desc_length,
                single_custom_prompt,
                single_extra_options,
                single_character_name,
                single_num_variants,
                model_dropdown,
                quantization_dropdown,
                max_tokens_slider,
                temperature_slider,
                top_p_slider,
                top_k_slider,
                seed_number
            ],
            outputs=[single_submit_btn, single_status, single_prompt_used] + [output for _, output in single_outputs] + [single_download, single_console_output, current_model_indicator]
        )

        # Duplicate Stop buttons in Image/Video tabs
        single_stop_btn_image.click(
            fn=stop_generation,
            outputs=single_status
        )

        single_stop_btn_video.click(
            fn=stop_generation,
            outputs=single_status
        )

        # Save preset handler
        def save_preset(name, prompt):
            if not name:
                return "âŒ Please enter a preset name"
            msg = save_prompt_preset(name, prompt)
            new_presets = list(load_prompt_presets().keys())
            return msg, gr.update(choices=new_presets, value=name if "successfully" in msg else None)

        single_save_preset_btn.click(
            fn=save_preset,
            inputs=[single_save_preset_name, single_custom_prompt],
            outputs=[single_save_preset_status, single_preset]
        )

        # Batch processing with button lock
        def process_batch_wrapper(files, desc_type, desc_length, custom_prompt,
                                  extra_options, character_name, num_variants,
                                  output_folder, export_formats, model_name, quantization,
                                  max_tokens, temperature, top_p, top_k, seed):
            # Disable button at start
            yield gr.update(value=get_text("generating"), interactive=False), "", "", None

            download_path = None

            # Process and yield results
            for status, output_text, download_path in process_batch_images(
                files, desc_type, desc_length, custom_prompt,
                extra_options, character_name, num_variants,
                output_folder, export_formats, model_name, quantization,
                max_tokens, temperature, top_p, top_k, seed
            ):
                yield gr.update(value=get_text("generating"), interactive=False), status, output_text, download_path

            # Re-enable button at end
            yield gr.update(value=get_text("process_batch_btn"), interactive=True), status, output_text, download_path

        batch_submit_btn.click(
            fn=process_batch_wrapper,
            inputs=[
                batch_images,
                batch_desc_type,
                batch_desc_length,
                batch_custom_prompt,
                batch_extra_options,
                batch_character_name,
                batch_num_variants,
                batch_output_folder,
                batch_export_formats,
                model_dropdown,
                quantization_dropdown,
                max_tokens_slider,
                temperature_slider,
                top_p_slider,
                top_k_slider,
                seed_number
            ],
            outputs=[batch_submit_btn, batch_status, batch_output, batch_download]
        )

        # Batch video processing with is_video=True
        def process_batch_video_wrapper(files, desc_type, desc_length, custom_prompt,
                                        extra_options, character_name, num_variants,
                                        output_folder, export_formats, model_name, quantization,
                                        max_tokens, temperature, top_p, top_k, seed):
            # Disable button at start
            yield gr.update(value="â³ Processing...", interactive=False), "", "", None

            download_path = None

            # Process and yield results with is_video=True
            for status, output_text, download_path in process_batch_images(
                files, desc_type, desc_length, custom_prompt,
                extra_options, character_name, num_variants,
                output_folder, export_formats, model_name, quantization,
                max_tokens, temperature, top_p, top_k, seed,
                is_video=True  # KEY DIFFERENCE: process as videos
            ):
                yield gr.update(value="â³ Processing...", interactive=False), status, output_text, download_path

            # Re-enable button at end
            yield gr.update(value="ğŸš€ ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ğ²Ğ¸Ğ´ĞµĞ¾", interactive=True), status, output_text, download_path

        batch_video_submit_btn.click(
            fn=process_batch_video_wrapper,
            inputs=[
                batch_videos,
                batch_video_desc_type,
                batch_video_desc_length,
                batch_video_custom_prompt,
                batch_video_extra_options,
                batch_video_character_name,
                batch_video_num_variants,
                batch_video_output_folder,
                batch_video_export_formats,
                model_dropdown,
                quantization_dropdown,
                max_tokens_slider,
                temperature_slider,
                top_p_slider,
                top_k_slider,
                seed_number
            ],
            outputs=[batch_video_submit_btn, batch_video_status, batch_video_output, batch_video_download]
        )

        return demo

# Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ Gradio
demo = create_interface()

if __name__ == "__main__":
    # Enable queue for progress bar support
    demo.queue(max_size=20, default_concurrency_limit=1).launch(
        server_name="127.0.0.1",
        server_port=None,
        share=False,
        show_error=True,
        inbrowser=True
    )
