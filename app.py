import gradio as gr
import torch
from transformers import Qwen3VLForConditionalGeneration, AutoProcessor, BitsAndBytesConfig
from qwen_vl_utils import process_vision_info
from PIL import Image
import random
import os
import warnings
from typing import List, Tuple, Optional, Generator
import requests
from io import BytesIO
import urllib.parse
import gc
import json
import csv
import shutil
from datetime import datetime
import time
import tempfile

# Optional: psutil for memory monitoring
try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False
    print("Note: psutil not installed. RAM monitoring will be limited.")

# Suppress specific warnings
warnings.filterwarnings('ignore', message='.*meta device.*')

# Global flag for stopping generation
stop_generation_flag = False

# Base directory for portable app
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
TEMP_DIR = os.path.join(SCRIPT_DIR, "temp")
OUTPUT_DIR = os.path.join(SCRIPT_DIR, "output")
DATASETS_DIR = os.path.join(SCRIPT_DIR, "datasets")
PROMPTS_DIR = os.path.join(SCRIPT_DIR, "prompts")

# Create directories if they don't exist
os.makedirs(TEMP_DIR, exist_ok=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(DATASETS_DIR, exist_ok=True)
os.makedirs(PROMPTS_DIR, exist_ok=True)

# Extra options for description enhancement
EXTRA_OPTIONS = {
    "en": {
        "Include lighting info": "Include information about lighting.",
        "Include camera angle": "Include information about camera angle.",
        "Include watermark info": "Include information about whether there is a watermark or not.",
        "Include JPEG artifacts info": "Include information about whether there are JPEG artifacts or not.",
        "Include camera/photo details": "If it is a photo, include information about what camera was likely used and details such as aperture, shutter speed, ISO, etc.",
        "Keep it SFW/PG": "Do NOT include anything sexual; keep it PG.",
        "Don't mention resolution": "Do NOT mention the image's resolution.",
        "Include aesthetic quality": "Include information about the subjective aesthetic quality of the image from low to very high.",
        "Include composition style": "Include information on the image's composition style, such as leading lines, rule of thirds, or symmetry.",
        "Don't mention text in image": "Do NOT mention any text that is in the image.",
        "Include depth of field": "Specify the depth of field and whether the background is in focus or blurred.",
        "Describe only key elements": "ONLY describe the most important elements of the image."
    },
    "ru": {
        "–î–æ–±–∞–≤–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—Å–≤–µ—â–µ–Ω–∏–∏": "–î–æ–±–∞–≤—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—Å–≤–µ—â–µ–Ω–∏–∏.",
        "–î–æ–±–∞–≤–∏—Ç—å —Ä–∞–∫—É—Ä—Å –∫–∞–º–µ—Ä—ã": "–î–æ–±–∞–≤—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ä–∞–∫—É—Ä—Å–µ –∫–∞–º–µ—Ä—ã.",
        "–£–ø–æ–º—è–Ω—É—Ç—å –≤–æ–¥—è–Ω–æ–π –∑–Ω–∞–∫": "–£–∫–∞–∂–∏, –µ—Å—Ç—å –ª–∏ –≤–æ–¥—è–Ω–æ–π –∑–Ω–∞–∫ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏.",
        "–£–ø–æ–º—è–Ω—É—Ç—å JPEG –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã": "–£–∫–∞–∂–∏, –µ—Å—Ç—å –ª–∏ JPEG –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏.",
        "–î–æ–±–∞–≤–∏—Ç—å –¥–µ—Ç–∞–ª–∏ –∫–∞–º–µ—Ä—ã/—Ñ–æ—Ç–æ": "–ï—Å–ª–∏ —ç—Ç–æ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è, —É–∫–∞–∂–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫–∞–º–µ—Ä–µ, –∞–ø–µ—Ä—Ç—É—Ä–µ, –≤—ã–¥–µ—Ä–∂–∫–µ, ISO –∏ —Ç.–¥.",
        "–°–æ—Ö—Ä–∞–Ω–∏—Ç—å SFW/PG —Ä–µ–π—Ç–∏–Ω–≥": "–ù–ï –≤–∫–ª—é—á–∞–π —Å–µ–∫—Å—É–∞–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç, —Å–æ—Ö—Ä–∞–Ω—è–π —Ä–µ–π—Ç–∏–Ω–≥ PG.",
        "–ù–µ —É–ø–æ–º–∏–Ω–∞—Ç—å —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ": "–ù–ï —É–ø–æ–º–∏–Ω–∞–π —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.",
        "–î–æ–±–∞–≤–∏—Ç—å —ç—Å—Ç–µ—Ç–∏—á–µ—Å–∫—É—é –æ—Ü–µ–Ω–∫—É": "–î–æ–±–∞–≤—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—É–±—ä–µ–∫—Ç–∏–≤–Ω–æ–º —ç—Å—Ç–µ—Ç–∏—á–µ—Å–∫–æ–º –∫–∞—á–µ—Å—Ç–≤–µ –æ—Ç –Ω–∏–∑–∫–æ–≥–æ –¥–æ –æ—á–µ–Ω—å –≤—ã—Å–æ–∫–æ–≥–æ.",
        "–î–æ–±–∞–≤–∏—Ç—å —Å—Ç–∏–ª—å –∫–æ–º–ø–æ–∑–∏—Ü–∏–∏": "–î–æ–±–∞–≤—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å—Ç–∏–ª–µ –∫–æ–º–ø–æ–∑–∏—Ü–∏–∏ (–≤–µ–¥—É—â–∏–µ –ª–∏–Ω–∏–∏, –ø—Ä–∞–≤–∏–ª–æ —Ç—Ä–µ—Ç–µ–π, —Å–∏–º–º–µ—Ç—Ä–∏—è).",
        "–ù–µ —É–ø–æ–º–∏–Ω–∞—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏": "–ù–ï —É–ø–æ–º–∏–Ω–∞–π —Ç–µ–∫—Å—Ç, –∫–æ—Ç–æ—Ä—ã–π –µ—Å—Ç—å –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏.",
        "–î–æ–±–∞–≤–∏—Ç—å –≥–ª—É–±–∏–Ω—É —Ä–µ–∑–∫–æ—Å—Ç–∏": "–£–∫–∞–∂–∏ –≥–ª—É–±–∏–Ω—É —Ä–µ–∑–∫–æ—Å—Ç–∏ –∏ —Ä–∞–∑–º—ã—Ç–æ—Å—Ç—å —Ñ–æ–Ω–∞.",
        "–û–ø–∏—Å—ã–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ –∫–ª—é—á–µ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã": "–û–ø–∏—Å—ã–≤–∞–π –¢–û–õ–¨–ö–û —Å–∞–º—ã–µ –≤–∞–∂–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."
    },
    "zh": {
        "ÂåÖÂê´ÂÖâÁÖß‰ø°ÊÅØ": "ÂåÖÂê´ÂÖâÁÖß‰ø°ÊÅØ„ÄÇ",
        "ÂåÖÂê´Áõ∏Êú∫ËßíÂ∫¶": "ÂåÖÂê´Áõ∏Êú∫ËßíÂ∫¶‰ø°ÊÅØ„ÄÇ",
        "ÊèêÂèäÊ∞¥Âç∞": "ËØ¥ÊòéÂõæÁâáÊòØÂê¶ÊúâÊ∞¥Âç∞„ÄÇ",
        "ÊèêÂèäJPEG‰º™ÂΩ±": "ËØ¥ÊòéÂõæÁâáÊòØÂê¶ÊúâJPEG‰º™ÂΩ±„ÄÇ",
        "ÂåÖÂê´Áõ∏Êú∫/ÁÖßÁâáËØ¶ÊÉÖ": "Â¶ÇÊûúÊòØÁÖßÁâáÔºåÂåÖÂê´ÂèØËÉΩ‰ΩøÁî®ÁöÑÁõ∏Êú∫‰ø°ÊÅØÔºåÂ¶ÇÂÖâÂúà„ÄÅÂø´Èó®ÈÄüÂ∫¶„ÄÅISOÁ≠â„ÄÇ",
        "‰øùÊåÅSFW/PGÁ∫ßÂà´": "‰∏çË¶ÅÂåÖÂê´‰ªª‰ΩïÊÄßÁõ∏ÂÖ≥ÂÜÖÂÆπÔºå‰øùÊåÅPGÁ∫ßÂà´„ÄÇ",
        "‰∏çË¶ÅÊèêÂèäÂàÜËæ®Áéá": "‰∏çË¶ÅÊèêÂèäÂõæÁâáÁöÑÂàÜËæ®Áéá„ÄÇ",
        "ÂåÖÂê´ÁæéÂ≠¶Ë¥®ÈáèËØÑ‰ª∑": "ÂåÖÂê´‰ªé‰ΩéÂà∞ÈùûÂ∏∏È´òÁöÑ‰∏ªËßÇÁæéÂ≠¶Ë¥®ÈáèËØÑ‰ª∑„ÄÇ",
        "ÂåÖÂê´ÊûÑÂõæÈ£éÊ†º": "ÂåÖÂê´ÊûÑÂõæÈ£éÊ†º‰ø°ÊÅØÔºåÂ¶ÇÂºïÂØºÁ∫ø„ÄÅ‰∏âÂàÜÊ≥ïÂàôÊàñÂØπÁß∞ÊÄß„ÄÇ",
        "‰∏çË¶ÅÊèêÂèäÂõæÁâá‰∏≠ÁöÑÊñáÂ≠ó": "‰∏çË¶ÅÊèêÂèäÂõæÁâá‰∏≠ÁöÑ‰ªª‰ΩïÊñáÂ≠ó„ÄÇ",
        "ÂåÖÂê´ÊôØÊ∑±‰ø°ÊÅØ": "ËØ¥ÊòéÊôØÊ∑±‰ª•ÂèäËÉåÊôØÊòØÂê¶Ê®°Á≥ä„ÄÇ",
        "Âè™ÊèèËø∞ÂÖ≥ÈîÆÂÖÉÁ¥†": "Âè™ÊèèËø∞ÂõæÁâá‰∏≠ÊúÄÈáçË¶ÅÁöÑÂÖÉÁ¥†„ÄÇ"
    }
}

def get_memory_info() -> str:
    """Get current memory usage information"""
    info_parts = []

    # GPU memory
    if torch.cuda.is_available():
        try:
            allocated = torch.cuda.memory_allocated() / (1024 ** 3)
            reserved = torch.cuda.memory_reserved() / (1024 ** 3)
            total = torch.cuda.get_device_properties(0).total_memory / (1024 ** 3)
            info_parts.append(f"GPU: {allocated:.1f}/{total:.1f} GB (reserved: {reserved:.1f} GB)")
        except:
            pass

    # RAM
    if PSUTIL_AVAILABLE:
        try:
            process = psutil.Process(os.getpid())
            ram_usage = process.memory_info().rss / (1024 ** 3)
            info_parts.append(f"RAM: {ram_usage:.1f} GB")
        except:
            pass

    return " | ".join(info_parts) if info_parts else "Memory info unavailable"

def load_prompt_presets() -> dict:
    """Load prompt presets from the prompts directory"""
    presets = {"None": ""}

    if not os.path.exists(PROMPTS_DIR):
        return presets

    for filename in os.listdir(PROMPTS_DIR):
        if filename.endswith('.txt'):
            preset_name = os.path.splitext(filename)[0]
            try:
                with open(os.path.join(PROMPTS_DIR, filename), 'r', encoding='utf-8') as f:
                    presets[preset_name] = f.read().strip()
            except:
                pass

    return presets

def save_prompt_preset(name: str, prompt: str) -> str:
    """Save a prompt preset to the prompts directory"""
    if not name or not name.strip():
        return "‚ùå Please provide a preset name"

    if not prompt or not prompt.strip():
        return "‚ùå Please provide a prompt to save"

    # Sanitize filename
    safe_name = "".join(c for c in name if c.isalnum() or c in "_ -").strip()
    if not safe_name:
        return "‚ùå Invalid preset name"

    try:
        os.makedirs(PROMPTS_DIR, exist_ok=True)
        filepath = os.path.join(PROMPTS_DIR, f"{safe_name}.txt")
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(prompt.strip())
        return f"‚úÖ Preset '{safe_name}' saved successfully!"
    except Exception as e:
        return f"‚ùå Error saving preset: {str(e)}"

def save_text_to_file(text: str, filename: str = "result.txt") -> str:
    """Save text to a temporary file and return the path"""
    temp_file = os.path.join(TEMP_DIR, filename)
    with open(temp_file, 'w', encoding='utf-8') as f:
        f.write(text)
    return temp_file

def stop_generation():
    """Set the stop flag to True"""
    global stop_generation_flag
    stop_generation_flag = True
    return "üõë Stopping generation..."

def reset_stop_flag():
    """Reset the stop flag"""
    global stop_generation_flag
    stop_generation_flag = False

# Custom CSS for beautiful UI
CUSTOM_CSS = """
/* Main container styling */
.gradio-container {
    background: linear-gradient(135deg, #f8fafc 0%, #e2e8f0 100%) !important;
}

/* Card style blocks */
.card-style {
    background: rgba(255, 255, 255, 0.9) !important;
    border: 1px solid rgba(203, 213, 225, 0.5) !important;
    box-shadow: 0 8px 32px rgba(100, 116, 139, 0.1) !important;
    border-radius: 16px !important;
    padding: 1.5rem !important;
    margin-bottom: 1rem !important;
}

/* Main header with gradient */
.main-header {
    background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
    padding: 2rem;
    border-radius: 20px;
    margin-bottom: 1.5rem;
    text-align: center;
    box-shadow: 0 10px 40px rgba(102, 126, 234, 0.3);
}

.main-header h1 {
    color: white !important;
    font-size: 2.5rem !important;
    font-weight: 700 !important;
    margin: 0 !important;
    text-shadow: 0 2px 4px rgba(0,0,0,0.3);
}

.main-header p {
    color: rgba(255,255,255,0.9) !important;
    font-size: 1.1rem !important;
    margin: 0.5rem 0 0 0 !important;
}

.main-header a {
    color: white !important;
    text-decoration: underline;
}

/* Generate button styling */
.generate-btn {
    min-height: 50px !important;
    font-size: 1.1rem !important;
    font-weight: 600 !important;
}

/* Status box */
.status-box {
    background: linear-gradient(135deg, #f0f9ff 0%, #e0f2fe 100%) !important;
    border: 1px solid #7dd3fc !important;
    border-radius: 12px !important;
    padding: 1rem !important;
}

/* Progress info */
.progress-info {
    background: #f0fdf4 !important;
    border: 1px solid #86efac !important;
    border-radius: 8px !important;
    padding: 0.75rem !important;
}

/* Dark mode support */
.dark .gradio-container {
    background: linear-gradient(135deg, #0f172a 0%, #1e293b 100%) !important;
}

.dark .card-style {
    background: rgba(30, 41, 59, 0.9) !important;
    border: 1px solid rgba(51, 65, 85, 0.5) !important;
    box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3) !important;
}

.dark .status-box {
    background: linear-gradient(135deg, #1e3a5f 0%, #1e293b 100%) !important;
    border: 1px solid #3b82f6 !important;
}

.dark .progress-info {
    background: #14532d !important;
    border: 1px solid #22c55e !important;
}

/* Accordion styling */
.settings-accordion {
    border-radius: 12px !important;
    overflow: hidden !important;
}

/* Result variants */
.variant-box {
    border: 2px solid #e2e8f0;
    border-radius: 12px;
    padding: 1rem;
    margin-bottom: 0.5rem;
    transition: all 0.2s ease;
}

.variant-box:hover {
    border-color: #667eea;
    box-shadow: 0 4px 12px rgba(102, 126, 234, 0.15);
}

/* Export buttons */
.export-btn {
    margin: 0.25rem !important;
}
"""

# Description types with prompts
DESCRIPTION_TYPES = {
    "en": {
        "Descriptive (Formal)": "Write a detailed and formal description of this image.",
        "Descriptive (Informal)": "Write a casual, friendly description of this image.",
        "Product Description": "Write a compelling product description for e-commerce based on this image.",
        "SEO Description": "Write an SEO-optimized description for this image, maximum 160 characters.",
        "Stable Diffusion Prompt": "Write a detailed Stable Diffusion prompt to recreate this image.",
        "MidJourney Prompt": "Write a MidJourney prompt to recreate this image.",
        "Booru Tags": "Write a list of Booru-style tags for this image, separated by commas.",
        "Art Critic Analysis": "Analyze this image like an art critic, discussing composition, style, color, lighting, and artistic elements.",
        "Social Media Caption": "Write an engaging social media caption for this image.",
        "Custom": ""
    },
    "ru": {
        "–û–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã–π (—Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π)": "–ù–∞–ø–∏—à–∏ –¥–µ—Ç–∞–ª—å–Ω–æ–µ –∏ —Ñ–æ—Ä–º–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —ç—Ç–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.",
        "–û–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã–π (–Ω–µ—Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π)": "–ù–∞–ø–∏—à–∏ –Ω–µ–ø—Ä–∏–Ω—É–∂–¥—ë–Ω–Ω–æ–µ, –¥—Ä—É–∂–µ–ª—é–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —ç—Ç–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.",
        "–û–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞": "–ù–∞–ø–∏—à–∏ –ø—Ä–∏–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ –¥–ª—è –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.",
        "SEO –æ–ø–∏—Å–∞–Ω–∏–µ": "–ù–∞–ø–∏—à–∏ SEO-–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è —ç—Ç–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –º–∞–∫—Å–∏–º—É–º 160 —Å–∏–º–≤–æ–ª–æ–≤.",
        "–ü—Ä–æ–º–ø—Ç Stable Diffusion": "–ù–∞–ø–∏—à–∏ –¥–µ—Ç–∞–ª—å–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è Stable Diffusion, —á—Ç–æ–±—ã –≤–æ—Å—Å–æ–∑–¥–∞—Ç—å —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.",
        "–ü—Ä–æ–º–ø—Ç MidJourney": "–ù–∞–ø–∏—à–∏ –ø—Ä–æ–º–ø—Ç –¥–ª—è MidJourney, —á—Ç–æ–±—ã –≤–æ—Å—Å–æ–∑–¥–∞—Ç—å —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.",
        "–¢–µ–≥–∏ Booru": "–ù–∞–ø–∏—à–∏ —Å–ø–∏—Å–æ–∫ —Ç–µ–≥–æ–≤ –≤ —Å—Ç–∏–ª–µ Booru –¥–ª—è —ç—Ç–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, —Ä–∞–∑–¥–µ–ª—ë–Ω–Ω—ã—Ö –∑–∞–ø—è—Ç—ã–º–∏.",
        "–ê–Ω–∞–ª–∏–∑ –∏—Å–∫—É—Å—Å—Ç–≤–æ–≤–µ–¥–∞": "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞–∫ –∏—Å–∫—É—Å—Å—Ç–≤–æ–≤–µ–¥, –æ–±—Å—É–∂–¥–∞—è –∫–æ–º–ø–æ–∑–∏—Ü–∏—é, —Å—Ç–∏–ª—å, —Ü–≤–µ—Ç, –æ—Å–≤–µ—â–µ–Ω–∏–µ –∏ —Ö—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.",
        "–ü–æ—Å—Ç –¥–ª—è —Å–æ—Ü—Å–µ—Ç–µ–π": "–ù–∞–ø–∏—à–∏ –ø—Ä–∏–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω—É—é –ø–æ–¥–ø–∏—Å—å –¥–ª—è —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç–µ–π –∫ —ç—Ç–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.",
        "–°–≤–æ–π –ø—Ä–æ–º–ø—Ç": ""
    },
    "zh": {
        "ÊèèËø∞ÊÄßÔºàÊ≠£ÂºèÔºâ": "ÂÜô‰∏Ä‰∏™ËØ¶ÁªÜÊ≠£ÂºèÁöÑÂõæÂÉèÊèèËø∞„ÄÇ",
        "ÊèèËø∞ÊÄßÔºàÈùûÊ≠£ÂºèÔºâ": "ÂÜô‰∏Ä‰∏™ËΩªÊùæÂèãÂ•ΩÁöÑÂõæÂÉèÊèèËø∞„ÄÇ",
        "‰∫ßÂìÅÊèèËø∞": "Ê†πÊçÆËøôÂº†ÂõæÁâá‰∏∫ÁîµÂïÜÂπ≥Âè∞ÂÜô‰∏Ä‰∏™Âê∏Âºï‰∫∫ÁöÑ‰∫ßÂìÅÊèèËø∞„ÄÇ",
        "SEOÊèèËø∞": "‰∏∫ËøôÂº†ÂõæÁâáÂÜô‰∏Ä‰∏™SEO‰ºòÂåñÁöÑÊèèËø∞ÔºåÊúÄÂ§ö160‰∏™Â≠óÁ¨¶„ÄÇ",
        "Stable DiffusionÊèêÁ§∫ËØç": "ÂÜô‰∏Ä‰∏™ËØ¶ÁªÜÁöÑStable DiffusionÊèêÁ§∫ËØçÊù•ÈáçÁé∞ËøôÂº†ÂõæÁâá„ÄÇ",
        "MidJourneyÊèêÁ§∫ËØç": "ÂÜô‰∏Ä‰∏™MidJourneyÊèêÁ§∫ËØçÊù•ÈáçÁé∞ËøôÂº†ÂõæÁâá„ÄÇ",
        "BooruÊ†áÁ≠æ": "‰∏∫ËøôÂº†ÂõæÁâáÂÜô‰∏Ä‰∏™BooruÈ£éÊ†ºÁöÑÊ†áÁ≠æÂàóË°®ÔºåÁî®ÈÄóÂè∑ÂàÜÈöî„ÄÇ",
        "Ëâ∫ÊúØËØÑËÆ∫ÂàÜÊûê": "ÂÉèËâ∫ÊúØËØÑËÆ∫ÂÆ∂‰∏ÄÊ†∑ÂàÜÊûêËøôÂº†ÂõæÁâáÔºåËÆ®ËÆ∫ÊûÑÂõæ„ÄÅÈ£éÊ†º„ÄÅËâ≤ÂΩ©„ÄÅÂÖâÁ∫øÂíåËâ∫ÊúØÂÖÉÁ¥†„ÄÇ",
        "Á§æ‰∫§Â™í‰ΩìÊñáÊ°à": "‰∏∫ËøôÂº†ÂõæÁâáÂÜô‰∏Ä‰∏™Âê∏Âºï‰∫∫ÁöÑÁ§æ‰∫§Â™í‰ΩìÊñáÊ°à„ÄÇ",
        "Ëá™ÂÆö‰πâ": ""
    }
}

# Description lengths
DESCRIPTION_LENGTHS = {
    "en": {
        "Any": "",
        "Very Short (1-2 sentences)": "Keep it very short, 1-2 sentences maximum.",
        "Short (3-4 sentences)": "Keep it short, 3-4 sentences.",
        "Medium (1 paragraph)": "Write a medium-length description, about one paragraph.",
        "Long (2-3 paragraphs)": "Write a detailed description, 2-3 paragraphs.",
        "Very Long (comprehensive)": "Write a comprehensive and very detailed description."
    },
    "ru": {
        "–õ—é–±–∞—è": "",
        "–û—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–∞—è (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)": "–°–¥–µ–ª–∞–π –æ—á–µ–Ω—å –∫–æ—Ä–æ—Ç–∫–æ, –º–∞–∫—Å–∏–º—É–º 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.",
        "–ö–æ—Ä–æ—Ç–∫–∞—è (3-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)": "–°–¥–µ–ª–∞–π –∫–æ—Ä–æ—Ç–∫–æ, 3-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.",
        "–°—Ä–µ–¥–Ω—è—è (1 –∞–±–∑–∞—Ü)": "–ù–∞–ø–∏—à–∏ –æ–ø–∏—Å–∞–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–π –¥–ª–∏–Ω—ã, –æ–∫–æ–ª–æ –æ–¥–Ω–æ–≥–æ –∞–±–∑–∞—Ü–∞.",
        "–î–ª–∏–Ω–Ω–∞—è (2-3 –∞–±–∑–∞—Ü–∞)": "–ù–∞–ø–∏—à–∏ –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ, 2-3 –∞–±–∑–∞—Ü–∞.",
        "–û—á–µ–Ω—å –¥–ª–∏–Ω–Ω–∞—è (–ø–æ–¥—Ä–æ–±–Ω–∞—è)": "–ù–∞–ø–∏—à–∏ –∏—Å—á–µ—Ä–ø—ã–≤–∞—é—â–µ–µ –∏ –æ—á–µ–Ω—å –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ."
    },
    "zh": {
        "‰ªªÊÑè": "",
        "ÈùûÂ∏∏Áü≠Ôºà1-2Âè•Ôºâ": "‰øùÊåÅÈùûÂ∏∏ÁÆÄÁü≠ÔºåÊúÄÂ§ö1-2Âè•„ÄÇ",
        "Áü≠Ôºà3-4Âè•Ôºâ": "‰øùÊåÅÁÆÄÁü≠Ôºå3-4Âè•„ÄÇ",
        "‰∏≠Á≠âÔºà1ÊÆµÔºâ": "ÂÜô‰∏Ä‰∏™‰∏≠Á≠âÈïøÂ∫¶ÁöÑÊèèËø∞ÔºåÂ§ßÁ∫¶‰∏ÄÊÆµ„ÄÇ",
        "ÈïøÔºà2-3ÊÆµÔºâ": "ÂÜô‰∏Ä‰∏™ËØ¶ÁªÜÁöÑÊèèËø∞Ôºå2-3ÊÆµ„ÄÇ",
        "ÈùûÂ∏∏ÈïøÔºàÂÖ®Èù¢Ôºâ": "ÂÜô‰∏Ä‰∏™ÂÖ®Èù¢‰∏îÈùûÂ∏∏ËØ¶ÁªÜÁöÑÊèèËø∞„ÄÇ"
    }
}

# Multi-language support
TRANSLATIONS = {
    "en": {
        "title": "Qwen VL Image Description Generator",
        "header": "üñºÔ∏è Image Description Generator based on Qwen Vision Language Models",
        "subtitle": "Upload an image and enter a prompt to generate a description using Qwen VL models.",
        "language": "Language",
        "language_info": "Select language",
        "model_selection": "Model Selection",
        "model_info": "Select a model for generating descriptions",
        "advanced_params": "‚öôÔ∏è Advanced Parameters",
        "max_tokens": "Max New Tokens",
        "max_tokens_info": "Maximum number of tokens to generate",
        "temperature": "Temperature",
        "temperature_info": "Controls randomness of generation",
        "top_p": "Top-p (nucleus sampling)",
        "top_p_info": "Probability threshold for token sampling",
        "top_k": "Top-k",
        "top_k_info": "Number of most probable tokens to consider",
        "seed": "Seed",
        "seed_info": "Seed for reproducibility (-1 for random)",
        "random_seed_btn": "üé≤ Random Seed",
        "single_processing": "üìÑ Single Processing",
        "batch_processing": "üìö Batch Processing",
        "upload_image": "Upload Image",
        "image_url": "Or enter Image URL",
        "image_url_placeholder": "https://example.com/image.jpg",
        "prompt": "Prompt",
        "prompt_placeholder": "For example: Create a product description for online store",
        "generate_btn": "üöÄ Generate Description",
        "result": "Result",
        "upload_images": "Upload Images",
        "prompts_multiline": "Prompts (one per line)",
        "prompts_placeholder": "Create a product description for online store\nCreate SEO Description for product\n...",
        "prompts_info": "Specify one prompt for all images or one prompt per image",
        "process_batch_btn": "üöÄ Process Batch",
        "results": "Results",
        "examples_title": "üí° Example Prompts:",
        "example_1": "Create a product description for online store",
        "example_2": "Create an SEO description for a product with a maximum of 160 characters.",
        "example_3": "Create an attractive product description for marketplace",
        "example_4": "Describe image in detail for product catalog",
        "error_no_image": "Please upload an image or provide an image URL",
        "error_no_prompt": "Please enter a prompt",
        "error_no_images": "Please upload images",
        "error_no_prompts": "Please enter prompts (one per line)",
        "error_prompt_mismatch": "Number of prompts ({}) does not match number of images ({}). Specify either one prompt for all images or one prompt per image.",
        "error_generation": "Error generating description: {}",
        "error_url_load": "Error loading image from URL: {}",
        "loading_model": "Loading model: {}",
        "model_loaded": "Model {} successfully loaded on {}",
        "image_label": "=== Image {}: {} ===",
        "prompt_label": "Prompt: {}",
        "result_label": "Result: {}",
        "model_size_warning": "‚ö†Ô∏è Note: Large models (8B+) may use CPU offloading if GPU memory is insufficient, which can slow down generation.",
        "quantization": "Quantization",
        "quantization_info": "Memory optimization (4-bit = ~75% less VRAM)",
        "quant_4bit": "4-bit (Recommended)",
        "quant_8bit": "8-bit (Better quality)",
        "quant_none": "None (Full precision)",
        "description_type": "Description Type",
        "description_type_info": "Select the type/style of description",
        "description_length": "Description Length",
        "description_length_info": "Select desired length",
        "num_variants": "Number of Variants",
        "num_variants_info": "Generate multiple description variants",
        "custom_prompt_override": "Custom Prompt (overrides type selection)",
        "custom_prompt_placeholder": "Enter your custom prompt here...",
        "status": "Status",
        "processing_time": "Processing time",
        "generating": "‚è≥ Generating...",
        "stop_btn": "üõë Stop",
        "save_results": "üíæ Save Results",
        "output_folder": "Output Folder Name",
        "output_folder_placeholder": "my_dataset",
        "export_format": "Export Format",
        "export_txt": "TXT (one file per image)",
        "export_json": "JSON (all results)",
        "export_csv": "CSV (table format)",
        "variant": "Variant",
        "copy_btn": "üìã Copy",
        "download_btn": "‚¨áÔ∏è Download",
        "generation_complete": "‚úÖ Generation complete!",
        "seconds": "seconds",
        "processing_image": "Processing image",
        "of": "of",
        "extra_options": "Extra Options",
        "extra_options_info": "Additional modifiers for description",
        "character_name": "Character/Person Name",
        "character_name_placeholder": "e.g., John, Alice, or leave empty",
        "character_name_info": "If provided, will use this name instead of generic terms",
        "prompt_preset": "Prompt Preset",
        "prompt_preset_info": "Load a preset from prompts/ folder",
        "refresh_presets": "Refresh",
        "memory_usage": "Memory Usage",
        "download_result": "Download Result",
        "generation_stopped": "Generation stopped by user",
        "stopping": "Stopping..."
    },
    "ru": {
        "title": "–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ–ø–∏—Å–∞–Ω–∏–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π Qwen VL",
        "header": "üñºÔ∏è –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ–ø–∏—Å–∞–Ω–∏–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ Qwen Vision Language Models",
        "subtitle": "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ –≤–≤–µ–¥–∏—Ç–µ –ø—Ä–æ–º—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–ø–∏—Å–∞–Ω–∏—è —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–µ–π Qwen VL.",
        "language": "–Ø–∑—ã–∫",
        "language_info": "–í—ã–±–µ—Ä–∏—Ç–µ —è–∑—ã–∫",
        "model_selection": "–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏",
        "model_info": "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–ø–∏—Å–∞–Ω–∏–π",
        "advanced_params": "‚öôÔ∏è –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã",
        "max_tokens": "–ú–∞–∫—Å. –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤",
        "max_tokens_info": "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏",
        "temperature": "–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞",
        "temperature_info": "–ö–æ–Ω—Ç—Ä–æ–ª–∏—Ä—É–µ—Ç —Å–ª—É—á–∞–π–Ω–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏",
        "top_p": "Top-p (nucleus sampling)",
        "top_p_info": "–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–ª—è –≤—ã–±–æ—Ä–∫–∏ —Ç–æ–∫–µ–Ω–æ–≤",
        "top_k": "Top-k",
        "top_k_info": "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è —Ä–∞—Å—Å–º–æ—Ç—Ä–µ–Ω–∏—è",
        "seed": "Seed",
        "seed_info": "Seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏ (-1 –¥–ª—è —Å–ª—É—á–∞–π–Ω–æ–≥–æ)",
        "random_seed_btn": "üé≤ –°–ª—É—á–∞–π–Ω—ã–π seed",
        "single_processing": "üìÑ –û–¥–∏–Ω–æ—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞",
        "batch_processing": "üìö –ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞",
        "upload_image": "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
        "image_url": "–ò–ª–∏ –≤–≤–µ–¥–∏—Ç–µ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è",
        "image_url_placeholder": "https://example.com/image.jpg",
        "prompt": "–ü—Ä–æ–º—Ç",
        "prompt_placeholder": "–ù–∞–ø—Ä–∏–º–µ—Ä: –°–æ–∑–¥–∞—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ –¥–ª—è –æ–Ω–ª–∞–π–Ω –º–∞–≥–∞–∑–∏–Ω–∞",
        "generate_btn": "üöÄ –ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ",
        "result": "–†–µ–∑—É–ª—å—Ç–∞—Ç",
        "upload_images": "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è",
        "prompts_multiline": "–ü—Ä–æ–º—Ç—ã (–ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ —Å—Ç—Ä–æ–∫—É)",
        "prompts_placeholder": "–°–æ–∑–¥–∞—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ –¥–ª—è –æ–Ω–ª–∞–π–Ω –º–∞–≥–∞–∑–∏–Ω–∞\n–°–æ–∑–¥–∞—Ç—å SEO-–æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è —Ç–æ–≤–∞—Ä–∞\n...",
        "prompts_info": "–£–∫–∞–∂–∏—Ç–µ –æ–¥–∏–Ω –ø—Ä–æ–º—Ç –¥–ª—è –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏–ª–∏ –ø–æ –æ–¥–Ω–æ–º—É –ø—Ä–æ–º—Ç—É –Ω–∞ –∫–∞–∂–¥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",
        "process_batch_btn": "üöÄ –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –ø–∞–∫–µ—Ç",
        "results": "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã",
        "examples_title": "üí° –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–æ–º—Ç–æ–≤:",
        "example_1": "–°–æ–∑–¥–∞—Ç—å –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ ''  –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ",
        "example_2": "–°–æ–∑–¥–∞—Ç—å SEO-–æ–ø–∏—Å–∞–Ω–∏–µ –¥–ª—è —Ç–æ–≤–∞—Ä–∞ –º–∞–∫—Å–∏–º—É–º 160 —Å–∏–º–≤–æ–ª–æ–≤ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ",
        "example_3": "–°–æ–∑–¥–∞—Ç—å –ø—Ä–∏–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞ –¥–ª—è –º–∞—Ä–∫–µ—Ç–ø–ª–µ–π—Å–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ",
        "example_4": "–î–µ—Ç–∞–ª—å–Ω–æ –æ–ø–∏—Å–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –∫–∞—Ç–∞–ª–æ–≥–∞ —Ç–æ–≤–∞—Ä–æ–≤ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ",
        "error_no_image": "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–ª–∏ —É–∫–∞–∂–∏—Ç–µ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è",
        "error_no_prompt": "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –ø—Ä–æ–º—Ç",
        "error_no_images": "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è",
        "error_no_prompts": "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –ø—Ä–æ–º—Ç—ã (–ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ —Å—Ç—Ä–æ–∫—É)",
        "error_prompt_mismatch": "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–º—Ç–æ–≤ ({}) –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ({}). –£–∫–∞–∂–∏—Ç–µ –ª–∏–±–æ –æ–¥–∏–Ω –ø—Ä–æ–º—Ç –¥–ª—è –≤—Å–µ—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π, –ª–∏–±–æ –ø–æ –æ–¥–Ω–æ–º—É –ø—Ä–æ–º—Ç—É –Ω–∞ –∫–∞–∂–¥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.",
        "error_generation": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–ø–∏—Å–∞–Ω–∏—è: {}",
        "error_url_load": "–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ URL: {}",
        "loading_model": "–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: {}",
        "model_loaded": "–ú–æ–¥–µ–ª—å {} —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ {}",
        "image_label": "=== –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ {}: {} ===",
        "prompt_label": "–ü—Ä–æ–º—Ç: {}",
        "result_label": "–†–µ–∑—É–ª—å—Ç–∞—Ç: {}",
        "model_size_warning": "‚ö†Ô∏è –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –ë–æ–ª—å—à–∏–µ –º–æ–¥–µ–ª–∏ (8B+) –º–æ–≥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—ã–≥—Ä—É–∑–∫—É –Ω–∞ CPU –ø—Ä–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–µ –ø–∞–º—è—Ç–∏ GPU, —á—Ç–æ –º–æ–∂–µ—Ç –∑–∞–º–µ–¥–ª–∏—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏—é.",
        "quantization": "–ö–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è",
        "quantization_info": "–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏ (4-bit = ~75% –º–µ–Ω—å—à–µ –≤–∏–¥–µ–æ–ø–∞–º—è—Ç–∏)",
        "quant_4bit": "4-bit (–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)",
        "quant_8bit": "8-bit (–õ—É—á—à–µ –∫–∞—á–µ—Å—Ç–≤–æ)",
        "quant_none": "–ù–µ—Ç (–ü–æ–ª–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å)",
        "description_type": "–¢–∏–ø –æ–ø–∏—Å–∞–Ω–∏—è",
        "description_type_info": "–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø/—Å—Ç–∏–ª—å –æ–ø–∏—Å–∞–Ω–∏—è",
        "description_length": "–î–ª–∏–Ω–∞ –æ–ø–∏—Å–∞–Ω–∏—è",
        "description_length_info": "–í—ã–±–µ—Ä–∏—Ç–µ –∂–µ–ª–∞–µ–º—É—é –¥–ª–∏–Ω—É",
        "num_variants": "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤",
        "num_variants_info": "–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ –æ–ø–∏—Å–∞–Ω–∏—è",
        "custom_prompt_override": "–°–≤–æ–π –ø—Ä–æ–º–ø—Ç (–ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –≤—ã–±–æ—Ä —Ç–∏–ø–∞)",
        "custom_prompt_placeholder": "–í–≤–µ–¥–∏—Ç–µ —Å–≤–æ–π –ø—Ä–æ–º–ø—Ç –∑–¥–µ—Å—å...",
        "status": "–°—Ç–∞—Ç—É—Å",
        "processing_time": "–í—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏",
        "generating": "‚è≥ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è...",
        "stop_btn": "üõë –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å",
        "save_results": "üíæ –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã",
        "output_folder": "–ù–∞–∑–≤–∞–Ω–∏–µ –ø–∞–ø–∫–∏",
        "output_folder_placeholder": "–º–æ–π_–¥–∞—Ç–∞—Å–µ—Ç",
        "export_format": "–§–æ—Ä–º–∞—Ç —ç–∫—Å–ø–æ—Ä—Ç–∞",
        "export_txt": "TXT (–æ–¥–∏–Ω —Ñ–∞–π–ª –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ)",
        "export_json": "JSON (–≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã)",
        "export_csv": "CSV (—Ç–∞–±–ª–∏—á–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç)",
        "variant": "–í–∞—Ä–∏–∞–Ω—Ç",
        "copy_btn": "üìã –ö–æ–ø–∏—Ä–æ–≤–∞—Ç—å",
        "download_btn": "‚¨áÔ∏è –°–∫–∞—á–∞—Ç—å",
        "generation_complete": "‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!",
        "seconds": "—Å–µ–∫—É–Ω–¥",
        "processing_image": "–û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è",
        "of": "–∏–∑",
        "extra_options": "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –æ–ø—Ü–∏–∏",
        "extra_options_info": "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –º–æ–¥–∏—Ñ–∏–∫–∞—Ç–æ—Ä—ã –æ–ø–∏—Å–∞–Ω–∏—è",
        "character_name": "–ò–º—è –ø–µ—Ä—Å–æ–Ω–∞–∂–∞/—á–µ–ª–æ–≤–µ–∫–∞",
        "character_name_placeholder": "–Ω–∞–ø—Ä., –ò–≤–∞–Ω, –ê–ª–∏—Å–∞, –∏–ª–∏ –æ—Å—Ç–∞–≤—å—Ç–µ –ø—É—Å—Ç—ã–º",
        "character_name_info": "–ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω–æ, –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≤–º–µ—Å—Ç–æ –æ–±—â–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤",
        "prompt_preset": "–ü—Ä–µ—Å–µ—Ç –ø—Ä–æ–º–ø—Ç–∞",
        "prompt_preset_info": "–ó–∞–≥—Ä—É–∑–∏—Ç—å –ø—Ä–µ—Å–µ—Ç –∏–∑ –ø–∞–ø–∫–∏ prompts/",
        "refresh_presets": "–û–±–Ω–æ–≤–∏—Ç—å",
        "memory_usage": "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏",
        "download_result": "–°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç",
        "generation_stopped": "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º",
        "stopping": "–û—Å—Ç–∞–Ω–æ–≤–∫–∞..."
    },
    "zh": {
        "title": "Qwen VL ÂõæÂÉèÊèèËø∞ÁîüÊàêÂô®",
        "header": "üñºÔ∏è Âü∫‰∫é Qwen Vision Language Models ÁöÑÂõæÂÉèÊèèËø∞ÁîüÊàêÂô®",
        "subtitle": "‰∏ä‰º†ÂõæÂÉèÂπ∂ËæìÂÖ•ÊèêÁ§∫ËØçÔºå‰ΩøÁî® Qwen VL Ê®°ÂûãÁîüÊàêÊèèËø∞„ÄÇ",
        "language": "ËØ≠Ë®Ä",
        "language_info": "ÈÄâÊã©ËØ≠Ë®Ä",
        "model_selection": "Ê®°ÂûãÈÄâÊã©",
        "model_info": "ÈÄâÊã©Áî®‰∫éÁîüÊàêÊèèËø∞ÁöÑÊ®°Âûã",
        "advanced_params": "‚öôÔ∏è È´òÁ∫ßÂèÇÊï∞",
        "max_tokens": "ÊúÄÂ§ßÊñ∞‰ª§ÁâåÊï∞",
        "max_tokens_info": "ÁîüÊàêÁöÑÊúÄÂ§ß‰ª§ÁâåÊï∞",
        "temperature": "Ê∏©Â∫¶",
        "temperature_info": "ÊéßÂà∂ÁîüÊàêÁöÑÈöèÊú∫ÊÄß",
        "top_p": "Top-pÔºàÊ†∏ÈááÊ†∑Ôºâ",
        "top_p_info": "‰ª§ÁâåÈááÊ†∑ÁöÑÊ¶ÇÁéáÈòàÂÄº",
        "top_k": "Top-k",
        "top_k_info": "ËÄÉËôëÁöÑÊúÄÂèØËÉΩ‰ª§ÁâåÊï∞",
        "seed": "ÈöèÊú∫ÁßçÂ≠ê",
        "seed_info": "Áî®‰∫éÂèØÈáçÁé∞ÊÄßÁöÑÁßçÂ≠êÔºà-1 Ë°®Á§∫ÈöèÊú∫Ôºâ",
        "random_seed_btn": "üé≤ ÈöèÊú∫ÁßçÂ≠ê",
        "single_processing": "üìÑ ÂçïÂº†Â§ÑÁêÜ",
        "batch_processing": "üìö ÊâπÈáèÂ§ÑÁêÜ",
        "upload_image": "‰∏ä‰º†ÂõæÂÉè",
        "image_url": "ÊàñËæìÂÖ•ÂõæÂÉèURL",
        "image_url_placeholder": "https://example.com/image.jpg",
        "prompt": "ÊèêÁ§∫ËØç",
        "prompt_placeholder": "‰æãÂ¶ÇÔºö‰∏∫Âú®Á∫øÂïÜÂ∫óÂàõÂª∫‰∫ßÂìÅÊèèËø∞",
        "generate_btn": "üöÄ ÁîüÊàêÊèèËø∞",
        "result": "ÁªìÊûú",
        "upload_images": "‰∏ä‰º†ÂõæÂÉè",
        "prompts_multiline": "ÊèêÁ§∫ËØçÔºàÊØèË°å‰∏Ä‰∏™Ôºâ",
        "prompts_placeholder": "‰∏∫Âú®Á∫øÂïÜÂ∫óÂàõÂª∫‰∫ßÂìÅÊèèËø∞\n‰∏∫‰∫ßÂìÅÂàõÂª∫SEOÊèèËø∞\n...",
        "prompts_info": "‰∏∫ÊâÄÊúâÂõæÂÉèÊåáÂÆö‰∏Ä‰∏™ÊèêÁ§∫ËØçÔºåÊàñ‰∏∫ÊØè‰∏™ÂõæÂÉèÊåáÂÆö‰∏Ä‰∏™ÊèêÁ§∫ËØç",
        "process_batch_btn": "üöÄ Â§ÑÁêÜÊâπÊ¨°",
        "results": "ÁªìÊûú",
        "examples_title": "üí° Á§∫‰æãÊèêÁ§∫ËØçÔºö",
        "example_1": "‰∏∫Âú®Á∫øÂïÜÂ∫óÂàõÂª∫‰∫ßÂìÅÊèèËø∞",
        "example_2": "‰∏∫‰∫ßÂìÅÂàõÂª∫SEOÊèèËø∞ÊúÄÂ§ö 160 ‰∏™Â≠óÁ¨¶",
        "example_3": "‰∏∫Â∏ÇÂú∫ÂàõÂª∫ÊúâÂê∏ÂºïÂäõÁöÑ‰∫ßÂìÅÊèèËø∞",
        "example_4": "ËØ¶ÁªÜÊèèËø∞‰∫ßÂìÅÁõÆÂΩïÁöÑÂõæÂÉè",
        "error_no_image": "ËØ∑‰∏ä‰º†ÂõæÂÉèÊàñÊèê‰æõÂõæÂÉèURL",
        "error_no_prompt": "ËØ∑ËæìÂÖ•ÊèêÁ§∫ËØç",
        "error_no_images": "ËØ∑‰∏ä‰º†ÂõæÂÉè",
        "error_no_prompts": "ËØ∑ËæìÂÖ•ÊèêÁ§∫ËØçÔºàÊØèË°å‰∏Ä‰∏™Ôºâ",
        "error_prompt_mismatch": "ÊèêÁ§∫ËØçÊï∞ÈáèÔºà{}Ôºâ‰∏éÂõæÂÉèÊï∞ÈáèÔºà{}Ôºâ‰∏çÂåπÈÖç„ÄÇËØ∑‰∏∫ÊâÄÊúâÂõæÂÉèÊåáÂÆö‰∏Ä‰∏™ÊèêÁ§∫ËØçÔºåÊàñ‰∏∫ÊØè‰∏™ÂõæÂÉèÊåáÂÆö‰∏Ä‰∏™ÊèêÁ§∫ËØç„ÄÇ",
        "error_generation": "ÁîüÊàêÊèèËø∞Êó∂Âá∫ÈîôÔºö{}",
        "error_url_load": "‰ªéURLÂä†ËΩΩÂõæÂÉèÊó∂Âá∫ÈîôÔºö{}",
        "loading_model": "Ê≠£Âú®Âä†ËΩΩÊ®°ÂûãÔºö{}",
        "model_loaded": "Ê®°Âûã {} Â∑≤ÊàêÂäüÂä†ËΩΩÂà∞ {}",
        "image_label": "=== ÂõæÂÉè {}: {} ===",
        "prompt_label": "ÊèêÁ§∫ËØçÔºö{}",
        "result_label": "ÁªìÊûúÔºö{}",
        "model_size_warning": "‚ö†Ô∏è Ê≥®ÊÑèÔºöÂ¶ÇÊûú GPU ÂÜÖÂ≠ò‰∏çË∂≥ÔºåÂ§ßÂûãÊ®°ÂûãÔºà8B+ÔºâÂèØËÉΩ‰ºö‰ΩøÁî® CPU Âç∏ËΩΩÔºåËøôÂèØËÉΩ‰ºöÂáèÊÖ¢ÁîüÊàêÈÄüÂ∫¶„ÄÇ",
        "quantization": "ÈáèÂåñ",
        "quantization_info": "ÂÜÖÂ≠ò‰ºòÂåñÔºà4‰Ωç = ÂáèÂ∞ëÁ∫¶75%ÊòæÂ≠òÔºâ",
        "quant_4bit": "4‰ΩçÔºàÊé®ËçêÔºâ",
        "quant_8bit": "8‰ΩçÔºàÊõ¥È´òË¥®ÈáèÔºâ",
        "quant_none": "Êó†ÔºàÂÖ®Á≤æÂ∫¶Ôºâ",
        "description_type": "ÊèèËø∞Á±ªÂûã",
        "description_type_info": "ÈÄâÊã©ÊèèËø∞Á±ªÂûã/È£éÊ†º",
        "description_length": "ÊèèËø∞ÈïøÂ∫¶",
        "description_length_info": "ÈÄâÊã©ÊâÄÈúÄÈïøÂ∫¶",
        "num_variants": "Âèò‰ΩìÊï∞Èáè",
        "num_variants_info": "ÁîüÊàêÂ§ö‰∏™ÊèèËø∞Âèò‰Ωì",
        "custom_prompt_override": "Ëá™ÂÆö‰πâÊèêÁ§∫ËØçÔºàË¶ÜÁõñÁ±ªÂûãÈÄâÊã©Ôºâ",
        "custom_prompt_placeholder": "Âú®Ê≠§ËæìÂÖ•ÊÇ®ÁöÑËá™ÂÆö‰πâÊèêÁ§∫ËØç...",
        "status": "Áä∂ÊÄÅ",
        "processing_time": "Â§ÑÁêÜÊó∂Èó¥",
        "generating": "‚è≥ ÁîüÊàê‰∏≠...",
        "stop_btn": "üõë ÂÅúÊ≠¢",
        "save_results": "üíæ ‰øùÂ≠òÁªìÊûú",
        "output_folder": "ËæìÂá∫Êñá‰ª∂Â§πÂêçÁß∞",
        "output_folder_placeholder": "ÊàëÁöÑÊï∞ÊçÆÈõÜ",
        "export_format": "ÂØºÂá∫Ê†ºÂºè",
        "export_txt": "TXTÔºàÊØèÂº†ÂõæÁâá‰∏Ä‰∏™Êñá‰ª∂Ôºâ",
        "export_json": "JSONÔºàÊâÄÊúâÁªìÊûúÔºâ",
        "export_csv": "CSVÔºàË°®Ê†ºÊ†ºÂºèÔºâ",
        "variant": "Âèò‰Ωì",
        "copy_btn": "üìã Â§çÂà∂",
        "download_btn": "‚¨áÔ∏è ‰∏ãËΩΩ",
        "generation_complete": "‚úÖ ÁîüÊàêÂÆåÊàêÔºÅ",
        "seconds": "Áßí",
        "processing_image": "Â§ÑÁêÜÂõæÂÉè",
        "of": "/",
        "extra_options": "È¢ùÂ§ñÈÄâÈ°π",
        "extra_options_info": "ÊèèËø∞ÁöÑÈ¢ùÂ§ñ‰øÆÈ•∞Á¨¶",
        "character_name": "ËßíËâ≤/‰∫∫Áâ©ÂêçÁß∞",
        "character_name_placeholder": "‰æãÂ¶ÇÔºöÂ∞èÊòé„ÄÅÂ∞èÁ∫¢ÔºåÊàñÁïôÁ©∫",
        "character_name_info": "Â¶ÇÊûúÊèê‰æõÔºåÂ∞Ü‰ΩøÁî®Ê≠§ÂêçÁß∞‰ª£ÊõøÈÄöÁî®ÊúØËØ≠",
        "prompt_preset": "ÊèêÁ§∫ËØçÈ¢ÑËÆæ",
        "prompt_preset_info": "‰ªéprompts/Êñá‰ª∂Â§πÂä†ËΩΩÈ¢ÑËÆæ",
        "refresh_presets": "Âà∑Êñ∞",
        "memory_usage": "ÂÜÖÂ≠ò‰ΩøÁî®",
        "download_result": "‰∏ãËΩΩÁªìÊûú",
        "generation_stopped": "Áî®Êà∑ÂÅúÊ≠¢‰∫ÜÁîüÊàê",
        "stopping": "ÂÅúÊ≠¢‰∏≠..."
    }
}

# Default language
current_language = "en"

def get_text(key: str) -> str:
    """Get translated text for the current language"""
    return TRANSLATIONS[current_language].get(key, key)

def get_description_types() -> list:
    """Get description types for current language"""
    return list(DESCRIPTION_TYPES.get(current_language, DESCRIPTION_TYPES["en"]).keys())

def get_description_lengths() -> list:
    """Get description lengths for current language"""
    return list(DESCRIPTION_LENGTHS.get(current_language, DESCRIPTION_LENGTHS["en"]).keys())

def get_extra_options() -> list:
    """Get extra options for current language"""
    return list(EXTRA_OPTIONS.get(current_language, EXTRA_OPTIONS["en"]).keys())

def get_extra_option_prompt(option: str) -> str:
    """Get the prompt text for an extra option"""
    options_dict = EXTRA_OPTIONS.get(current_language, EXTRA_OPTIONS["en"])
    return options_dict.get(option, "")

def build_prompt(
    description_type: str,
    description_length: str,
    custom_prompt: str,
    base_prompt: str = "",
    extra_options: list = None,
    character_name: str = ""
) -> str:
    """Build the final prompt based on type, length, custom input, extra options and character name"""
    # If custom prompt is provided, use it (but still add character name if present)
    if custom_prompt and custom_prompt.strip():
        final_prompt = custom_prompt.strip()
    else:
        # Get type prompt
        types_dict = DESCRIPTION_TYPES.get(current_language, DESCRIPTION_TYPES["en"])
        type_prompt = types_dict.get(description_type, "")

        # If type is Custom, use base prompt
        if not type_prompt:
            type_prompt = base_prompt if base_prompt else "Describe this image."

        # Get length modifier
        lengths_dict = DESCRIPTION_LENGTHS.get(current_language, DESCRIPTION_LENGTHS["en"])
        length_modifier = lengths_dict.get(description_length, "")

        # Combine type and length
        if length_modifier:
            final_prompt = f"{type_prompt} {length_modifier}"
        else:
            final_prompt = type_prompt

    # Add character name instruction if provided
    if character_name and character_name.strip():
        name = character_name.strip()
        if current_language == "ru":
            final_prompt += f" –ï—Å–ª–∏ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –µ—Å—Ç—å —á–µ–ª–æ–≤–µ–∫ –∏–ª–∏ –ø–µ—Ä—Å–æ–Ω–∞–∂, –∏—Å–ø–æ–ª—å–∑—É–π –∏–º—è '{name}' –≤–º–µ—Å—Ç–æ –æ–±—â–∏—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤."
        elif current_language == "zh":
            final_prompt += f" Â¶ÇÊûúÂõæÁâá‰∏≠Êúâ‰∫∫ÊàñËßíËâ≤ÔºåËØ∑‰ΩøÁî®ÂêçÂ≠ó'{name}'ËÄå‰∏çÊòØÈÄöÁî®ÊúØËØ≠„ÄÇ"
        else:
            final_prompt += f" If there is a person or character in the image, use the name '{name}' instead of generic terms."

    # Add extra options
    if extra_options:
        for option in extra_options:
            option_prompt = get_extra_option_prompt(option)
            if option_prompt:
                final_prompt += f" {option_prompt}"

    return final_prompt

def create_output_folder(folder_name: str = None) -> str:
    """Create and return path to output folder"""
    if folder_name and folder_name.strip():
        # Sanitize folder name
        safe_name = "".join(c for c in folder_name if c.isalnum() or c in "_ -").strip()
        if not safe_name:
            safe_name = f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    else:
        safe_name = f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

    folder_path = os.path.join(DATASETS_DIR, safe_name)
    os.makedirs(folder_path, exist_ok=True)
    return folder_path

def save_results_txt(results: List[dict], output_folder: str) -> List[str]:
    """Save results as individual TXT files"""
    saved_files = []
    for result in results:
        filename = os.path.splitext(os.path.basename(result.get("image_path", "image")))[0]
        txt_path = os.path.join(output_folder, f"{filename}.txt")
        with open(txt_path, "w", encoding="utf-8") as f:
            if isinstance(result.get("descriptions"), list):
                for i, desc in enumerate(result["descriptions"], 1):
                    f.write(f"=== Variant {i} ===\n{desc}\n\n")
            else:
                f.write(result.get("description", ""))
        saved_files.append(txt_path)

        # Copy image if exists
        if result.get("image_path") and os.path.exists(result["image_path"]):
            img_dest = os.path.join(output_folder, os.path.basename(result["image_path"]))
            if not os.path.exists(img_dest):
                shutil.copy2(result["image_path"], img_dest)

    return saved_files

def save_results_json(results: List[dict], output_folder: str) -> str:
    """Save all results as a single JSON file"""
    json_path = os.path.join(output_folder, "results.json")
    export_data = []
    for result in results:
        export_data.append({
            "image": os.path.basename(result.get("image_path", "")),
            "prompt": result.get("prompt", ""),
            "descriptions": result.get("descriptions", [result.get("description", "")]),
            "timestamp": datetime.now().isoformat()
        })

    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(export_data, f, ensure_ascii=False, indent=2)

    return json_path

def save_results_csv(results: List[dict], output_folder: str) -> str:
    """Save all results as a CSV file"""
    csv_path = os.path.join(output_folder, "results.csv")

    with open(csv_path, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(["Image", "Prompt", "Description", "Variant"])

        for result in results:
            image_name = os.path.basename(result.get("image_path", ""))
            prompt = result.get("prompt", "")
            descriptions = result.get("descriptions", [result.get("description", "")])

            for i, desc in enumerate(descriptions, 1):
                writer.writerow([image_name, prompt, desc, i])

    return csv_path

class ImageDescriptionGenerator:
    def __init__(self):
        self.model = None
        self.processor = None
        self.current_model_name = None
        self.current_quantization = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"

    def load_model(self, model_name: str, quantization: str = "4-bit"):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–µ–π BitsAndBytes"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω—É–∂–Ω–∞ –ª–∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞
        if (self.current_model_name == model_name and
            self.current_quantization == quantization and
            self.model is not None):
            return

        print(get_text("loading_model").format(model_name))
        print(f"Quantization: {quantization}")

        # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª—è—Ö
        if "8B" in model_name or "32B" in model_name or "30B" in model_name:
            print(get_text("model_size_warning"))

        # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –ø–∞–º—è—Ç—å –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–µ–π –º–æ–¥–µ–ª–∏
        if self.model is not None:
            del self.model
            del self.processor
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.synchronize()

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏–∏ BitsAndBytes
        bnb_config = None
        dtype = torch.bfloat16 if torch.cuda.is_available() else torch.float32

        if quantization == "4-bit" and torch.cuda.is_available():
            bnb_config = BitsAndBytesConfig(
                load_in_4bit=True,
                bnb_4bit_compute_dtype=torch.bfloat16,
                bnb_4bit_quant_type="nf4",
                bnb_4bit_use_double_quant=True,
            )
            print("Using 4-bit quantization (NF4 + double quant) - ~75% VRAM reduction")
        elif quantization == "8-bit" and torch.cuda.is_available():
            bnb_config = BitsAndBytesConfig(
                load_in_8bit=True,
            )
            print("Using 8-bit quantization - ~50% VRAM reduction")
        else:
            print("Using full precision (bfloat16/float32)")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–æ–≤—É—é –º–æ–¥–µ–ª—å —Å –ø–æ–¥–∞–≤–ª–µ–Ω–∏–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
        with warnings.catch_warnings():
            warnings.filterwarnings('ignore')
            load_kwargs = {
                "device_map": "auto",
                "trust_remote_code": True,
            }

            if bnb_config is not None:
                load_kwargs["quantization_config"] = bnb_config
            else:
                load_kwargs["torch_dtype"] = dtype

            # SDPA (Scaled Dot Product Attention) - –≤—Å—Ç—Ä–æ–µ–Ω –≤ PyTorch 2.0+
            # –ë—ã—Å—Ç—Ä—ã–π –∏ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ Windows –±–µ–∑ –¥–æ–ø. –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
            if torch.cuda.is_available():
                load_kwargs["attn_implementation"] = "sdpa"
                print("Using SDPA attention (PyTorch native, fast)")

            self.model = Qwen3VLForConditionalGeneration.from_pretrained(
                model_name,
                **load_kwargs
            )
            self.processor = AutoProcessor.from_pretrained(model_name, trust_remote_code=True)

        self.current_model_name = model_name
        self.current_quantization = quantization
        print(get_text("model_loaded").format(model_name, self.device))
    
    def generate_description(
        self,
        image_path: str,
        prompt: str,
        model_name: str,
        quantization: str = "4-bit",
        max_new_tokens: int = 1024,
        temperature: float = 0.6,
        top_p: float = 0.9,
        top_k: int = 50,
        seed: int = -1
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ
            self.load_model(model_name, quantization)
            
            # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º seed –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω
            if seed != -1:
                torch.manual_seed(seed)
                if torch.cuda.is_available():
                    torch.cuda.manual_seed(seed)
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏
            messages = [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image",
                            "image": image_path,
                        },
                        {"type": "text", "text": prompt},
                    ],
                }
            ]
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –º–æ–¥–µ–ª–∏
            text = self.processor.apply_chat_template(
                messages, tokenize=False, add_generation_prompt=True
            )
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏ —Ç–µ–∫—Å—Ç
            image_inputs, video_inputs = process_vision_info(messages)
            inputs = self.processor(
                text=[text],
                images=image_inputs,
                videos=video_inputs,
                padding=True,
                return_tensors="pt",
            )
            inputs = inputs.to(self.device)
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç (inference_mode –±—ã—Å—Ç—Ä–µ–µ —á–µ–º no_grad)
            with torch.inference_mode():
                generated_ids = self.model.generate(
                    **inputs,
                    max_new_tokens=max_new_tokens,
                    temperature=temperature,
                    top_p=top_p,
                    top_k=top_k,
                    do_sample=True if temperature > 0 else False,
                    use_cache=True,  # KV –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
                )
            
            # –î–µ–∫–æ–¥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            generated_ids_trimmed = [
                out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
            ]
            output_text = self.processor.batch_decode(
                generated_ids_trimmed,
                skip_special_tokens=True,
                clean_up_tokenization_spaces=False
            )
            
            return output_text[0]
            
        except Exception as e:
            return get_text("error_generation").format(str(e))

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞
generator = ImageDescriptionGenerator()

def load_image_from_url(url: str) -> Optional[str]:
    """Load image from URL and save to temporary file"""
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        
        # Load image from response content
        image = Image.open(BytesIO(response.content))
        
        # Save to temporary file
        temp_path = os.path.join(TEMP_DIR, "temp_url_image.jpg")
        image.save(temp_path)
        
        return temp_path
    except Exception as e:
        raise Exception(get_text("error_url_load").format(str(e)))

def process_single_image(
    image,
    video,
    image_url: str,
    description_type: str,
    description_length: str,
    custom_prompt: str,
    extra_options: list,
    character_name: str,
    num_variants: int,
    model_name: str,
    quantization: str,
    max_new_tokens: int,
    temperature: float,
    top_p: float,
    top_k: int,
    seed: int,
    progress=gr.Progress(track_tqdm=True)
) -> Generator:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è/–≤–∏–¥–µ–æ —Å –≥–µ–Ω–µ—Ä–∞—Ü–∏–µ–π –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤"""
    global stop_generation_flag
    reset_stop_flag()
    start_time = time.time()

    # Check if we have either uploaded image/video or URL
    if image is None and video is None and not image_url.strip():
        yield get_text("error_no_image"), "", [], None
        return

    # Build prompt from type, length, custom, extra options and character name
    final_prompt = build_prompt(
        description_type, description_length, custom_prompt,
        extra_options=extra_options or [],
        character_name=character_name or ""
    )
    if not final_prompt.strip():
        yield get_text("error_no_prompt"), "", [], None
        return

    temp_path = None
    num_variants = int(num_variants) if num_variants and str(num_variants).strip() else 1

    try:
        # Priority: URL > video > image
        if image_url and image_url.strip():
            yield f"‚è≥ {get_text('generating')} (loading from URL...)", final_prompt, [], None
            image_path = load_image_from_url(image_url.strip())
            temp_path = image_path
        elif video is not None:
            # Video uploaded - use it directly
            image_path = video
        elif hasattr(image, 'shape'):
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –µ—Å–ª–∏ —ç—Ç–æ numpy array
            temp_path = os.path.join(TEMP_DIR, "temp_image.jpg")
            Image.fromarray(image).save(temp_path)
            image_path = temp_path
        else:
            image_path = image

        results = []
        for i in range(num_variants):
            # Check stop flag
            if stop_generation_flag:
                elapsed_time = time.time() - start_time
                yield f"üõë {get_text('generation_stopped')} ({get_text('processing_time')}: {elapsed_time:.1f} {get_text('seconds')})", final_prompt, results, None
                return

            variant_seed = seed if seed == -1 else seed + i
            memory_info = get_memory_info()
            status_msg = f"‚è≥ {get_text('generating')} ({get_text('variant')} {i+1}/{num_variants}) | {memory_info}"
            yield status_msg, final_prompt, results, None

            result = generator.generate_description(
                image_path=image_path,
                prompt=final_prompt,
                model_name=model_name,
                quantization=quantization,
                max_new_tokens=max_new_tokens,
                temperature=temperature,
                top_p=top_p,
                top_k=top_k,
                seed=variant_seed
            )
            results.append(result)

        # Calculate processing time
        elapsed_time = time.time() - start_time
        memory_info = get_memory_info()
        final_status = f"{get_text('generation_complete')} ({get_text('processing_time')}: {elapsed_time:.1f} {get_text('seconds')}) | {memory_info}"

        # Prepare download file
        download_path = None
        if results:
            all_text = "\n\n".join([f"=== Variant {i+1} ===\n{r}" for i, r in enumerate(results)])
            download_path = save_text_to_file(all_text, f"result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt")

        yield final_status, final_prompt, results, download_path

    except Exception as e:
        yield f"‚ùå Error: {str(e)}", final_prompt, [], None
    finally:
        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        if temp_path and os.path.exists(temp_path):
            try:
                os.remove(temp_path)
            except:
                pass

        # Clean up GPU memory
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()

def process_batch_images(
    files: List,
    description_type: str,
    description_length: str,
    custom_prompt: str,
    extra_options: list,
    character_name: str,
    num_variants: int,
    output_folder_name: str,
    export_formats: List[str],
    model_name: str,
    quantization: str,
    max_new_tokens: int,
    temperature: float,
    top_p: float,
    top_k: int,
    seed: int,
    progress=gr.Progress(track_tqdm=True)
) -> Generator:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–∫–µ—Ç–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π —Å –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–æ–º –∏ —ç–∫—Å–ø–æ—Ä—Ç–æ–º"""
    global stop_generation_flag
    reset_stop_flag()
    start_time = time.time()

    if not files:
        yield get_text("error_no_images"), "", None
        return

    # Build prompt from type, length, custom, extra options and character name
    final_prompt = build_prompt(
        description_type, description_length, custom_prompt,
        extra_options=extra_options or [],
        character_name=character_name or ""
    )
    if not final_prompt.strip():
        yield get_text("error_no_prompts"), "", None
        return

    num_variants = int(num_variants)
    total_files = len(files)
    all_results = []
    output_lines = []

    # Create output folder
    output_folder = create_output_folder(output_folder_name)

    for idx, file in enumerate(progress.tqdm(files, desc="Processing images")):
        # Check stop flag
        if stop_generation_flag:
            elapsed_time = time.time() - start_time
            final_status = f"üõë {get_text('generation_stopped')}\n"
            final_status += f"üìä {idx} {get_text('of')} {total_files} images processed in {elapsed_time:.1f} {get_text('seconds')}"
            yield final_status, "\n".join(output_lines), None
            return

        image_path = file.name if hasattr(file, 'name') else file
        filename = os.path.basename(image_path)

        # Status update with memory info
        memory_info = get_memory_info()
        status_msg = f"‚è≥ {get_text('processing_image')} {idx + 1} {get_text('of')} {total_files}: {filename} | {memory_info}"
        yield status_msg, "\n".join(output_lines), None

        descriptions = []
        for v in range(num_variants):
            # Check stop flag between variants
            if stop_generation_flag:
                break

            variant_seed = seed if seed == -1 else seed + idx * num_variants + v

            result = generator.generate_description(
                image_path=image_path,
                prompt=final_prompt,
                model_name=model_name,
                quantization=quantization,
                max_new_tokens=max_new_tokens,
                temperature=temperature,
                top_p=top_p,
                top_k=top_k,
                seed=variant_seed
            )
            descriptions.append(result)

        if not descriptions:
            continue

        # Store result
        all_results.append({
            "image_path": image_path,
            "prompt": final_prompt,
            "descriptions": descriptions,
            "description": descriptions[0] if descriptions else ""
        })

        # Add to output
        output_lines.append(f"{'='*50}")
        output_lines.append(get_text("image_label").format(idx + 1, filename))
        output_lines.append(get_text("prompt_label").format(final_prompt))

        for v_idx, desc in enumerate(descriptions, 1):
            if num_variants > 1:
                output_lines.append(f"\n--- {get_text('variant')} {v_idx} ---")
            output_lines.append(f"{desc}\n")

        yield status_msg, "\n".join(output_lines), None

    # Save results in selected formats
    saved_paths = []
    if export_formats and all_results:
        if "TXT" in export_formats:
            txt_files = save_results_txt(all_results, output_folder)
            saved_paths.extend(txt_files)

        if "JSON" in export_formats:
            json_path = save_results_json(all_results, output_folder)
            saved_paths.append(json_path)

        if "CSV" in export_formats:
            csv_path = save_results_csv(all_results, output_folder)
            saved_paths.append(csv_path)

    # Calculate total time
    elapsed_time = time.time() - start_time
    memory_info = get_memory_info()

    # Final status
    final_status = f"{get_text('generation_complete')}\n"
    final_status += f"üìä {total_files} images processed in {elapsed_time:.1f} {get_text('seconds')} | {memory_info}\n"
    if saved_paths:
        final_status += f"üíæ Results saved to: {output_folder}"

    # Prepare download file for batch results
    download_path = None
    if all_results:
        download_path = save_text_to_file("\n".join(output_lines), f"batch_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt")

    yield final_status, "\n".join(output_lines), download_path

    # Clean up GPU memory
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

def random_seed() -> int:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–ª—É—á–∞–π–Ω–æ–≥–æ seed"""
    return random.randint(0, 2**32 - 1)

def update_examples():
    return [
        [get_text("example_1")],
        [get_text("example_2")],
        [get_text("example_3")],
        [get_text("example_4")]
    ]

def create_interface():
    """Create Gradio interface with current language and beautiful styling"""
    with gr.Blocks(
        title=get_text("title"),
        theme=gr.themes.Soft(primary_hue="indigo", secondary_hue="purple", neutral_hue="slate"),
        css=CUSTOM_CSS
    ) as demo:
        # Beautiful gradient header with credits
        gr.HTML("""
        <div class="main-header">
            <h1>üñºÔ∏è Qwen VL Image Description Generator PRO</h1>
            <p>Advanced AI-powered image description with multiple styles and export options</p>
            <p style="font-size: 0.9rem; margin-top: 0.75rem; opacity: 0.85;">
                Developed by <a href="#">NeuralSoft</a> |
                Powered by <a href="https://huggingface.co/Qwen" target="_blank">Qwen Vision Models</a> |
                <a href="https://github.com/timoncool/qwen3-vl" target="_blank">GitHub</a>
            </p>
        </div>
        """)

        # Header that will be updated for language
        header_md = gr.Markdown(f"""
        {get_text("subtitle")}
        """)
        
        # –û–±—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ - –º–æ–¥–µ–ª—å, –∫–≤–∞–Ω—Ç–∏–∑–∞—Ü–∏—è –∏ —è–∑—ã–∫
        with gr.Row():
            model_dropdown = gr.Dropdown(
                choices=[
                    # Abliterated models (–±–µ–∑ —Ü–µ–Ω–∑—É—Ä—ã) - —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ
                    ("2B Instruct Abliterated (~1.2GB 4-bit)", "huihui-ai/Huihui-Qwen3-VL-2B-Instruct-abliterated"),
                    ("2B Thinking Abliterated (~1.2GB 4-bit)", "huihui-ai/Huihui-Qwen3-VL-2B-Thinking-abliterated"),
                    ("4B Instruct Abliterated (~2.5GB 4-bit)", "huihui-ai/Huihui-Qwen3-VL-4B-Instruct-abliterated"),
                    ("4B Thinking Abliterated (~2.5GB 4-bit)", "huihui-ai/Huihui-Qwen3-VL-4B-Thinking-abliterated"),
                    ("8B Instruct Abliterated (~5GB 4-bit)", "huihui-ai/Huihui-Qwen3-VL-8B-Instruct-abliterated"),
                    ("8B Thinking Abliterated (~5GB 4-bit)", "huihui-ai/Huihui-Qwen3-VL-8B-Thinking-abliterated"),
                    ("30B-A3B MoE Instruct Abliterated (~18GB 4-bit)", "huihui-ai/Huihui-Qwen3-VL-30B-A3B-Instruct-abliterated"),
                    ("30B-A3B MoE Thinking Abliterated (~18GB 4-bit)", "huihui-ai/Huihui-Qwen3-VL-30B-A3B-Thinking-abliterated"),
                    ("32B Instruct Abliterated (~18GB 4-bit)", "huihui-ai/Huihui-Qwen3-VL-32B-Instruct-abliterated"),
                    ("32B Thinking Abliterated (~18GB 4-bit)", "huihui-ai/Huihui-Qwen3-VL-32B-Thinking-abliterated"),
                    # Original Qwen models
                    ("Qwen 2B Instruct (~1.2GB 4-bit)", "Qwen/Qwen3-VL-2B-Instruct"),
                    ("Qwen 4B Instruct (~2.5GB 4-bit)", "Qwen/Qwen3-VL-4B-Instruct"),
                    ("Qwen 8B Instruct (~5GB 4-bit)", "Qwen/Qwen3-VL-8B-Instruct"),
                ],
                value="huihui-ai/Huihui-Qwen3-VL-2B-Instruct-abliterated",
                label=get_text("model_selection"),
                info=get_text("model_info"),
                scale=3
            )
            quantization_dropdown = gr.Dropdown(
                choices=[
                    ("4-bit (Recommended)", "4-bit"),
                    ("8-bit (Better quality)", "8-bit"),
                    ("None (Full precision)", "none"),
                ],
                value="4-bit",
                label=get_text("quantization"),
                info=get_text("quantization_info"),
                scale=1
            )
            language_dropdown = gr.Dropdown(
                choices=[("English", "en"), ("–†—É—Å—Å–∫–∏–π", "ru"), ("‰∏≠Êñá", "zh")],
                value=current_language,
                label=get_text("language"),
                info=get_text("language_info"),
                scale=1
            )
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã
        advanced_accordion = gr.Accordion(get_text("advanced_params"), open=False)
        with advanced_accordion:
            with gr.Row():
                max_tokens_slider = gr.Slider(
                    minimum=1,
                    maximum=4096,
                    value=1024,
                    step=1,
                    label=get_text("max_tokens"),
                    info=get_text("max_tokens_info")
                )
                temperature_slider = gr.Slider(
                    minimum=0.1,
                    maximum=2.0,
                    value=0.6,
                    step=0.1,
                    label=get_text("temperature"),
                    info=get_text("temperature_info")
                )
            
            with gr.Row():
                top_p_slider = gr.Slider(
                    minimum=0.05,
                    maximum=1.0,
                    value=0.9,
                    step=0.05,
                    label=get_text("top_p"),
                    info=get_text("top_p_info")
                )
                top_k_slider = gr.Slider(
                    minimum=1,
                    maximum=1000,
                    value=50,
                    step=1,
                    label=get_text("top_k"),
                    info=get_text("top_k_info")
                )
            
            with gr.Row():
                seed_number = gr.Number(
                    value=-1,
                    label=get_text("seed"),
                    info=get_text("seed_info"),
                    precision=0
                )
                random_seed_btn = gr.Button(get_text("random_seed_btn"), size="sm")
        
        # –í–∫–ª–∞–¥–∫–∏ –¥–ª—è –æ–¥–∏–Ω–æ—á–Ω–æ–π –∏ –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
        tabs = gr.Tabs()
        with tabs:
            # –í–∫–ª–∞–¥–∫–∞ –æ–¥–∏–Ω–æ—á–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
            single_tab = gr.TabItem(get_text("single_processing"))
            with single_tab:
                with gr.Row():
                    with gr.Column(scale=1, elem_classes="card-style"):
                        gr.Markdown("### üì∑ Input")
                        
                        # Tabs for Image and Video
                        with gr.Tabs():
                            with gr.TabItem("üñºÔ∏è Image"):
                                single_image = gr.Image(
                                    type="numpy",
                                    label=get_text("upload_image"),
                                    height=300
                                )
                                single_image_url = gr.Textbox(
                                    label=get_text("image_url"),
                                    placeholder=get_text("image_url_placeholder"),
                                    lines=1
                                )
                            with gr.TabItem("üé• Video"):
                                single_video = gr.Video(
                                    label="Upload Video",
                                    height=300
                                )

                        gr.Markdown("### üìù Description Settings")

                        # Prompt preset dropdown with save option
                        with gr.Row():
                            single_preset = gr.Dropdown(
                                choices=list(load_prompt_presets().keys()),
                                value="None",
                                label=get_text("prompt_preset"),
                                info=get_text("prompt_preset_info"),
                                scale=3
                            )
                            single_refresh_presets = gr.Button(
                                get_text("refresh_presets"),
                                size="sm",
                                scale=1
                            )
                        
                        # Save preset accordion
                        with gr.Accordion("üíæ Save Preset", open=False):
                            with gr.Row():
                                single_save_preset_name = gr.Textbox(
                                    label="Preset Name",
                                    placeholder="my_preset",
                                    scale=2
                                )
                                single_save_preset_btn = gr.Button(
                                    "Save",
                                    size="sm",
                                    scale=1
                                )
                            single_save_preset_status = gr.Markdown("")

                        single_desc_type = gr.Dropdown(
                            choices=get_description_types(),
                            value=get_description_types()[0],
                            label=get_text("description_type"),
                            info=get_text("description_type_info")
                        )
                        single_desc_length = gr.Dropdown(
                            choices=get_description_lengths(),
                            value=get_description_lengths()[0],
                            label=get_text("description_length"),
                            info=get_text("description_length_info")
                        )
                        single_num_variants = gr.Slider(
                            minimum=1,
                            maximum=5,
                            value=1,
                            step=1,
                            label=get_text("num_variants"),
                            info=get_text("num_variants_info")
                        )

                        # Character name field
                        single_character_name = gr.Textbox(
                            label=get_text("character_name"),
                            placeholder=get_text("character_name_placeholder"),
                            info=get_text("character_name_info"),
                            lines=1
                        )

                        # Extra options
                        with gr.Accordion(get_text("extra_options"), open=False):
                            single_extra_options = gr.CheckboxGroup(
                                choices=get_extra_options(),
                                value=[],
                                label="",
                                info=get_text("extra_options_info")
                            )

                        with gr.Accordion(get_text("custom_prompt_override"), open=False):
                            single_custom_prompt = gr.Textbox(
                                placeholder=get_text("custom_prompt_placeholder"),
                                lines=3,
                                label=""
                            )

                        with gr.Row():
                            single_submit_btn = gr.Button(
                                get_text("generate_btn"),
                                variant="primary",
                                elem_classes="generate-btn",
                                scale=3
                            )
                            single_stop_btn = gr.Button(
                                get_text("stop_btn"),
                                variant="stop",
                                scale=1
                            )

                    with gr.Column(scale=1, elem_classes="card-style"):
                        gr.Markdown("### üìä Results")
                        single_status = gr.Textbox(
                            label=get_text("status"),
                            interactive=False,
                            elem_classes="status-box"
                        )
                        single_prompt_used = gr.Textbox(
                            label="Prompt Used",
                            interactive=False,
                            lines=2
                        )

                        # Multiple variant outputs
                        single_outputs = []
                        for i in range(5):
                            with gr.Group(visible=(i == 0)) as variant_group:
                                variant_output = gr.Textbox(
                                    label=f"{get_text('variant')} {i+1}" if i > 0 else get_text("result"),
                                    lines=8,
                                    show_copy_button=True
                                )
                                single_outputs.append((variant_group, variant_output))

                        # Download result file
                        single_download = gr.File(
                            label=get_text("download_result"),
                            visible=True
                        )

                # –ö–ª–∏–∫–∞–±–µ–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –ø—Ä–æ–º—Ç–æ–≤
                examples_title = gr.Markdown(f"### {get_text('examples_title')}")

            # –í–∫–ª–∞–¥–∫–∞ –ø–∞–∫–µ—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
            batch_tab = gr.TabItem(get_text("batch_processing"))
            with batch_tab:
                with gr.Row():
                    with gr.Column(scale=1, elem_classes="card-style"):
                        gr.Markdown("### üìÅ Input Files")
                        batch_images = gr.File(
                            file_count="multiple",
                            label=get_text("upload_images"),
                            file_types=["image"]
                        )

                        gr.Markdown("### üìù Description Settings")

                        # Prompt preset dropdown
                        with gr.Row():
                            batch_preset = gr.Dropdown(
                                choices=list(load_prompt_presets().keys()),
                                value="None",
                                label=get_text("prompt_preset"),
                                info=get_text("prompt_preset_info"),
                                scale=4
                            )
                            batch_refresh_presets = gr.Button(
                                get_text("refresh_presets"),
                                size="sm",
                                scale=1
                            )

                        batch_desc_type = gr.Dropdown(
                            choices=get_description_types(),
                            value=get_description_types()[0],
                            label=get_text("description_type"),
                            info=get_text("description_type_info")
                        )
                        batch_desc_length = gr.Dropdown(
                            choices=get_description_lengths(),
                            value=get_description_lengths()[0],
                            label=get_text("description_length"),
                            info=get_text("description_length_info")
                        )
                        batch_num_variants = gr.Slider(
                            minimum=1,
                            maximum=3,
                            value=1,
                            step=1,
                            label=get_text("num_variants"),
                            info=get_text("num_variants_info")
                        )

                        # Character name field
                        batch_character_name = gr.Textbox(
                            label=get_text("character_name"),
                            placeholder=get_text("character_name_placeholder"),
                            info=get_text("character_name_info"),
                            lines=1
                        )

                        # Extra options
                        with gr.Accordion(get_text("extra_options"), open=False):
                            batch_extra_options = gr.CheckboxGroup(
                                choices=get_extra_options(),
                                value=[],
                                label="",
                                info=get_text("extra_options_info")
                            )

                        with gr.Accordion(get_text("custom_prompt_override"), open=False):
                            batch_custom_prompt = gr.Textbox(
                                placeholder=get_text("custom_prompt_placeholder"),
                                lines=3,
                                label=""
                            )

                        gr.Markdown("### üíæ Export Settings")
                        batch_output_folder = gr.Textbox(
                            label=get_text("output_folder"),
                            placeholder=get_text("output_folder_placeholder"),
                            value=""
                        )
                        batch_export_formats = gr.CheckboxGroup(
                            choices=["TXT", "JSON", "CSV"],
                            value=["TXT"],
                            label=get_text("export_format")
                        )

                        with gr.Row():
                            batch_submit_btn = gr.Button(
                                get_text("process_batch_btn"),
                                variant="primary",
                                elem_classes="generate-btn",
                                scale=3
                            )
                            batch_stop_btn = gr.Button(
                                get_text("stop_btn"),
                                variant="stop",
                                scale=1
                            )

                    with gr.Column(scale=1, elem_classes="card-style"):
                        gr.Markdown("### üìä Results")
                        batch_status = gr.Textbox(
                            label=get_text("status"),
                            interactive=False,
                            elem_classes="status-box"
                        )
                        batch_output = gr.Textbox(
                            label=get_text("results"),
                            lines=20,
                            show_copy_button=True
                        )

                        # Download result file
                        batch_download = gr.File(
                            label=get_text("download_result"),
                            visible=True
                        )
        
        # –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–æ–±—ã—Ç–∏–π
        def change_language(lang):
            global current_language
            current_language = lang

            # Return updated text for key components
            return [
                f"{get_text('subtitle')}",  # header_md
                gr.update(label=get_text("model_selection"), info=get_text("model_info")),  # model_dropdown
                gr.update(label=get_text("quantization"), info=get_text("quantization_info")),  # quantization_dropdown
                gr.update(label=get_text("language"), info=get_text("language_info")),  # language_dropdown
                gr.update(label=get_text("advanced_params")),  # advanced_accordion
                gr.update(value=get_text("generate_btn")),  # single_submit_btn
                gr.update(value=get_text("process_batch_btn")),  # batch_submit_btn
                gr.update(choices=get_description_types(), value=get_description_types()[0]),  # single_desc_type
                gr.update(choices=get_description_lengths(), value=get_description_lengths()[0]),  # single_desc_length
                gr.update(choices=get_description_types(), value=get_description_types()[0]),  # batch_desc_type
                gr.update(choices=get_description_lengths(), value=get_description_lengths()[0]),  # batch_desc_length
                gr.update(choices=get_extra_options(), value=[]),  # single_extra_options
                gr.update(choices=get_extra_options(), value=[]),  # batch_extra_options
                gr.update(value=get_text("stop_btn")),  # single_stop_btn
                gr.update(value=get_text("stop_btn")),  # batch_stop_btn
            ]

        language_dropdown.change(
            fn=change_language,
            inputs=language_dropdown,
            outputs=[
                header_md,
                model_dropdown,
                quantization_dropdown,
                language_dropdown,
                advanced_accordion,
                single_submit_btn,
                batch_submit_btn,
                single_desc_type,
                single_desc_length,
                batch_desc_type,
                batch_desc_length,
                single_extra_options,
                batch_extra_options,
                single_stop_btn,
                batch_stop_btn,
            ]
        )

        # Stop button handlers
        single_stop_btn.click(
            fn=stop_generation,
            outputs=single_status
        )

        batch_stop_btn.click(
            fn=stop_generation,
            outputs=batch_status
        )

        # Preset refresh handlers
        def refresh_presets():
            presets = load_prompt_presets()
            return gr.update(choices=list(presets.keys()), value="None")

        single_refresh_presets.click(
            fn=refresh_presets,
            outputs=single_preset
        )

        batch_refresh_presets.click(
            fn=refresh_presets,
            outputs=batch_preset
        )

        # Preset selection handlers (load preset text into custom prompt)
        def load_preset(preset_name):
            presets = load_prompt_presets()
            if preset_name and preset_name != "None":
                return presets.get(preset_name, "")
            return ""

        single_preset.change(
            fn=load_preset,
            inputs=single_preset,
            outputs=single_custom_prompt
        )

        batch_preset.change(
            fn=load_preset,
            inputs=batch_preset,
            outputs=batch_custom_prompt
        )

        random_seed_btn.click(
            fn=random_seed,
            outputs=seed_number
        )

        # Update variant visibility based on slider
        def update_variant_visibility(num_variants):
            updates = []
            for i in range(5):
                updates.append(gr.update(visible=(i < num_variants)))
            return updates

        single_num_variants.change(
            fn=update_variant_visibility,
            inputs=[single_num_variants],
            outputs=[group for group, _ in single_outputs]
        )

        # Single image processing with button lock
        def process_single_wrapper(image, video, image_url, desc_type, desc_length, custom_prompt,
                                   extra_options, character_name, num_variants,
                                   model_name, quantization, max_tokens, temperature, top_p, top_k, seed):
            # Disable button at start
            yield gr.update(value=get_text("generating"), interactive=False), "", "", *[gr.update(value="") for _ in range(5)], None

            results = []
            download_path = None

            # Process and yield results
            for status, prompt_used, results, download_path in process_single_image(
                image, video, image_url, desc_type, desc_length, custom_prompt,
                extra_options, character_name, num_variants,
                model_name, quantization, max_tokens, temperature, top_p, top_k, seed
            ):
                # Prepare outputs for each variant box
                variant_outputs = []
                for i in range(5):
                    if i < len(results):
                        variant_outputs.append(gr.update(value=results[i]))
                    else:
                        variant_outputs.append(gr.update(value=""))

                yield gr.update(value=get_text("generating"), interactive=False), status, prompt_used, *variant_outputs, download_path

            # Re-enable button at end
            final_outputs = []
            for i in range(5):
                if i < len(results):
                    final_outputs.append(gr.update(value=results[i]))
                else:
                    final_outputs.append(gr.update(value=""))

            yield gr.update(value=get_text("generate_btn"), interactive=True), status, prompt_used, *final_outputs, download_path

        single_submit_btn.click(
            fn=process_single_wrapper,
            inputs=[
                single_image,
                single_video,
                single_image_url,
                single_desc_type,
                single_desc_length,
                single_custom_prompt,
                single_extra_options,
                single_character_name,
                single_num_variants,
                model_dropdown,
                quantization_dropdown,
                max_tokens_slider,
                temperature_slider,
                top_p_slider,
                top_k_slider,
                seed_number
            ],
            outputs=[single_submit_btn, single_status, single_prompt_used] + [output for _, output in single_outputs] + [single_download]
        )
        
        # Preset handlers
        def refresh_presets_list():
            presets = load_prompt_presets()
            return gr.update(choices=list(presets.keys()), value="None")
        
        single_refresh_presets.click(
            fn=refresh_presets_list,
            outputs=single_preset
        )
        
        def load_preset(preset_name):
            if preset_name and preset_name != "None":
                presets = load_prompt_presets()
                return presets.get(preset_name, "")
            return ""
        
        single_preset.change(
            fn=load_preset,
            inputs=single_preset,
            outputs=single_custom_prompt
        )
        
        def save_preset(name, prompt):
            if not name:
                return "‚ùå Please enter a preset name"
            msg = save_prompt_preset(name, prompt)
            new_presets = list(load_prompt_presets().keys())
            return msg, gr.update(choices=new_presets, value=name if "successfully" in msg else None)
        
        single_save_preset_btn.click(
            fn=save_preset,
            inputs=[single_save_preset_name, single_custom_prompt],
            outputs=[single_save_preset_status, single_preset]
        )

        # Batch processing with button lock
        def process_batch_wrapper(files, desc_type, desc_length, custom_prompt,
                                  extra_options, character_name, num_variants,
                                  output_folder, export_formats, model_name, quantization,
                                  max_tokens, temperature, top_p, top_k, seed):
            # Disable button at start
            yield gr.update(value=get_text("generating"), interactive=False), "", "", None

            download_path = None

            # Process and yield results
            for status, output_text, download_path in process_batch_images(
                files, desc_type, desc_length, custom_prompt,
                extra_options, character_name, num_variants,
                output_folder, export_formats, model_name, quantization,
                max_tokens, temperature, top_p, top_k, seed
            ):
                yield gr.update(value=get_text("generating"), interactive=False), status, output_text, download_path

            # Re-enable button at end
            yield gr.update(value=get_text("process_batch_btn"), interactive=True), status, output_text, download_path

        batch_submit_btn.click(
            fn=process_batch_wrapper,
            inputs=[
                batch_images,
                batch_desc_type,
                batch_desc_length,
                batch_custom_prompt,
                batch_extra_options,
                batch_character_name,
                batch_num_variants,
                batch_output_folder,
                batch_export_formats,
                model_dropdown,
                quantization_dropdown,
                max_tokens_slider,
                temperature_slider,
                top_p_slider,
                top_k_slider,
                seed_number
            ],
            outputs=[batch_submit_btn, batch_status, batch_output, batch_download]
        )

        return demo

# –°–æ–∑–¥–∞–µ–º –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å Gradio
demo = create_interface()

if __name__ == "__main__":
    # Enable queue for progress bar support
    demo.queue(max_size=20, default_concurrency_limit=1).launch(
        server_name="127.0.0.1",
        server_port=None,
        share=False,
        show_error=True,
        inbrowser=True
    )
